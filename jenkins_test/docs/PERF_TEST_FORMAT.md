# TensorRT-LLM æ€§èƒ½æµ‹è¯• TestList æ ¼å¼è¯´æ˜

## ğŸ¯ æ ¸å¿ƒç†è§£

### test_perf_sanity.py::test_e2e çš„å·¥ä½œåŸç†

```python
# tests/integration/defs/perf/test_perf_sanity.py

@pytest.mark.parametrize("perf_sanity_test_case", PERF_SANITY_TEST_CASES)
def test_e2e(output_dir, perf_sanity_test_case):
    """
    æ€§èƒ½æµ‹è¯•çš„å…¥å£å‡½æ•°
    
    perf_sanity_test_case æ ¼å¼:
    - Agg æ¨¡å¼: {test_type}-{config_yml}[-{server_config_name}]
    - Disagg æ¨¡å¼: {test_type}-{config_yml}
    
    ç¤ºä¾‹:
    - "profiling-deepseek_r1_fp4_v2_blackwell"
    - "profiling-deepseek_r1_fp4_v2_blackwell-default_config"
    - "benchmark-llama3_70b_disagg"
    """
    config = PerfSanityTestConfig(perf_sanity_test_case, output_dir)
    ...
```

### æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆé€»è¾‘

```python
# Agg æµ‹è¯•ç±»å‹
AGG_TEST_TYPES = ["profiling", "benchmark"]

# Disagg æµ‹è¯•ç±»å‹
DISAGG_TEST_TYPES = ["benchmark"]

# è‡ªåŠ¨ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹
def get_aggr_test_cases():
    """
    æ‰«æ tests/scripts/perf-sanity/*.yaml
    ä¸ºæ¯ä¸ª YAML å’Œæ¯ä¸ª test_type ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹
    
    å¦‚æœ YAML ä¸­å®šä¹‰äº†å¤šä¸ª server_configsï¼Œè¿˜ä¼šç”Ÿæˆæ¯ä¸ª server_config çš„æµ‹è¯•ç”¨ä¾‹
    """
    test_cases = []
    for config_yml in yaml_files:
        for test_type in AGG_TEST_TYPES:
            # è¿è¡Œæ‰€æœ‰ server configs
            test_cases.append(f"{test_type}-{config_yml}")
            
            # è¿è¡Œå•ä¸ª server config
            for server_name in server_names:
                test_cases.append(f"{test_type}-{config_yml}-{server_name}")
    return test_cases

def get_disagg_test_cases():
    """
    æ‰«æ tests/integration/defs/perf/disagg/test_configs/disagg/perf/*.yaml
    ä¸ºæ¯ä¸ª YAML å’Œæ¯ä¸ª test_type ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹
    """
    test_cases = []
    for config_yml in yaml_files:
        for test_type in DISAGG_TEST_TYPES:
            test_cases.append(f"{test_type}-{config_yml}")
    return test_cases
```

---

## ğŸ“ TestList æ ¼å¼

### æ–¹å¼ 1: pytest è·¯å¾„æ ¼å¼ï¼ˆæ¨è TXTï¼‰

```txt
# å®Œæ•´çš„ pytest è·¯å¾„ï¼ˆJenkins L0_Test.groovy ä½¿ç”¨çš„æ ¼å¼ï¼‰
tests/integration/defs/perf/test_perf_sanity.py::test_e2e[profiling-deepseek_r1_fp4_v2_blackwell]
tests/integration/defs/perf/test_perf_sanity.py::test_e2e[benchmark-deepseek_r1_fp4_v2_blackwell-default_config]
tests/integration/defs/perf/test_perf_sanity.py::test_e2e[benchmark-llama3_70b_disagg]
```

### æ–¹å¼ 2: ç®€åŒ–æ ¼å¼ï¼ˆå¯é€‰ï¼‰

```txt
# åªå†™å‚æ•°éƒ¨åˆ†ï¼ˆæ¨èç”¨äºå¿«é€Ÿ debugï¼‰
profiling-deepseek_r1_fp4_v2_blackwell
benchmark-deepseek_r1_fp4_v2_blackwell-default_config
benchmark-llama3_70b_disagg
```

### æ–¹å¼ 3: pytest -k æ ¼å¼ï¼ˆæ¨èç”¨äºè¿‡æ»¤ï¼‰

```bash
# ä½¿ç”¨ pytest -k è¿‡æ»¤
pytest tests/integration/defs/perf/test_perf_sanity.py -k "deepseek"
pytest tests/integration/defs/perf/test_perf_sanity.py -k "profiling and deepseek"
pytest tests/integration/defs/perf/test_perf_sanity.py -k "benchmark and not disagg"
```

---

## ğŸ” æµ‹è¯•ç”¨ä¾‹å‘½åè§„åˆ™

### Agg æ¨¡å¼ï¼ˆå•èŠ‚ç‚¹æˆ–å¤šèŠ‚ç‚¹èšåˆï¼‰

æ ¼å¼: `{test_type}-{config_yml}[-{server_config_name}]`

| éƒ¨åˆ† | è¯´æ˜ | ç¤ºä¾‹ |
|------|------|------|
| `test_type` | æµ‹è¯•ç±»å‹ | `profiling`, `benchmark` |
| `config_yml` | YAML é…ç½®æ–‡ä»¶åï¼ˆä¸å«æ‰©å±•åï¼‰ | `deepseek_r1_fp4_v2_blackwell` |
| `server_config_name` | å¯é€‰ï¼šserver_config åç§° | `default_config`, `high_throughput` |

**é…ç½®æ–‡ä»¶ä½ç½®**: `tests/scripts/perf-sanity/`

**ç¤ºä¾‹**:
```txt
# è¿è¡Œæ‰€æœ‰ server configs
profiling-deepseek_r1_fp4_v2_blackwell
benchmark-deepseek_r1_fp4_v2_blackwell

# è¿è¡Œç‰¹å®š server config
profiling-deepseek_r1_fp4_v2_blackwell-default_config
benchmark-deepseek_r1_fp4_v2_blackwell-high_throughput_config
```

### Disagg æ¨¡å¼ï¼ˆåˆ†ç¦»å¼ï¼‰

æ ¼å¼: `{test_type}-{config_yml}`

| éƒ¨åˆ† | è¯´æ˜ | ç¤ºä¾‹ |
|------|------|------|
| `test_type` | æµ‹è¯•ç±»å‹ | `benchmark` (disagg åªæ”¯æŒ benchmark) |
| `config_yml` | YAML é…ç½®æ–‡ä»¶åï¼ˆä¸å«æ‰©å±•åï¼‰ | `llama3_70b_disagg` |

**é…ç½®æ–‡ä»¶ä½ç½®**: `tests/integration/defs/perf/disagg/test_configs/disagg/perf/`

**ç¤ºä¾‹**:
```txt
benchmark-llama3_70b_disagg
benchmark-llama3_405b_disagg
```

---

## ğŸ“‚ é…ç½®æ–‡ä»¶ç»“æ„

### Agg é…ç½®æ–‡ä»¶ç¤ºä¾‹

```yaml
# tests/scripts/perf-sanity/deepseek_r1_fp4_v2_blackwell.yaml

server_configs:
  - name: "default_config"
    model_name: "deepseek_r1_0528_fp4_v2"
    tensor_parallel_size: 8
    max_batch_size: 512
    # ... å…¶ä»–é…ç½®

  - name: "high_throughput_config"
    model_name: "deepseek_r1_0528_fp4_v2"
    tensor_parallel_size: 8
    max_batch_size: 1024
    # ... å…¶ä»–é…ç½®

benchmark_configs:
  - name: "default_benchmark"
    # ... benchmark é…ç½®
```

**ç”Ÿæˆçš„æµ‹è¯•ç”¨ä¾‹**:
```txt
profiling-deepseek_r1_fp4_v2_blackwell
profiling-deepseek_r1_fp4_v2_blackwell-default_config
profiling-deepseek_r1_fp4_v2_blackwell-high_throughput_config
benchmark-deepseek_r1_fp4_v2_blackwell
benchmark-deepseek_r1_fp4_v2_blackwell-default_config
benchmark-deepseek_r1_fp4_v2_blackwell-high_throughput_config
```

### Disagg é…ç½®æ–‡ä»¶ç¤ºä¾‹

```yaml
# tests/integration/defs/perf/disagg/test_configs/disagg/perf/llama3_70b_disagg.yaml

server_configs:
  - name: "prefill_server"
    model_name: "llama3_70b"
    disagg_run_type: "PREFILL"
    # ... å…¶ä»–é…ç½®

  - name: "kv_server"
    model_name: "llama3_70b"
    disagg_run_type: "KV"
    # ... å…¶ä»–é…ç½®

benchmark_configs:
  - name: "disagg_benchmark"
    # ... benchmark é…ç½®
```

**ç”Ÿæˆçš„æµ‹è¯•ç”¨ä¾‹**:
```txt
benchmark-llama3_70b_disagg
```

---

## ğŸš€ å®é™…ä½¿ç”¨ç¤ºä¾‹

### ç¤ºä¾‹ 1: debug_cases.txt (æ¨èæ ¼å¼)

```txt
# Debug Test Cases for Performance Testing
# Format: test_perf_sanity.py::test_e2e[test_case_id]

# ============================================
# Profiling æµ‹è¯•
# ============================================
test_perf_sanity.py::test_e2e[profiling-deepseek_r1_fp4_v2_blackwell]
test_perf_sanity.py::test_e2e[profiling-deepseek_r1_fp4_v2_blackwell-default_config]

# ============================================
# Benchmark æµ‹è¯•
# ============================================
test_perf_sanity.py::test_e2e[benchmark-deepseek_r1_fp4_v2_blackwell]
test_perf_sanity.py::test_e2e[benchmark-deepseek_r1_fp4_v2_blackwell-high_throughput_config]

# ============================================
# Disagg æµ‹è¯•
# ============================================
test_perf_sanity.py::test_e2e[benchmark-llama3_70b_disagg]
test_perf_sanity.py::test_e2e[benchmark-llama3_405b_disagg]
```

### ç¤ºä¾‹ 2: ç®€åŒ–æ ¼å¼ (ä¹Ÿæ”¯æŒ)

```txt
# Simplified format - test case ID only
profiling-deepseek_r1_fp4_v2_blackwell
benchmark-deepseek_r1_fp4_v2_blackwell-default_config
benchmark-llama3_70b_disagg
```

### ç¤ºä¾‹ 3: ä½¿ç”¨ pytest -k è¿‡æ»¤

```bash
# åªè¿è¡Œ profiling æµ‹è¯•
pytest tests/integration/defs/perf/test_perf_sanity.py -k "profiling"

# åªè¿è¡Œ deepseek ç›¸å…³æµ‹è¯•
pytest tests/integration/defs/perf/test_perf_sanity.py -k "deepseek"

# è¿è¡Œ benchmark ä½†æ’é™¤ disagg
pytest tests/integration/defs/perf/test_perf_sanity.py -k "benchmark and not disagg"

# è¿è¡Œç‰¹å®šé…ç½®
pytest tests/integration/defs/perf/test_perf_sanity.py -k "deepseek_r1_fp4_v2_blackwell and default_config"
```

---

## ğŸ”§ Jenkins é›†æˆ

### åœ¨ Jenkins Pipeline ä¸­ä½¿ç”¨

```groovy
// æ–¹å¼ 1: ä½¿ç”¨ testlist æ–‡ä»¶
def testList = 'jenkins_test/testlists/debug_cases.txt'
sh """
    cd tests/integration/defs/perf && \
    pytest test_perf_sanity.py --test-list=${testList}
"""

// æ–¹å¼ 2: ä½¿ç”¨ pytest -k è¿‡æ»¤
sh """
    cd tests/integration/defs/perf && \
    pytest test_perf_sanity.py -k "profiling and deepseek"
"""

// æ–¹å¼ 3: ç›´æ¥æŒ‡å®šæµ‹è¯•ç”¨ä¾‹
sh """
    cd tests/integration/defs/perf && \
    pytest test_perf_sanity.py::test_e2e[profiling-deepseek_r1_fp4_v2_blackwell]
"""
```

---

## ğŸ“‹ å¿«é€Ÿå‚è€ƒ

### ä»å¤±è´¥æ—¥å¿—åˆ›å»º debug testlist

```bash
# 1. ä» CI æ—¥å¿—å¤åˆ¶å¤±è´¥æµ‹è¯•
FAILED test_perf_sanity.py::test_e2e[profiling-deepseek_r1_fp4_v2_blackwell]
FAILED test_perf_sanity.py::test_e2e[benchmark-llama3_70b_disagg]

# 2. ç²˜è´´åˆ° debug_cases.txt
test_perf_sanity.py::test_e2e[profiling-deepseek_r1_fp4_v2_blackwell]
test_perf_sanity.py::test_e2e[benchmark-llama3_70b_disagg]

# 3. åœ¨ Jenkins ä¸­è¿è¡Œ
TESTLIST = 'debug_cases'
```

### æŸ¥çœ‹æ‰€æœ‰å¯ç”¨æµ‹è¯•ç”¨ä¾‹

```bash
# åˆ—å‡ºæ‰€æœ‰æµ‹è¯•ç”¨ä¾‹
cd tests/integration/defs/perf
pytest test_perf_sanity.py --collect-only

# åªçœ‹ pytest IDs
pytest test_perf_sanity.py --collect-only -q
```

---

## âš ï¸ æ³¨æ„äº‹é¡¹

1. **é…ç½®æ–‡ä»¶å¿…é¡»å­˜åœ¨**
   - Agg: `tests/scripts/perf-sanity/{config_yml}.yaml`
   - Disagg: `tests/integration/defs/perf/disagg/test_configs/disagg/perf/{config_yml}.yaml`

2. **æµ‹è¯•ç±»å‹é™åˆ¶**
   - Agg æ”¯æŒ: `profiling`, `benchmark`
   - Disagg åªæ”¯æŒ: `benchmark`

3. **server_config_name å¯é€‰**
   - ä¸æŒ‡å®š: è¿è¡Œæ‰€æœ‰ server_configs
   - æŒ‡å®š: åªè¿è¡Œç‰¹å®š server_config

4. **æ¨¡å¼æ ‡è®°ä¸å†éœ€è¦**
   - TXT æ ¼å¼ä¸éœ€è¦ `# mode:single-agg` ç­‰æ ‡è®°
   - æµ‹è¯•ç±»å‹ç”±é…ç½®æ–‡ä»¶è‡ªåŠ¨è¯†åˆ«

---

## ğŸ“š ç›¸å…³æ–‡æ¡£

- [test_perf_sanity.py æºç ](../tests/integration/defs/perf/test_perf_sanity.py)
- [Jenkins L0_Test.groovy](../jenkins/L0_Test.groovy)
- [é…ç½®æ–‡ä»¶ç¤ºä¾‹](../tests/scripts/perf-sanity/)
