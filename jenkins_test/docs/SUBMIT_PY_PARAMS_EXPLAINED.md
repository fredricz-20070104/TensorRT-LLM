# submit.py å‚æ•°è¯¦è§£ä¸Ž L0 å¯¹é½æ–¹æ¡ˆ

> åŸºäºŽ L0_Test.groovy çš„ disagg æ¨¡å¼ï¼Œå®Œæ•´è§£æž submit.py çš„æ¯ä¸ªå‚æ•°åŠå…¶ç”¨é€”

---

## ðŸŽ¯ L0_Test.groovy çš„ Disagg è°ƒç”¨æ–¹å¼

### å®Œæ•´è°ƒç”¨ï¼ˆç¬¬ 1208-1219 è¡Œï¼‰

```groovy
python3 ${scriptSubmitLocalPath} \
    --run-ci \
    --llm-src ${llmSrcLocal} \
    --test-list ${testListPathLocal} \
    --draft-launch-sh ${scriptLaunchDraftPathLocal} \
    --launch-sh ${scriptLaunchPathLocal} \
    --run-sh ${scriptRunPathNode} \
    --install-sh ${scriptInstallPathNode} \
    --script-prefix ${scriptLaunchPrefixPathLocal} \
    --srun-args ${scriptLaunchSrunArgsPathLocal}
```

---

## ðŸ“‹ æ¯ä¸ªå‚æ•°çš„è¯¦ç»†è§£é‡Š

### 1. `--run-ci` (å¿…éœ€æ ‡å¿—)

**ç±»åž‹ï¼š** Flagï¼ˆå¸ƒå°”å€¼ï¼‰
**ä½œç”¨ï¼š** å‘Šè¯‰ `submit.py` ä½¿ç”¨ CI æ¨¡å¼

**ä»£ç ä½ç½®ï¼š** submit.py ç¬¬ 168-172 è¡Œ

```python
parser.add_argument(
    "--run-ci",
    action="store_true",
    default=False,
    help="Run in CI mode (true) or local mode (false)",
)
```

**è¯´æ˜Žï¼š**
- CI æ¨¡å¼ï¼šä»Ž test-list æ–‡ä»¶ä¸­æå–é…ç½®å
- Local æ¨¡å¼ï¼šç›´æŽ¥ä½¿ç”¨ `--config-yaml` å‚æ•°

**L0 ä½¿ç”¨ï¼š** æ€»æ˜¯è®¾ç½®æ­¤æ ‡å¿—ï¼ˆä½¿ç”¨ CI æ¨¡å¼ï¼‰

---

### 2. `--llm-src` (å¿…éœ€ï¼ŒCI æ¨¡å¼)

**ç±»åž‹ï¼š** å­—ç¬¦ä¸²
**ä½œç”¨ï¼š** TensorRT-LLM æºç çš„è·¯å¾„

**ä»£ç ä½ç½®ï¼š** submit.py ç¬¬ 184 è¡Œ

```python
parser.add_argument("--llm-src", default="", help="Path to LLM source code")
```

**åœ¨ submit.py ä¸­çš„ä½¿ç”¨ï¼š** ç¬¬ 199 è¡Œ

```python
config_yaml = get_config_yaml(args.test_list, args.llm_src)
# æž„å»ºé…ç½®æ–‡ä»¶è·¯å¾„ï¼š
# {llm_src}/tests/integration/defs/perf/disagg/test_configs/disagg/perf/{config_name}.yaml
```

**L0 çš„å€¼ï¼š** `${llmSrcLocal}` = `/path/to/workspace/TensorRT-LLM/src`

**Jenkins åº”è¯¥ä¼ ä»€ä¹ˆï¼š** `$TRTLLM_DIR` (TensorRT-LLM çš„æ ¹ç›®å½•)

---

### 3. `--test-list` (å¿…éœ€ï¼ŒCI æ¨¡å¼)

**ç±»åž‹ï¼š** å­—ç¬¦ä¸²ï¼ˆæ–‡ä»¶è·¯å¾„ï¼‰
**ä½œç”¨ï¼š** Test list æ–‡ä»¶ï¼ŒåŒ…å« pytest å‘½ä»¤

**ä»£ç ä½ç½®ï¼š** submit.py ç¬¬ 185 è¡Œ

```python
parser.add_argument("--test-list", default="", help="Path to test list file")
```

**æ–‡ä»¶å†…å®¹æ ¼å¼ï¼š**

```
perf/test_perf_sanity.py::test_e2e[disagg_upload-deepseek-r1-fp4_1k1k_ctx1_gen1_dep8_bs768_eplb0_mtp0_ccb-UCX]
```

**åœ¨ submit.py ä¸­çš„ä½¿ç”¨ï¼š** ç¬¬ 126-161 è¡Œ

```python
def get_config_yaml(test_list_path, llm_src):
    # 1. è¯»å– test list æ–‡ä»¶çš„ç¬¬ä¸€è¡Œ
    with open(test_list_path, "r") as f:
        first_line = f.readline().strip()
    
    # 2. ä»Ž test case name ä¸­æå–é…ç½®æ–‡ä»¶å
    # ä¾‹å¦‚: test_e2e[disagg_upload-deepseek-r1-fp4_1k1k...]
    # æå–: deepseek-r1-fp4_1k1k_ctx1_gen1_dep8_bs768_eplb0_mtp0_ccb-UCX
    bracket_content = first_line.split("[")[-1].split("]")[0]
    parts = bracket_content.split("-")
    config_base_name = "-".join(parts[1:])  # è·³è¿‡ "disagg_upload" æˆ– "disagg"
    
    # 3. æž„å»ºé…ç½®æ–‡ä»¶å®Œæ•´è·¯å¾„
    config_yaml_path = os.path.join(
        llm_src,
        "tests/integration/defs/perf/disagg/test_configs/disagg/perf",
        f"{config_base_name}.yaml"
    )
    
    return config_yaml_path
```

**å…³é”®ï¼š** test-list æ–‡ä»¶çš„ç¬¬ä¸€è¡Œå¿…é¡»åŒ…å«å®Œæ•´çš„ pytest å‚æ•°åŒ–åç§°ï¼

**L0 çš„å€¼ï¼š** `${testListPathNode}` = `/home/svc_tensorrt/bloom/scripts/{job_uid}/{test_list_name}.txt`

**Jenkins åº”è¯¥æ€Žä¹ˆåšï¼š**

```bash
# åˆ›å»ºä¸´æ—¶ test list æ–‡ä»¶
TEST_LIST_FILE="$WORKSPACE/test_list_disagg.txt"
echo "perf/test_perf_sanity.py::test_e2e[disagg_upload-${CONFIG_NAME}]" > "$TEST_LIST_FILE"
```

---

### 4. `--draft-launch-sh` (å¿…éœ€)

**ç±»åž‹ï¼š** å­—ç¬¦ä¸²ï¼ˆæ–‡ä»¶è·¯å¾„ï¼‰
**ä½œç”¨ï¼š** æ¨¡æ¿è„šæœ¬ï¼ŒåŒ…å«å¯åŠ¨é€»è¾‘

**ä»£ç ä½ç½®ï¼š** submit.py ç¬¬ 174 è¡Œ

```python
parser.add_argument("--draft-launch-sh", required=True, help="Path to draft-launch.sh script")
```

**æ–‡ä»¶ä½ç½®ï¼š** `jenkins/scripts/perf/disaggregated/slurm_launch_draft.sh`

**æ–‡ä»¶å†…å®¹ï¼š** ï¼ˆç¬¬ 1-77 è¡Œï¼Œå°±æ˜¯ä½ ä¹‹å‰çœ‹åˆ°çš„é‚£ä¸ªæ–‡ä»¶ï¼‰

```bash
cleanup_on_failure() { ... }
mkdir -p $jobWorkspace
chmod +x $runScript
chmod +x $installScript

# Run installation on all nodes...
srun "${srunArgs[@]}" $installScript

# Start gen servers...
for i in $(seq 0 $((numGenServers - 1))); do
    export DISAGG_SERVING_TYPE="GEN_$i"
    export pytestCommand="$pytestCommandWorker"
    srun "${srunArgs[@]}" ... $runScript &
done

# Start ctx servers...
# Start disagg server...
# Start benchmark...
```

**åœ¨ submit.py ä¸­çš„ä½¿ç”¨ï¼š** ç¬¬ 278-282 è¡Œ

```python
with open(args.draft_launch_sh, "r") as f:
    draft_launch_content = f.read()
draft_launch_lines = draft_launch_content.split("\n")
remove_whitespace_lines(draft_launch_lines)
draft_launch_content = "\n".join(draft_launch_lines)
```

**L0 çš„å€¼ï¼š** `${llmSrcLocal}/jenkins/scripts/perf/disaggregated/slurm_launch_draft.sh`

**Jenkins åº”è¯¥ä¼ ä»€ä¹ˆï¼š** `$TRTLLM_DIR/jenkins/scripts/perf/disaggregated/slurm_launch_draft.sh`

---

### 5. `--launch-sh` (å¿…éœ€)

**ç±»åž‹ï¼š** å­—ç¬¦ä¸²ï¼ˆæ–‡ä»¶è·¯å¾„ï¼‰
**ä½œç”¨ï¼š** è¾“å‡ºè„šæœ¬è·¯å¾„ï¼Œsubmit.py ä¼šç”Ÿæˆè¿™ä¸ªæ–‡ä»¶

**ä»£ç ä½ç½®ï¼š** submit.py ç¬¬ 175 è¡Œ

```python
parser.add_argument("--launch-sh", required=True, help="Path to output launch.sh script")
```

**åœ¨ submit.py ä¸­çš„ä½¿ç”¨ï¼š** ç¬¬ 284-285 è¡Œ

```python
with open(args.launch_sh, "w") as f:
    f.write(f"{script_prefix}\n{srun_args}\n{draft_launch_content}")
```

**ç”Ÿæˆçš„æ–‡ä»¶ç»“æž„ï¼š**

```bash
#!/bin/bash

# ============ Part 1: script_prefix ============
# çŽ¯å¢ƒå˜é‡å¯¼å‡º
export pytestCommand="pytest perf/test_perf_sanity.py::test_e2e[...]"
export pytestCommandWorker="unset UCX_TLS && TLLM_LOG_LEVEL=INFO ... $pytestCommand"
export pytestCommandDisaggServer="TRTLLM_SERVER_DISABLE_GC=1 $pytestCommandNoLLMAPILaunch"
export pytestCommandBenchmark="... $pytestCommandNoLLMAPILaunch"
export runScript=/path/to/slurm_run.sh
export installScript=/path/to/slurm_install.sh
export numCtxServers=1
export numGenServers=1
export gpusPerNode=4
export totalNodes=2
export totalGpus=8

# ============ Part 2: srun_args ============
srunArgs=(
  "--container-name=multi_node_test-${SLURM_JOB_ID}"
  "--container-image=/path/to/image.sqsh"
  "--container-workdir=/job/workspace"
  "--container-mounts=/data:/data"
  "--mpi=pmix"
  "--container-env=DISAGG_SERVING_TYPE"
  "--container-env=pytestCommand"
)

# ============ Part 3: draft_launch_content ============
# slurm_launch_draft.sh çš„å†…å®¹
cleanup_on_failure() { ... }
mkdir -p $jobWorkspace
...
# å¯åŠ¨æ‰€æœ‰ç»„ä»¶çš„é€»è¾‘
```

**L0 çš„å€¼ï¼š** ä¸´æ—¶æ–‡ä»¶è·¯å¾„ï¼ˆæ¯æ¬¡ç”Ÿæˆæ–°çš„ï¼‰

**Jenkins åº”è¯¥ä¼ ä»€ä¹ˆï¼š** `$WORKSPACE/slurm_launch_generated.sh`

---

### 6. `--run-sh` (å¿…éœ€)

**ç±»åž‹ï¼š** å­—ç¬¦ä¸²ï¼ˆæ–‡ä»¶è·¯å¾„ï¼‰
**ä½œç”¨ï¼š** slurm_run.sh è„šæœ¬çš„è·¯å¾„ï¼ˆåœ¨é›†ç¾¤èŠ‚ç‚¹ä¸Šï¼‰

**ä»£ç ä½ç½®ï¼š** submit.py ç¬¬ 176 è¡Œ

```python
parser.add_argument("--run-sh", required=True, help="Path to slurm_run.sh script")
```

**åœ¨ submit.py ä¸­çš„ä½¿ç”¨ï¼š** ç¬¬ 251 è¡Œ

```python
script_prefix_lines.extend([
    f"export runScript={args.run_sh}",  # â† è¿™é‡Œ
    ...
])
```

**slurm_run.sh çš„ä½œç”¨ï¼š**

```bash
#!/bin/bash
# jenkins/scripts/slurm_run.sh

cd $resourcePathNode
llmSrcNode=$resourcePathNode/TensorRT-LLM/src

# ... å®‰è£…å’ŒçŽ¯å¢ƒè®¾ç½® ...

cd $llmSrcNode/tests/integration/defs

echo "Full Command: $pytestCommand"
eval $pytestCommand  # â† æ‰§è¡Œ pytest
```

**L0 çš„å€¼ï¼š** `${scriptRunPathNode}` = `/home/svc_tensorrt/bloom/scripts/{job_uid}/{job_uid}-slurm_run.sh`

**Jenkins åº”è¯¥ä¼ ä»€ä¹ˆï¼š** åœ¨é›†ç¾¤ä¸Šçš„ slurm_run.sh è·¯å¾„ï¼ˆéœ€è¦å…ˆåŒæ­¥è¿‡åŽ»ï¼‰

---

### 7. `--install-sh` (å¿…éœ€)

**ç±»åž‹ï¼š** å­—ç¬¦ä¸²ï¼ˆæ–‡ä»¶è·¯å¾„ï¼‰
**ä½œç”¨ï¼š** slurm_install.sh è„šæœ¬çš„è·¯å¾„ï¼ˆåœ¨é›†ç¾¤èŠ‚ç‚¹ä¸Šï¼‰

**ä»£ç ä½ç½®ï¼š** submit.py ç¬¬ 177 è¡Œ

```python
parser.add_argument("--install-sh", required=True, help="Path to slurm_install.sh script")
```

**åœ¨ submit.py ä¸­çš„ä½¿ç”¨ï¼š** ç¬¬ 205, 252 è¡Œ

```python
install_script = args.install_sh
script_prefix_lines.extend([
    ...
    f"export installScript={install_script}",  # â† è¿™é‡Œ
    ...
])
```

**slurm_install.sh çš„ä½œç”¨ï¼š**

```bash
#!/bin/bash
# jenkins/scripts/slurm_install.sh

# è§£åŽ‹ TensorRT-LLM æºç 
# å®‰è£… Python wheel
# è®¾ç½®çŽ¯å¢ƒ
```

**L0 çš„å€¼ï¼š** `${scriptInstallPathNode}` = `/home/svc_tensorrt/bloom/scripts/{job_uid}/{job_uid}-slurm_install.sh`

**Jenkins åº”è¯¥ä¼ ä»€ä¹ˆï¼š** åœ¨é›†ç¾¤ä¸Šçš„ slurm_install.sh è·¯å¾„ï¼ˆéœ€è¦å…ˆåŒæ­¥è¿‡åŽ»ï¼‰

---

### 8. `--script-prefix` (å¿…éœ€ï¼ŒCI æ¨¡å¼)

**ç±»åž‹ï¼š** å­—ç¬¦ä¸²ï¼ˆæ–‡ä»¶è·¯å¾„ï¼‰
**ä½œç”¨ï¼š** åŒ…å«çŽ¯å¢ƒå˜é‡å’Œ pytest å‘½ä»¤çš„è„šæœ¬

**ä»£ç ä½ç½®ï¼š** submit.py ç¬¬ 186-189 è¡Œ

```python
parser.add_argument(
    "--script-prefix",
    default="",
    help="Launch script prefix file path (optional, CI mode only)",
)
```

**åœ¨ submit.py ä¸­çš„ä½¿ç”¨ï¼š** ç¬¬ 220-222 è¡Œ

```python
with open(args.script_prefix, "r") as f:
    script_prefix_content = f.read()
script_prefix_lines = script_prefix_content.split("\n")
```

**æ–‡ä»¶å†…å®¹ç¤ºä¾‹ï¼š** ï¼ˆL0_Test.groovy ç¬¬ 1162-1192 è¡Œç”Ÿæˆï¼‰

```bash
#!/bin/bash
#SBATCH --output=/path/to/job-output.log
#SBATCH --nodes=2
#SBATCH --ntasks=8
#SBATCH --gpus-per-node=4
#SBATCH --partition=batch
#SBATCH --time=04:00:00

set -xEeuo pipefail
trap 'rc=$?; echo "Error ..."; exit $rc' ERR

echo "Starting Slurm job $SLURM_JOB_ID on $SLURM_NODELIST"
export jobWorkspace=/home/svc_tensorrt/bloom/scripts/{job_uid}
export tarName=tensorrt_llm-*.tar.gz
export llmTarfile=https://urm.nvidia.com/artifactory/.../tensorrt_llm-*.tar.gz
export llmSrcNode=/tmp/TensorRT-LLM/src
export stageName="GB200-12_GPUs-3_Nodes-PyTorch-PerfSanity-Disagg-Post-Merge-1"
export perfMode=true
export resourcePathNode=/tmp
export pytestCommand="pytest perf/test_perf_sanity.py::test_e2e[disagg_upload-deepseek-r1-fp4_1k1k_ctx1_gen1_dep8_bs768_eplb0_mtp0_ccb-UCX] -vv --junit-xml=..."
export coverageConfigFile=/path/to/coverage_config.json
export NVIDIA_IMEX_CHANNELS=${NVIDIA_IMEX_CHANNELS:-0}
export NVIDIA_VISIBLE_DEVICES=${NVIDIA_VISIBLE_DEVICES:-...}
export OPEN_SEARCH_DB_BASE_URL="..."
export BUILD_ID="123"
export BUILD_URL="..."
export JOB_NAME="..."

# Enroot å®¹å™¨å¯¼å…¥é€»è¾‘ï¼ˆå¦‚æžœä½¿ç”¨ ENROOTï¼‰
importContainerWithRetries() { ... }
importContainerWithRetries "urm.nvidia.com#..." "/path/to/container.sqsh"
```

**å…³é”®å†…å®¹ï¼š**
1. SBATCH æŒ‡ä»¤ï¼ˆèŠ‚ç‚¹æ•°ã€GPU æ•°ã€åˆ†åŒºç­‰ï¼‰
2. çŽ¯å¢ƒå˜é‡å¯¼å‡º
3. pytestCommand å®šä¹‰
4. å®¹å™¨é•œåƒå¯¼å…¥ï¼ˆå¦‚æžœä½¿ç”¨ ENROOTï¼‰

**L0 å¦‚ä½•ç”Ÿæˆï¼š**

```groovy
// L0_Test.groovy ç¬¬ 1199 è¡Œ
def scriptLaunchPrefixPathLocal = Utils.createTempLocation(pipeline, "./slurm_launch_prefix.sh")
// ç¬¬ 1204 è¡Œ
pipeline.writeFile(file: scriptLaunchPrefixPathLocal, text: scriptLaunchPrefix)
```

**Jenkins åº”è¯¥æ€Žä¹ˆåšï¼š**

```bash
# ç”Ÿæˆ script prefix æ–‡ä»¶
SCRIPT_PREFIX_FILE="$WORKSPACE/slurm_launch_prefix.sh"
cat > "$SCRIPT_PREFIX_FILE" << 'EOF'
#!/bin/bash
#SBATCH --output=$WORKSPACE/slurm_%j.log
#SBATCH --nodes=$TOTAL_NODES
#SBATCH --ntasks=$TOTAL_GPUS
#SBATCH --gpus-per-node=$GPUS_PER_NODE
#SBATCH --partition=$CLUSTER_PARTITION
#SBATCH --account=$CLUSTER_ACCOUNT
#SBATCH --time=04:00:00

set -xEeuo pipefail
export jobWorkspace=$WORKSPACE/disagg_workspace
export llmSrcNode=$TRTLLM_DIR
export stageName="disagg_perf_test"
export perfMode=true
export pytestCommand="pytest perf/test_perf_sanity.py::test_e2e[disagg_upload-${CONFIG_NAME}] -vv --junit-xml=$WORKSPACE/results.xml"
EOF
```

---

### 9. `--srun-args` (å¿…éœ€ï¼ŒCI æ¨¡å¼)

**ç±»åž‹ï¼š** å­—ç¬¦ä¸²ï¼ˆæ–‡ä»¶è·¯å¾„ï¼‰
**ä½œç”¨ï¼š** åŒ…å« srun å‘½ä»¤è¡Œå‚æ•°çš„æ–‡ä»¶

**ä»£ç ä½ç½®ï¼š** submit.py ç¬¬ 191-194 è¡Œ

```python
parser.add_argument(
    "--srun-args",
    default="",
    help="Path to file containing srun args (optional, CI mode only)",
)
```

**åœ¨ submit.py ä¸­çš„ä½¿ç”¨ï¼š** ç¬¬ 223-226 è¡Œ

```python
with open(args.srun_args, "r") as f:
    srun_args_content = f.read()

srun_args_lines = srun_args_content.split()  # â† æŒ‰ç©ºæ ¼åˆ†å‰²
```

**æ–‡ä»¶å†…å®¹ç¤ºä¾‹ï¼š** ï¼ˆL0_Test.groovy ç¬¬ 1137-1146 è¡Œç”Ÿæˆï¼‰

```
--container-name=multi_node_test-${SLURM_JOB_ID}
--container-image=/path/to/container.sqsh
--container-workdir=/home/svc_tensorrt/bloom/scripts/{job_uid}
--container-mounts=/lustre/fsw:/lustre/fsw,/home:/home
--container-env=NVIDIA_IMEX_CHANNELS
--container-env=OPEN_SEARCH_DB_BASE_URL
--container-env=BUILD_ID
--container-env=BUILD_URL
--mpi=pmix
```

**submit.py ä¼šæ·»åŠ é¢å¤–å‚æ•°ï¼š** ç¬¬ 269-274 è¡Œ

```python
srun_args_lines.extend([
    "--container-env=DISAGG_SERVING_TYPE",  # â† disagg ç‰¹æœ‰
    "--container-env=pytestCommand",        # â† disagg ç‰¹æœ‰
])
```

**L0 å¦‚ä½•ç”Ÿæˆï¼š**

```groovy
// L0_Test.groovy ç¬¬ 1200 è¡Œ
def scriptLaunchSrunArgsPathLocal = Utils.createTempLocation(pipeline, "./slurm_srun_args.txt")
// ç¬¬ 1205 è¡Œ
pipeline.writeFile(file: scriptLaunchSrunArgsPathLocal, text: srunArgs.join(" "))
```

**Jenkins åº”è¯¥æ€Žä¹ˆåšï¼š**

```bash
# ç”Ÿæˆ srun args æ–‡ä»¶
SRUN_ARGS_FILE="$WORKSPACE/slurm_srun_args.txt"
cat > "$SRUN_ARGS_FILE" << EOF
--container-name=disagg_test_\${SLURM_JOB_ID}
--container-image=${DOCKER_IMAGE}
--container-workdir=${WORKSPACE}/disagg_workspace
--container-mounts=${CLUSTER_LLM_DATA}:/data
--mpi=pmix
EOF
```

---

## ðŸ”„ submit.py çš„å·¥ä½œæµç¨‹

### è¾“å…¥å¤„ç†ï¼ˆç¬¬ 197-215 è¡Œï¼‰

```python
args = parser.parse_args()

# 1. ä»Ž test-list æå–é…ç½®æ–‡ä»¶è·¯å¾„
config_yaml = get_config_yaml(args.test_list, args.llm_src)

# 2. è¯»å–é…ç½®æ–‡ä»¶
with open(config_yaml, "r") as f:
    config = yaml.safe_load(f)

# 3. è§£æžé…ç½®
env_config = get_env_config(config)           # environment éƒ¨åˆ†
benchmark_config = get_benchmark_config(config)  # benchmark éƒ¨åˆ†
hardware_config = get_hardware_config(config, benchmark_mode)  # hardware + worker_config
```

### è¯»å–è¾“å…¥æ–‡ä»¶ï¼ˆç¬¬ 217-226 è¡Œï¼‰

```python
script_prefix_lines = []
srun_args_lines = []

# è¯»å– script prefix æ–‡ä»¶
with open(args.script_prefix, "r") as f:
    script_prefix_content = f.read()
script_prefix_lines = script_prefix_content.split("\n")

# è¯»å– srun args æ–‡ä»¶
with open(args.srun_args, "r") as f:
    srun_args_content = f.read()
srun_args_lines = srun_args_content.split()
```

### å¤„ç† pytest å‘½ä»¤ï¼ˆç¬¬ 228-229 è¡Œï¼‰

```python
# ä»Ž script_prefix_lines ä¸­æå– pytestCommand
# ç”Ÿæˆ pytestCommandNoLLMAPILaunchï¼ˆåŽ»æŽ‰ trtllm-llmapi-launchï¼‰
pytest_command_no_llmapi_launch = get_pytest_command_no_llmapilaunch(script_prefix_lines)
```

### æ·»åŠ çŽ¯å¢ƒå˜é‡ï¼ˆç¬¬ 231-263 è¡Œï¼‰

```python
# æž„å»º worker çŽ¯å¢ƒå˜é‡
worker_env_vars = env_config["worker_env_var"]
server_env_vars = env_config["server_env_var"]

# å¦‚æžœæ˜¯ gen_only æ¨¡å¼ï¼Œæ·»åŠ é¢å¤–çŽ¯å¢ƒå˜é‡
if "gen_only" in benchmark_config["mode"]:
    worker_env_vars = f"TRTLLM_DISAGG_BENCHMARK_GEN_ONLY=1 ... {worker_env_vars}"
    server_env_vars = f"TRTLLM_DISAGG_BENCHMARK_GEN_ONLY=1 {server_env_vars}"

# æ·»åŠ åˆ° script_prefix_lines
script_prefix_lines.extend([
    pytest_command_no_llmapi_launch,
    f'export pytestCommandWorker="unset UCX_TLS && {worker_env_vars} $pytestCommand"',
    f'export pytestCommandDisaggServer="{server_env_var} $pytestCommandNoLLMAPILaunch"',
    f'export pytestCommandBenchmark="{env_config["benchmark_env_var"]} $pytestCommandNoLLMAPILaunch"',
    f"export runScript={args.run_sh}",
    f"export installScript={install_script}",
    f"export numCtxServers={hardware_config['num_ctx_servers']}",
    f"export numGenServers={hardware_config['num_gen_servers']}",
    f"export gpusPerNode={hardware_config['gpus_per_node']}",
    f"export gpusPerCtxServer={hardware_config['gpus_per_ctx_server']}",
    f"export gpusPerGenServer={hardware_config['gpus_per_gen_server']}",
    f"export nodesPerCtxServer={hardware_config['nodes_per_ctx_server']}",
    f"export nodesPerGenServer={hardware_config['nodes_per_gen_server']}",
    f"export totalNodes={hardware_config['total_nodes']}",
    f"export totalGpus={hardware_config['total_gpus']}",
])
```

### æ·»åŠ  srun å‚æ•°ï¼ˆç¬¬ 268-276 è¡Œï¼‰

```python
srun_args_lines.extend([
    "--container-env=DISAGG_SERVING_TYPE",
    "--container-env=pytestCommand",
])

# æ ¼å¼åŒ–ä¸º bash æ•°ç»„
srun_args_lines = ["srunArgs=("] + [f'  "{line}"' for line in srun_args_lines] + [")"]
srun_args = "\n".join(srun_args_lines)
```

### è¯»å–æ¨¡æ¿å¹¶ç”Ÿæˆæœ€ç»ˆè„šæœ¬ï¼ˆç¬¬ 278-288 è¡Œï¼‰

```python
# è¯»å– draft-launch.sh
with open(args.draft_launch_sh, "r") as f:
    draft_launch_content = f.read()

# ç»„åˆï¼šscript_prefix + srun_args + draft_launch_content
with open(args.launch_sh, "w") as f:
    f.write(f"{script_prefix}\n{srun_args}\n{draft_launch_content}")

print(f"Launch script generated at: {args.launch_sh}")
print(f"Launch script:\n{script_prefix}\n{srun_args}\n{draft_launch_content}")
```

---

## ðŸ“ Jenkins run_disagg_test.sh ä¿®æ­£æ–¹æ¡ˆ

### å½“å‰é—®é¢˜

```bash
# jenkins_test/scripts/run_disagg_test.sh ç¬¬ 287-293 è¡Œ
python3 $SUBMIT_PY \
    --run-ci \
    --llm-src $TRTLLM_DIR \
    --config $CONFIG_FULL_PATH    # âŒ é”™è¯¯ï¼
```

**ç¼ºå°‘çš„å‚æ•°ï¼š**
- `--test-list` âŒ
- `--draft-launch-sh` âŒ
- `--launch-sh` âŒ
- `--run-sh` âŒ
- `--install-sh` âŒ
- `--script-prefix` âŒ
- `--srun-args` âŒ

### å®Œæ•´ä¿®æ­£ç‰ˆæœ¬

```bash
#!/bin/bash
# jenkins_test/scripts/run_disagg_test.sh

# ... å‰é¢çš„ä»£ç ä¿æŒä¸å˜ ...

# ============================================
# æ­¥éª¤ 4: å‡†å¤‡ submit.py æ‰€éœ€çš„è¾“å…¥æ–‡ä»¶
# ============================================
echo ""
echo "[æ­¥éª¤ 4] å‡†å¤‡ submit.py è¾“å…¥æ–‡ä»¶..."

# 4.1 åˆ›å»º test list æ–‡ä»¶
TEST_LIST_FILE="$WORKSPACE/test_list_disagg.txt"
cat > "$TEST_LIST_FILE" << EOF
perf/test_perf_sanity.py::test_e2e[disagg_upload-${CONFIG_NAME}]
EOF
echo "âœ“ ç”Ÿæˆ test list: $TEST_LIST_FILE"

# 4.2 åˆ›å»º script prefix æ–‡ä»¶ï¼ˆåŒ…å« SBATCH æŒ‡ä»¤å’ŒçŽ¯å¢ƒå˜é‡ï¼‰
SCRIPT_PREFIX_FILE="$WORKSPACE/slurm_launch_prefix.sh"
cat > "$SCRIPT_PREFIX_FILE" << EOFPREFIX
#!/bin/bash
#SBATCH --output=$WORKSPACE/slurm_%j.log
#SBATCH --nodes=$TOTAL_NODES
#SBATCH --ntasks=$TOTAL_GPUS
#SBATCH --ntasks-per-node=$GPUS_PER_NODE
#SBATCH --gpus-per-node=$GPUS_PER_NODE
#SBATCH --partition=$CLUSTER_PARTITION
#SBATCH --account=$CLUSTER_ACCOUNT
#SBATCH --job-name=disagg_perf_test
#SBATCH --time=04:00:00

set -xEeuo pipefail
trap 'rc=\$?; echo "Error in file \${BASH_SOURCE[0]} on line \$LINENO: \$BASH_COMMAND (exit \$rc)"; exit \$rc' ERR

echo "Starting Slurm job \$SLURM_JOB_ID on \$SLURM_NODELIST"
export jobWorkspace=$WORKSPACE/disagg_workspace
export llmSrcNode=$TRTLLM_DIR
export stageName="disagg_perf_test"
export perfMode=true
export resourcePathNode=$TRTLLM_DIR
export pytestCommand="pytest perf/test_perf_sanity.py::test_e2e[disagg_upload-${CONFIG_NAME}] -vv --junit-xml=$WORKSPACE/results.xml"
export coverageConfigFile=$WORKSPACE/coverage_config.json
export NVIDIA_IMEX_CHANNELS=\${NVIDIA_IMEX_CHANNELS:-0}
export NVIDIA_VISIBLE_DEVICES=\${NVIDIA_VISIBLE_DEVICES:-\$(seq -s, 0 \$((\$(nvidia-smi --query-gpu=count -i 0 --format=csv,noheader)-1)))}
EOFPREFIX
echo "âœ“ ç”Ÿæˆ script prefix: $SCRIPT_PREFIX_FILE"

# 4.3 åˆ›å»º srun args æ–‡ä»¶
SRUN_ARGS_FILE="$WORKSPACE/slurm_srun_args.txt"
cat > "$SRUN_ARGS_FILE" << EOFSRUN
--container-name=disagg_test_\${SLURM_JOB_ID}
--container-image=${DOCKER_IMAGE}
--container-workdir=$WORKSPACE/disagg_workspace
--container-mounts=${CLUSTER_LLM_DATA}:/data,${TRTLLM_DIR}:${TRTLLM_DIR}
--mpi=pmix
EOFSRUN
echo "âœ“ ç”Ÿæˆ srun args: $SRUN_ARGS_FILE"

# 4.4 å‡†å¤‡å…¶ä»–æ–‡ä»¶è·¯å¾„
DRAFT_LAUNCH_SH="$TRTLLM_DIR/jenkins/scripts/perf/disaggregated/slurm_launch_draft.sh"
LAUNCH_SH="$WORKSPACE/slurm_launch_generated.sh"
RUN_SH="$TRTLLM_DIR/jenkins/scripts/slurm_run.sh"
INSTALL_SH="$TRTLLM_DIR/jenkins/scripts/slurm_install.sh"

# éªŒè¯æ–‡ä»¶å­˜åœ¨
for file in "$DRAFT_LAUNCH_SH" "$RUN_SH" "$INSTALL_SH"; do
    if [[ ! -f "$file" ]]; then
        echo "é”™è¯¯ï¼šæ‰¾ä¸åˆ°æ–‡ä»¶: $file"
        exit 1
    fi
done

echo "âœ“ æ‰€æœ‰è¾“å…¥æ–‡ä»¶å‡†å¤‡å®Œæˆ"

# ============================================
# æ­¥éª¤ 5: è°ƒç”¨ submit.py ç”Ÿæˆ launch è„šæœ¬
# ============================================
echo ""
echo "[æ­¥éª¤ 5] è°ƒç”¨ submit.py ç”Ÿæˆ launch è„šæœ¬..."

SUBMIT_PY="$TRTLLM_DIR/jenkins/scripts/perf/disaggregated/submit.py"

if [[ ! -f "$SUBMIT_PY" ]]; then
    echo "é”™è¯¯ï¼šæ‰¾ä¸åˆ° submit.py: $SUBMIT_PY"
    exit 1
fi

python3 "$SUBMIT_PY" \
    --run-ci \
    --llm-src "$TRTLLM_DIR" \
    --test-list "$TEST_LIST_FILE" \
    --draft-launch-sh "$DRAFT_LAUNCH_SH" \
    --launch-sh "$LAUNCH_SH" \
    --run-sh "$RUN_SH" \
    --install-sh "$INSTALL_SH" \
    --script-prefix "$SCRIPT_PREFIX_FILE" \
    --srun-args "$SRUN_ARGS_FILE"

if [[ ! -f "$LAUNCH_SH" ]]; then
    echo "é”™è¯¯ï¼šsubmit.py æœªç”Ÿæˆ launch è„šæœ¬: $LAUNCH_SH"
    exit 1
fi

echo "âœ“ Launch è„šæœ¬å·²ç”Ÿæˆ: $LAUNCH_SH"
echo ""
echo "ç”Ÿæˆçš„è„šæœ¬å†…å®¹ï¼š"
echo "----------------------------------------"
cat "$LAUNCH_SH"
echo "----------------------------------------"

# ============================================
# æ­¥éª¤ 6: æäº¤ä½œä¸š
# ============================================
if [[ "$DRY_RUN" == "true" ]]; then
    echo ""
    echo "[è¯•è¿è¡Œæ¨¡å¼] è·³è¿‡å®žé™…æäº¤"
    echo "è¦æ‰‹åŠ¨æäº¤ï¼Œè¯·è¿è¡Œ:"
    echo "  sbatch $LAUNCH_SH"
    exit 0
fi

echo ""
echo "[æ­¥éª¤ 6] æäº¤ Slurm ä½œä¸š..."

SUBMIT_OUTPUT=$(sbatch "$LAUNCH_SH")
echo "$SUBMIT_OUTPUT"

JOB_ID=$(echo "$SUBMIT_OUTPUT" | awk '{print $NF}')

if [[ -z "$JOB_ID" ]]; then
    echo "é”™è¯¯ï¼šæ— æ³•èŽ·å–ä½œä¸š ID"
    exit 1
fi

echo "Slurm Job ID: $JOB_ID"
LOG_FILE="$WORKSPACE/slurm_${JOB_ID}.log"
echo "æ—¥å¿—æ–‡ä»¶: $LOG_FILE"

# ... åŽç»­ç­‰å¾…ä½œä¸šå®Œæˆçš„é€»è¾‘ä¿æŒä¸å˜ ...
```

---

## ðŸŽ¯ å…³é”®è¦ç‚¹æ€»ç»“

### 1. submit.py ä¸æ‰§è¡Œæµ‹è¯•

**å®ƒåªç”Ÿæˆè„šæœ¬ï¼** ç”Ÿæˆçš„ `launch.sh` éœ€è¦é€šè¿‡ `sbatch` æäº¤ã€‚

### 2. æ‰€æœ‰å‚æ•°éƒ½æ˜¯å¿…éœ€çš„

**æ²¡æœ‰å¯é€‰å‚æ•°ï¼** é™¤äº† `--config-yaml` å’Œ `--stage-name`ï¼ˆlocal æ¨¡å¼ç”¨ï¼‰ï¼Œå…¶ä»–å…¨éƒ¨å¿…éœ€ã€‚

### 3. å‚æ•°çš„èŒè´£åˆ’åˆ†

| å‚æ•° | èŒè´£ | æ¥æº |
|------|------|------|
| `--test-list` | æä¾› pytest å‘½ä»¤å’Œé…ç½®å | Jenkins ç”Ÿæˆ |
| `--script-prefix` | æä¾› SBATCH æŒ‡ä»¤å’ŒçŽ¯å¢ƒå˜é‡ | Jenkins ç”Ÿæˆ |
| `--srun-args` | æä¾›å®¹å™¨å’Œ MPI å‚æ•° | Jenkins ç”Ÿæˆ |
| `--draft-launch-sh` | æä¾›å¯åŠ¨é€»è¾‘æ¨¡æ¿ | TensorRT-LLM ä»“åº“ |
| `--run-sh` / `--install-sh` | æä¾›æ‰§è¡Œè„šæœ¬ | TensorRT-LLM ä»“åº“ |
| `--llm-src` | æŸ¥æ‰¾é…ç½®æ–‡ä»¶ | Jenkins ä¼ é€’ |
| `--launch-sh` | è¾“å‡ºæ–‡ä»¶è·¯å¾„ | Jenkins æŒ‡å®š |

### 4. YAML é…ç½®æ–‡ä»¶çš„ä½œç”¨

**submit.py ä»Ž YAML è¯»å–ï¼š**
- `hardware` â†’ è®¡ç®—èŠ‚ç‚¹æ•°
- `worker_config` â†’ è®¡ç®—æ¯ä¸ª server çš„ GPU æ•°
- `environment.worker_env_var` â†’ æ·»åŠ åˆ° pytestCommandWorker
- `environment.server_env_var` â†’ æ·»åŠ åˆ° pytestCommandDisaggServer
- `benchmark.mode` â†’ åˆ¤æ–­æ˜¯å¦ gen_only æ¨¡å¼

**YAML å ä½ç¬¦ä¸éœ€è¦ï¼š**
- `container_image` âŒ (ä»Ž srun-args æä¾›)
- `container_mount` âŒ (ä»Ž srun-args æä¾›)
- `model_path` âŒ (test_perf_sanity.py ç¡¬ç¼–ç )
- `work_dir` âŒ (ä»Ž script-prefix çš„ jobWorkspace æä¾›)

### 5. ä¸Ž L0 ä¿æŒä¸€è‡´

**L0 çš„æ–¹å¼ï¼š**
1. âœ… ä½¿ç”¨ `test_perf_sanity.py`
2. âœ… é€šè¿‡ `submit.py` ç”Ÿæˆ launch è„šæœ¬
3. âœ… æ‰€æœ‰çŽ¯å¢ƒå˜é‡åœ¨ script-prefix ä¸­å®šä¹‰
4. âœ… æ‰€æœ‰ srun å‚æ•°åœ¨ srun-args æ–‡ä»¶ä¸­å®šä¹‰
5. âœ… ä½¿ç”¨ sbatch æäº¤ç”Ÿæˆçš„è„šæœ¬

**ä½ çš„ Jenkins ä¹Ÿåº”è¯¥ï¼š**
1. âœ… ç»§ç»­ä½¿ç”¨ `test_perf_sanity.py`
2. âœ… ç”Ÿæˆæ‰€æœ‰å¿…éœ€çš„è¾“å…¥æ–‡ä»¶
3. âœ… è°ƒç”¨ `submit.py` ç”Ÿæˆ launch è„šæœ¬
4. âœ… é€šè¿‡ sbatch æäº¤ç”Ÿæˆçš„è„šæœ¬

---

## âœ… æ£€æŸ¥æ¸…å•

åœ¨è¿è¡Œä¿®æ­£çš„è„šæœ¬å‰ï¼Œç¡®è®¤ï¼š

- [ ] `TRTLLM_DIR` æŒ‡å‘æ­£ç¡®çš„ TensorRT-LLM æ ¹ç›®å½•
- [ ] `CLUSTER_PARTITION` å’Œ `CLUSTER_ACCOUNT` å·²è®¾ç½®
- [ ] `DOCKER_IMAGE` å·²è®¾ç½®
- [ ] `CLUSTER_LLM_DATA` å·²è®¾ç½®ï¼ˆæ¨¡åž‹å’Œæ•°æ®è·¯å¾„ï¼‰
- [ ] `CONFIG_NAME` æ­£ç¡®ï¼ˆé…ç½®æ–‡ä»¶åï¼Œä¸å¸¦ `.yaml` åŽç¼€ï¼‰
- [ ] `WORKSPACE` ç›®å½•å­˜åœ¨ä¸”å¯å†™
- [ ] æ‰€æœ‰ TensorRT-LLM ä»“åº“ä¸­çš„è„šæœ¬æ–‡ä»¶å­˜åœ¨ï¼š
  - `jenkins/scripts/perf/disaggregated/slurm_launch_draft.sh`
  - `jenkins/scripts/slurm_run.sh`
  - `jenkins/scripts/slurm_install.sh`
  - `jenkins/scripts/perf/disaggregated/submit.py`

---

**çŽ°åœ¨å‚æ•°æ¸…æ¥šäº†å—ï¼Ÿéœ€è¦æˆ‘å¸®ä½ ä¿®æ”¹ `run_disagg_test.sh` æ–‡ä»¶å—ï¼Ÿ** ðŸš€
