# Disagg è°ƒç”¨é“¾æ¡è¯¦ç»†ä»£ç å‚è€ƒ

> æœ¬æ–‡æ¡£æä¾›å®Œæ•´çš„ä»£ç è·¯å¾„ã€è¡Œå·å’Œå…³é”®ä»£ç ç‰‡æ®µï¼Œæ–¹ä¾¿è¿½è¸ªå’ŒéªŒè¯è°ƒç”¨é“¾æ¡

---

## ğŸ“‹ å®Œæ•´è°ƒç”¨é“¾æ¡ï¼ˆå¸¦ä»£ç ä½ç½®ï¼‰

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. Jenkins Pipeline                                               â”‚
â”‚    æ–‡ä»¶: jenkins_test/Perf_Test.groovy                           â”‚
â”‚    è¡Œå·: ~300-350                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. run_perf_tests.sh                                              â”‚
â”‚    æ–‡ä»¶: jenkins_test/scripts/run_perf_tests.sh                  â”‚
â”‚    è¡Œå·: 324-371 (run_disagg_tests å‡½æ•°)                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. run_disagg_test.sh                                             â”‚
â”‚    æ–‡ä»¶: jenkins_test/scripts/run_disagg_test.sh                 â”‚
â”‚    è¡Œå·: å…¨æ–‡ (å…³é”®è¡Œåœ¨ä¸‹æ–¹è¯¦è¿°)                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. submit.py (ç¯å¢ƒå˜é‡ç”Ÿæˆå™¨)                                     â”‚
â”‚    æ–‡ä»¶: jenkins/scripts/perf/disaggregated/submit.py            â”‚
â”‚    è¡Œå·: 292è¡Œå®Œæ•´æ–‡ä»¶ (å…³é”®å‡½æ•°åœ¨ä¸‹æ–¹è¯¦è¿°)                       â”‚
â”‚    åŠŸèƒ½: ç”Ÿæˆ slurm_launch_draft.sh éœ€è¦çš„ç¯å¢ƒå˜é‡å’Œ launch.sh   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 5. slurm_launch_draft.sh (çœŸæ­£çš„å¯åŠ¨å™¨)                           â”‚
â”‚    æ–‡ä»¶: jenkins/scripts/perf/disaggregated/slurm_launch_draft.shâ”‚
â”‚    è¡Œå·: 77è¡Œå®Œæ•´æ–‡ä»¶                                             â”‚
â”‚    åŠŸèƒ½: ä½¿ç”¨ srun å¯åŠ¨æ‰€æœ‰ CTX/GEN servers å’Œ benchmark          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 6. test_perf_sanity.py                                            â”‚
â”‚    æ–‡ä»¶: tests/integration/defs/perf/test_perf_sanity.py         â”‚
â”‚    è¡Œå·: 1490-1521 (test_e2e å‡½æ•°)                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## âš ï¸ é‡è¦æ›´æ–°è¯´æ˜

åœ¨ä¹‹å‰çš„åˆ†æä¸­ï¼Œæˆ‘é”™è¯¯åœ°æè¿°äº† `jenkins/scripts/perf/disaggregated/submit.py` çš„åŠŸèƒ½ã€‚è¯¥æ–‡ä»¶æ˜¯ä¸€ä¸ª**ç¯å¢ƒå˜é‡ç”Ÿæˆå™¨**ï¼ˆ292è¡Œï¼‰ï¼Œè€Œä¸æ˜¯å®Œæ•´çš„ SLURM job æäº¤å™¨ï¼ˆ594è¡Œï¼‰ã€‚ä»¥ä¸‹æ˜¯ä¿®æ­£åçš„åˆ†æã€‚

---

## ğŸ” è¯¦ç»†ä»£ç è¿½è¸ª

### 1. Jenkins Pipeline å…¥å£

**æ–‡ä»¶ï¼š** `jenkins_test/Perf_Test.groovy`

**å…³é”®ä»£ç æ®µï¼ˆç¬¬274è¡Œé™„è¿‘ï¼‰ï¼š**

```groovy
stage('Run Disagg Tests') {
    steps {
        script {
            sh """
                cd ${WORKSPACE}
                ${SCRIPTS_DIR}/run_perf_tests.sh \\
                    --testlist ${TESTLIST_PATH} \\
                    --trtllm-dir ${TRTLLM_DIR} \\
                    --mode disagg
            """
        }
    }
}
```

**éªŒè¯ç‚¹ï¼š**
- [ ] æ£€æŸ¥ `SCRIPTS_DIR` å˜é‡æ˜¯å¦æ­£ç¡®æŒ‡å‘ `jenkins_test/scripts`
- [ ] æ£€æŸ¥ `run_perf_tests.sh` æ–‡ä»¶æ˜¯å¦å­˜åœ¨
- [ ] æ£€æŸ¥ä¼ é€’çš„å‚æ•°æ˜¯å¦å®Œæ•´

---

### 2. run_perf_tests.sh - æµ‹è¯•åˆ†å‘å™¨

**æ–‡ä»¶ï¼š** `jenkins_test/scripts/run_perf_tests.sh`

#### 2.1 Disagg æµ‹è¯•åˆ†å‘å‡½æ•°

**ä»£ç ä½ç½®ï¼š** ç¬¬ 324-371 è¡Œ

```bash
# å‡½æ•°ï¼šæ‰§è¡Œ Disagg æµ‹è¯•
run_disagg_tests() {
    if [[ $DISAGG_COUNT -eq 0 ]]; then
        echo "âŠ˜ æ²¡æœ‰ Disagg æµ‹è¯•"
        return 0
    fi
    
    echo ""
    echo "========================================"
    echo "è¿è¡Œ Disagg æµ‹è¯• ($DISAGG_COUNT ä¸ª)"
    echo "========================================"
    
    for i in $(seq 0 $((DISAGG_COUNT - 1))); do
        local test_info=$(echo "$DISAGG_TESTS" | python3 -c "import sys, json; print(json.dumps(json.load(sys.stdin)[$i]))")
        local config_file=$(echo "$test_info" | python3 -c "import sys, json; print(json.load(sys.stdin)['config_file'])")
        
        echo ""
        echo "----------------------------------------"
        echo "[Disagg $((i + 1))/$DISAGG_COUNT] $config_file"
        echo "----------------------------------------"
        
        local script_args=()
        script_args+=("--trtllm-dir" "$TRTLLM_DIR")
        script_args+=("--config-file" "$config_file")
        script_args+=("--workspace" "${WORKSPACE:-$(pwd)}/disagg_workspace")
        
        # æ³¨æ„ï¼šdisagg æ¨¡å¼ä¸æ”¯æŒ pytest -k è¿‡æ»¤
        
        if [[ "$DRY_RUN" == "true" ]]; then
            script_args+=("--dry-run")
        fi
        
        if "$SCRIPT_DIR/run_disagg_test.sh" "${script_args[@]}"; then  # â† ç¬¬355è¡Œï¼šè°ƒç”¨ run_disagg_test.sh
            ((PASSED_TESTS++))
            echo "âœ“ æµ‹è¯•é€šè¿‡"
        else
            ((FAILED_TESTS++))
            FAILED_LIST+=("Disagg: $config_file")
            echo "âœ— æµ‹è¯•å¤±è´¥"
            
            if [[ "$STOP_ON_ERROR" == "true" ]]; then
                echo "é‡åˆ°é”™è¯¯ï¼Œåœæ­¢æ‰§è¡Œ"
                return 1
            fi
        fi
    done
    
    return 0
}
```

**å…³é”®è°ƒç”¨ï¼š** ç¬¬ 355 è¡Œ
```bash
"$SCRIPT_DIR/run_disagg_test.sh" "${script_args[@]}"
```

**éªŒè¯ç‚¹ï¼š**
- [ ] æ£€æŸ¥ `DISAGG_TESTS` JSON æ ¼å¼æ˜¯å¦æ­£ç¡®
- [ ] æ£€æŸ¥ `config_file` æ˜¯å¦æ˜¯æœ‰æ•ˆçš„é…ç½®æ–‡ä»¶å
- [ ] æ£€æŸ¥ `WORKSPACE` å˜é‡æ˜¯å¦è®¾ç½®

---

### 3. run_disagg_test.sh - SLURM ä½œä¸šæäº¤å™¨

**æ–‡ä»¶ï¼š** `jenkins_test/scripts/run_disagg_test.sh`

#### 3.1 æå–é…ç½®æ–‡ä»¶å®Œæ•´è·¯å¾„

**ä»£ç ä½ç½®ï¼š** ç¬¬ 180-204 è¡Œ

```bash
# ============================================
# æ­¥éª¤ 2: æŸ¥æ‰¾é…ç½®æ–‡ä»¶å®Œæ•´è·¯å¾„
# ============================================
echo ""
echo "[æ­¥éª¤ 2] æŸ¥æ‰¾é…ç½®æ–‡ä»¶..."

CONFIG_FULL_PATH=""
for path in \
    "$TRTLLM_DIR/tests/integration/defs/perf/disagg/test_configs/disagg/perf/${CONFIG_NAME}.yaml" \
    "$TRTLLM_DIR/tests/integration/defs/perf/disagg/test_configs/wideep/perf/${CONFIG_NAME}.yaml"; do
    if [[ -f "$path" ]]; then
        CONFIG_FULL_PATH="$path"
        break
    fi
done

if [[ -z "$CONFIG_FULL_PATH" ]]; then
    echo "é”™è¯¯ï¼šæ‰¾ä¸åˆ°é…ç½®æ–‡ä»¶: ${CONFIG_NAME}.yaml"
    echo "æŸ¥æ‰¾è·¯å¾„:"
    echo "  - $TRTLLM_DIR/tests/integration/defs/perf/disagg/test_configs/disagg/perf/"
    echo "  - $TRTLLM_DIR/tests/integration/defs/perf/disagg/test_configs/wideep/perf/"
    exit 1
fi

echo "æ‰¾åˆ°é…ç½®æ–‡ä»¶: $CONFIG_FULL_PATH"
```

**éªŒè¯ç‚¹ï¼š**
- [ ] æ£€æŸ¥é…ç½®æ–‡ä»¶è·¯å¾„æ˜¯å¦å­˜åœ¨
- [ ] æ£€æŸ¥ `CONFIG_NAME` æ˜¯å¦æ­£ç¡®è§£æ

#### 3.2 è®¡ç®—ç¡¬ä»¶èŠ‚ç‚¹æ•°

**ä»£ç ä½ç½®ï¼š** ç¬¬ 206-240 è¡Œ

```bash
# ============================================
# æ­¥éª¤ 3: è®¡ç®—ç¡¬ä»¶èŠ‚ç‚¹æ•°
# ============================================
echo ""
echo "[æ­¥éª¤ 3] è®¡ç®—ç¡¬ä»¶èŠ‚ç‚¹æ•°..."

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
CALC_SCRIPT="$SCRIPT_DIR/calculate_hardware_nodes.py"

if [[ ! -f "$CALC_SCRIPT" ]]; then
    echo "é”™è¯¯ï¼šæ‰¾ä¸åˆ° calculate_hardware_nodes.py"
    exit 1
fi

NODE_INFO_JSON="$WORKSPACE/node_info.json"
python3 "$CALC_SCRIPT" --config "$CONFIG_FULL_PATH" --json > "$NODE_INFO_JSON"

# è¯»å–èŠ‚ç‚¹ä¿¡æ¯
TOTAL_NODES=$(python3 -c "import json; print(json.load(open('$NODE_INFO_JSON'))['total_nodes'])")
TOTAL_GPUS=$(python3 -c "import json; print(json.load(open('$NODE_INFO_JSON'))['total_gpus'])")
GPUS_PER_NODE=$(python3 -c "import json; print(json.load(open('$NODE_INFO_JSON'))['gpus_per_node'])")
NUM_CTX_SERVERS=$(python3 -c "import json; print(json.load(open('$NODE_INFO_JSON')).get('num_ctx_servers', 0))")
NUM_GEN_SERVERS=$(python3 -c "import json; print(json.load(open('$NODE_INFO_JSON'))['num_gen_servers'])")
CTX_NODES=$(python3 -c "import json; print(json.load(open('$NODE_INFO_JSON')).get('ctx_nodes', 0))")
GEN_NODES=$(python3 -c "import json; print(json.load(open('$NODE_INFO_JSON'))['gen_nodes'])")

echo "èŠ‚ç‚¹è®¡ç®—ç»“æœ:"
echo "  é€»è¾‘ CTX servers: $NUM_CTX_SERVERS"
echo "  é€»è¾‘ GEN servers: $NUM_GEN_SERVERS"
echo "  ç¡¬ä»¶ CTX nodes: $CTX_NODES"
echo "  ç¡¬ä»¶ GEN nodes: $GEN_NODES"
echo "  æ€»ç¡¬ä»¶èŠ‚ç‚¹: $TOTAL_NODES"
echo "  æ€» GPU æ•°: $TOTAL_GPUS"
echo "  æ¯èŠ‚ç‚¹ GPU æ•°: $GPUS_PER_NODE"
```

**éªŒè¯ç‚¹ï¼š**
- [ ] æ£€æŸ¥ `calculate_hardware_nodes.py` æ˜¯å¦å­˜åœ¨
- [ ] æ£€æŸ¥è®¡ç®—ç»“æœæ˜¯å¦åˆç†ï¼ˆèŠ‚ç‚¹æ•°ã€GPUæ•°ï¼‰

#### 3.3 ç”Ÿæˆ sbatch è„šæœ¬

**ä»£ç ä½ç½®ï¼š** ç¬¬ 242-310 è¡Œ

```bash
# ============================================
# æ­¥éª¤ 4: ç”Ÿæˆ sbatch è„šæœ¬
# ============================================
echo ""
echo "[æ­¥éª¤ 4] ç”Ÿæˆ sbatch è„šæœ¬..."

SBATCH_SCRIPT="$WORKSPACE/sbatch_disagg.sh"
SUBMIT_PY="$TRTLLM_DIR/jenkins/scripts/perf/disaggregated/submit.py"

if [[ ! -f "$SUBMIT_PY" ]]; then
    echo "é”™è¯¯ï¼šæ‰¾ä¸åˆ° submit.py: $SUBMIT_PY"
    exit 1
fi

# ä»ç¯å¢ƒå˜é‡è·å– cluster é…ç½®ï¼ˆç”± Jenkins è®¾ç½®ï¼‰
CLUSTER_ACCOUNT="${CLUSTER_ACCOUNT:-coreai_comparch_trtllm}"
CLUSTER_PARTITION="${CLUSTER_PARTITION:-batch}"
MPI_TYPE="${MPI_TYPE:-pmix}"
DOCKER_IMAGE="${DOCKER_IMAGE:-nvcr.io/nvidia/tensorrt-llm:latest}"

cat > "$SBATCH_SCRIPT" << EOFSBATCH
#!/bin/bash
#SBATCH --nodes=$TOTAL_NODES
#SBATCH --ntasks=$TOTAL_GPUS
#SBATCH --ntasks-per-node=$GPUS_PER_NODE
#SBATCH --gpus-per-node=$GPUS_PER_NODE
#SBATCH --partition=$CLUSTER_PARTITION
#SBATCH --account=$CLUSTER_ACCOUNT
#SBATCH --output=$WORKSPACE/slurm_%j.log
#SBATCH --error=$WORKSPACE/slurm_%j.log
#SBATCH --job-name=disagg_perf_test

set -xEeuo pipefail

echo "=========================================="
echo "Slurm Job ID: \$SLURM_JOB_ID"
echo "Slurm Nodelist: \$SLURM_NODELIST"
echo "Total Nodes: $TOTAL_NODES"
echo "Total GPUs: $TOTAL_GPUS"
echo "GPUs per Node: $GPUS_PER_NODE"
echo "Partition: $CLUSTER_PARTITION"
echo "Account: $CLUSTER_ACCOUNT"
echo "=========================================="

cd $TRTLLM_DIR

# è°ƒç”¨ submit.py æ‰§è¡Œ disagg æµ‹è¯•
# æ³¨æ„ï¼šsubmit.py ä¼šå¤„ç†æ‰€æœ‰çš„ disagg é€»è¾‘
python3 $SUBMIT_PY \\
    --run-ci \\
    --llm-src $TRTLLM_DIR \\
    --config $CONFIG_FULL_PATH

exit_code=\$?

echo "=========================================="
echo "Test completed with exit code: \$exit_code"
echo "=========================================="

exit \$exit_code
EOFSBATCH

chmod +x "$SBATCH_SCRIPT"
```

**å…³é”®è°ƒç”¨ï¼š** ç¬¬ 289-292 è¡Œ
```bash
python3 $SUBMIT_PY \
    --run-ci \
    --llm-src $TRTLLM_DIR \
    --config $CONFIG_FULL_PATH
```

**éªŒè¯ç‚¹ï¼š**
- [ ] æ£€æŸ¥ `SUBMIT_PY` è·¯å¾„æ˜¯å¦æ­£ç¡®
- [ ] æ£€æŸ¥ SLURM å‚æ•°æ˜¯å¦åˆç†
- [ ] æ£€æŸ¥ä¼ é€’ç»™ submit.py çš„å‚æ•°

#### 3.4 æäº¤åˆ° SLURM

**ä»£ç ä½ç½®ï¼š** ç¬¬ 314-377 è¡Œ

```bash
# ============================================
# æ­¥éª¤ 5: æäº¤ä½œä¸š
# ============================================
if [[ "$DRY_RUN" == "true" ]]; then
    echo ""
    echo "[è¯•è¿è¡Œæ¨¡å¼] è·³è¿‡å®é™…æäº¤"
    echo "è¦æ‰‹åŠ¨æäº¤ï¼Œè¯·è¿è¡Œ:"
    echo "  sbatch $SBATCH_SCRIPT"
    exit 0
fi

echo ""
echo "[æ­¥éª¤ 5] æäº¤ Slurm ä½œä¸š..."

SUBMIT_OUTPUT=$(sbatch "$SBATCH_SCRIPT")
echo "$SUBMIT_OUTPUT"

JOB_ID=$(echo "$SUBMIT_OUTPUT" | awk '{print $NF}')

if [[ -z "$JOB_ID" ]]; then
    echo "é”™è¯¯ï¼šæ— æ³•è·å–ä½œä¸š ID"
    exit 1
fi

echo "Slurm Job ID: $JOB_ID"
LOG_FILE="$WORKSPACE/slurm_${JOB_ID}.log"
echo "æ—¥å¿—æ–‡ä»¶: $LOG_FILE"

# ============================================
# æ­¥éª¤ 6: ç­‰å¾…ä½œä¸šå®Œæˆ
# ============================================
echo ""
echo "[æ­¥éª¤ 6] ç­‰å¾…ä½œä¸šå®Œæˆ..."

while true; do
    STATUS=$(sacct -j "$JOB_ID" --format=State -Pn --allocations 2>/dev/null || echo "")
    
    if [[ -z "$STATUS" || "$STATUS" == "RUNNING" || "$STATUS" == "PENDING" || "$STATUS" == "CONFIGURING" ]]; then
        echo "ä½œä¸šçŠ¶æ€: ${STATUS:-PENDING} (ç­‰å¾… 30s...)"
        sleep 30
    else
        echo "ä½œä¸šçŠ¶æ€: $STATUS"
        break
    fi
done
```

**éªŒè¯ç‚¹ï¼š**
- [ ] æ£€æŸ¥ `sbatch` å‘½ä»¤æ˜¯å¦æˆåŠŸ
- [ ] æ£€æŸ¥èƒ½å¦æ­£ç¡®è·å– JOB_ID
- [ ] æ£€æŸ¥ `sacct` å‘½ä»¤æ˜¯å¦å¯ç”¨

---

### 4. submit.py - ç¯å¢ƒå˜é‡ç”Ÿæˆå™¨ âš ï¸ é‡è¦çº æ­£

**æ–‡ä»¶ï¼š** `jenkins/scripts/perf/disaggregated/submit.py` (292è¡Œ)

**âš ï¸ æ³¨æ„ï¼š** è¿™ä¸ªæ–‡ä»¶**ä¸æ˜¯** `examples/disaggregated/slurm/benchmark/submit.py` (594è¡Œ)ï¼
- Jenkins ä½¿ç”¨çš„æ˜¯ 292 è¡Œçš„ç®€åŒ–ç‰ˆæœ¬
- å®ƒåªè´Ÿè´£ç”Ÿæˆç¯å¢ƒå˜é‡å’Œ launch.sh è„šæœ¬
- **ä¸è´Ÿè´£å¯åŠ¨ servers**ï¼ˆé‚£æ˜¯ slurm_launch_draft.sh çš„å·¥ä½œï¼‰

#### 4.1 ä¸»å‡½æ•°

**ä»£ç ä½ç½®ï¼š** ç¬¬ 164-292 è¡Œï¼ˆ`main` å‡½æ•°ï¼‰

```python
def main():
    parser = argparse.ArgumentParser(
        description="Generate SLURM launch script for both CI and local modes"
    )
    parser.add_argument("--run-ci", action="store_true", default=False)
    parser.add_argument("--draft-launch-sh", required=True)  # â† slurm_launch_draft.sh æ¨¡æ¿
    parser.add_argument("--launch-sh", required=True)        # â† è¾“å‡ºçš„ launch.sh
    parser.add_argument("--run-sh", required=True)           # â† slurm_run.sh
    parser.add_argument("--install-sh", required=True)       # â† slurm_install.sh
    parser.add_argument("--llm-src", default="")
    parser.add_argument("--test-list", default="")
    parser.add_argument("--script-prefix", default="")
    parser.add_argument("--srun-args", default="")

    args = parser.parse_args()

    # 1. ä» test_list æå–é…ç½®æ–‡ä»¶è·¯å¾„
    config_yaml = get_config_yaml(args.test_list, args.llm_src)  # â† ç¬¬199è¡Œ
    
    # 2. åŠ è½½é…ç½®
    with open(config_yaml, "r") as f:
        config = yaml.safe_load(f)  # â† ç¬¬202è¡Œ
    
    # 3. æå–å„ç§é…ç½®
    env_config = get_env_config(config)           # â† ç¬¬207è¡Œ
    benchmark_config = get_benchmark_config(config)  # â† ç¬¬210è¡Œ
    hardware_config = get_hardware_config(config, benchmark_mode)  # â† ç¬¬214è¡Œ
    
    # 4. ç”Ÿæˆ pytest å‘½ä»¤ç¯å¢ƒå˜é‡
    script_prefix_lines.extend([
        pytest_command_no_llmapi_launch,
        f'export pytestCommandWorker="unset UCX_TLS && {worker_env_vars} $pytestCommand"',  # â† ç¬¬248è¡Œ
        f'export pytestCommandDisaggServer="{server_env_vars} $pytestCommandNoLLMAPILaunch"',  # â† ç¬¬249è¡Œ
        f'export pytestCommandBenchmark="{env_config["benchmark_env_var"]} $pytestCommandNoLLMAPILaunch"',  # â† ç¬¬250è¡Œ
        f"export runScript={args.run_sh}",
        f"export installScript={install_script}",
        f"export numCtxServers={hardware_config['num_ctx_servers']}",  # â† ç¬¬253è¡Œ
        f"export numGenServers={hardware_config['num_gen_servers']}",
        f"export gpusPerNode={hardware_config['gpus_per_node']}",
        # ... æ›´å¤šç¯å¢ƒå˜é‡ ...
    ])  # â† ç¬¬245-262è¡Œï¼šå…³é”®çš„ç¯å¢ƒå˜é‡è®¾ç½®
    
    # 5. ç”Ÿæˆ srun å‚æ•°
    srun_args_lines.extend([
        "--container-env=DISAGG_SERVING_TYPE",  # â† ç¬¬271è¡Œï¼šå…³é”®ï¼ä¼ é€’ç¯å¢ƒå˜é‡
        "--container-env=pytestCommand",
    ])
    
    # 6. åˆå¹¶ç”Ÿæˆæœ€ç»ˆçš„ launch.sh
    with open(args.launch_sh, "w") as f:
        f.write(f"{script_prefix}\n{srun_args}\n{draft_launch_content}")  # â† ç¬¬285è¡Œ
```

**å…³é”®è¾“å‡ºï¼š**
- `launch.sh` = `ç¯å¢ƒå˜é‡å®šä¹‰` + `srunå‚æ•°` + `slurm_launch_draft.sh å†…å®¹`

#### 4.2 å…³é”®å‡½æ•° - get_hardware_config

**ä»£ç ä½ç½®ï¼š** ç¬¬ 8-54 è¡Œ

```python
def get_hardware_config(config, benchmark_mode):
    hardware = config.get("hardware", {})
    worker_config = config.get("worker_config", {})

    num_ctx_servers = 0 if "gen_only" in benchmark_mode else hardware.get("num_ctx_servers")
    num_gen_servers = hardware.get("num_gen_servers")
    gpus_per_node = hardware.get("gpus_per_node")

    # ä» worker_config è®¡ç®—æ¯ä¸ª server éœ€è¦çš„ GPU æ•°
    ctx_tp = ctx_config.get("tensor_parallel_size", 1)
    ctx_pp = ctx_config.get("pipeline_parallel_size", 1)
    ctx_cp = ctx_config.get("context_parallel_size", 1)
    gpus_per_ctx_server = ctx_tp * ctx_pp * ctx_cp

    gen_tp = gen_config.get("tensor_parallel_size", 1)
    gen_pp = gen_config.get("pipeline_parallel_size", 1)
    gen_cp = gen_config.get("context_parallel_size", 1)
    gpus_per_gen_server = gen_tp * gen_pp * gen_cp

    # è®¡ç®—èŠ‚ç‚¹æ•°
    nodes_per_ctx_server = (gpus_per_ctx_server + gpus_per_node - 1) // gpus_per_node
    nodes_per_gen_server = (gpus_per_gen_server + gpus_per_node - 1) // gpus_per_node

    total_nodes = num_ctx_servers * nodes_per_ctx_server + num_gen_servers * nodes_per_gen_server
    total_gpus = total_nodes * gpus_per_node

    return {
        "num_ctx_servers": num_ctx_servers,
        "num_gen_servers": num_gen_servers,
        "gpus_per_node": gpus_per_node,
        # ... å…¶ä»–é…ç½® ...
        "total_nodes": total_nodes,
        "total_gpus": total_gpus,
    }
```

**éªŒè¯ç‚¹ï¼š**
- [ ] æ£€æŸ¥é…ç½® YAML ä¸­çš„ `hardware` å’Œ `worker_config` éƒ¨åˆ†
- [ ] æ£€æŸ¥èŠ‚ç‚¹æ•°è®¡ç®—æ˜¯å¦æ­£ç¡®ï¼ˆå‘ä¸Šå–æ•´ï¼‰
- [ ] æ£€æŸ¥ gen_only æ¨¡å¼æ˜¯å¦æ­£ç¡®å¤„ç†

**éªŒè¯ç‚¹ï¼š**
- [ ] æ£€æŸ¥ `get_config_yaml()` æ˜¯å¦æ­£ç¡®è§£æ test_list
- [ ] æ£€æŸ¥ç”Ÿæˆçš„ç¯å¢ƒå˜é‡æ˜¯å¦å®Œæ•´
- [ ] æ£€æŸ¥ `--container-env=DISAGG_SERVING_TYPE` æ˜¯å¦ä¼ é€’ç»™ srun

---

### 5. slurm_launch_draft.sh - Server å¯åŠ¨å™¨ï¼ˆçœŸæ­£çš„å·¥ä½œè€…ï¼‰

**æ–‡ä»¶ï¼š** `jenkins/scripts/perf/disaggregated/slurm_launch_draft.sh`

**å®Œæ•´æ–‡ä»¶ï¼š** 77 è¡Œ

**âš ï¸ é‡è¦è¯´æ˜ï¼š** è¿™ä¸ªè„šæœ¬æ‰æ˜¯çœŸæ­£å¯åŠ¨æ‰€æœ‰ servers çš„åœ°æ–¹ï¼å®ƒä½¿ç”¨ `submit.py` ç”Ÿæˆçš„ç¯å¢ƒå˜é‡ã€‚

#### 5.1 å®‰è£…é˜¶æ®µ

**ä»£ç ä½ç½®ï¼š** ç¬¬ 8-17 è¡Œ

```bash
mkdir -p $jobWorkspace
chmod +x $runScript
chmod +x $installScript

# Run installation on all nodes
echo "Running installation on all nodes..."
if ! srun "${srunArgs[@]}" $installScript &> $jobWorkspace/install.log; then
    cleanup_on_failure "Failed to run installation. Check $jobWorkspace/install.log"
fi
echo "Installation completed on all nodes"
```

**éªŒè¯ç‚¹ï¼š**
- [ ] æ£€æŸ¥ `$runScript` å’Œ `$installScript` å˜é‡æ˜¯å¦è®¾ç½®
- [ ] æ£€æŸ¥ `$jobWorkspace` ç›®å½•æ˜¯å¦å¯å†™
- [ ] æ£€æŸ¥ `srunArgs` æ•°ç»„æ˜¯å¦æ­£ç¡®

#### 5.2 å¯åŠ¨ GEN Servers

**ä»£ç ä½ç½®ï¼š** ç¬¬ 19-31 è¡Œ

```bash
# Start gen servers
echo "Starting gen servers..."
for i in $(seq 0 $((numGenServers - 1))); do
    gen_world_size=$((nodesPerGenServer * gpusPerNode))
    export DISAGG_SERVING_TYPE="GEN_$i"  # â† å…³é”®ï¼šè®¾ç½®ç¯å¢ƒå˜é‡
    export pytestCommand="$pytestCommandWorker"
    srun "${srunArgs[@]}" --kill-on-bad-exit=1 \
        -N $nodesPerGenServer \
        --ntasks=$gen_world_size \
        --ntasks-per-node=$gpusPerNode \
        $runScript &> $jobWorkspace/gen_server_$i.log &  # â† åå°è¿è¡Œï¼Œæ—¥å¿—é‡å®šå‘
    echo "Started gen server $i"
done
```

**å…³é”®ç¯å¢ƒå˜é‡ï¼š**
- `DISAGG_SERVING_TYPE="GEN_$i"` - å‘Šè¯‰ pytest è¿™æ˜¯ GEN server
- `pytestCommand="$pytestCommandWorker"` - pytest å‘½ä»¤

**éªŒè¯ç‚¹ï¼š**
- [ ] æ£€æŸ¥ `numGenServers` å˜é‡æ˜¯å¦æ­£ç¡®
- [ ] æ£€æŸ¥ `$runScript` æ˜¯å¦è°ƒç”¨ pytest
- [ ] æ£€æŸ¥æ—¥å¿—æ–‡ä»¶æ˜¯å¦åˆ›å»º

#### 5.3 å¯åŠ¨ CTX Servers

**ä»£ç ä½ç½®ï¼š** ç¬¬ 33-49 è¡Œ

```bash
# Start ctx servers (skip if gen_only mode)
if [ "${TRTLLM_DISAGG_BENCHMARK_GEN_ONLY:-0}" != "1" ]; then
    echo "Starting ctx servers..."
    for i in $(seq 0 $((numCtxServers - 1))); do
        ctx_world_size=$((nodesPerCtxServer * gpusPerNode))
        export DISAGG_SERVING_TYPE="CTX_$i"  # â† å…³é”®ï¼šè®¾ç½®ç¯å¢ƒå˜é‡
        export pytestCommand="$pytestCommandWorker"
        srun "${srunArgs[@]}" --kill-on-bad-exit=1 \
            -N $nodesPerCtxServer \
            --ntasks=$ctx_world_size \
            --ntasks-per-node=$gpusPerNode \
            $runScript &> $jobWorkspace/ctx_server_$i.log &  # â† åå°è¿è¡Œ
        echo "Started ctx server $i"
    done
else
    echo "Skipping ctx servers (gen_only mode)"
fi
```

**éªŒè¯ç‚¹ï¼š**
- [ ] æ£€æŸ¥ `numCtxServers` å˜é‡
- [ ] æ£€æŸ¥ gen_only æ¨¡å¼åˆ¤æ–­æ˜¯å¦æ­£ç¡®

#### 5.4 å¯åŠ¨ Disagg Coordinator

**ä»£ç ä½ç½®ï¼š** ç¬¬ 52-61 è¡Œ

```bash
# Start disagg server
echo "Starting disagg server..."
export DISAGG_SERVING_TYPE="DISAGG_SERVER"  # â† å…³é”®
export pytestCommand="$pytestCommandDisaggServer"
srun "${srunArgs[@]}" --kill-on-bad-exit=1 --overlap \
    -N 1 \
    --ntasks=1 \
    --ntasks-per-node=1 \
    $runScript &> $jobWorkspace/disagg_server.log &  # â† åå°è¿è¡Œ
echo "Started disagg server"
```

**éªŒè¯ç‚¹ï¼š**
- [ ] æ£€æŸ¥ coordinator æ˜¯å¦åªåœ¨å•èŠ‚ç‚¹è¿è¡Œ
- [ ] æ£€æŸ¥ `pytestCommandDisaggServer` å˜é‡

#### 5.5 è¿è¡Œ Benchmark

**ä»£ç ä½ç½®ï¼š** ç¬¬ 63-73 è¡Œ

```bash
# Start benchmark
echo "Starting benchmark..."
export DISAGG_SERVING_TYPE="BENCHMARK"  # â† å…³é”®ï¼šåªæœ‰è¿™ä¸ªèŠ‚ç‚¹ä¼šä¸Šä¼ æ•°æ®
export pytestCommand="$pytestCommandBenchmark"
if ! srun "${srunArgs[@]}" --kill-on-bad-exit=1 --overlap \
    -N 1 \
    --ntasks=1 \
    --ntasks-per-node=1 \
    $runScript; then  # â† å‰å°è¿è¡Œï¼Œç­‰å¾…å®Œæˆ
    cleanup_on_failure "Benchmark failed. Check logs in ${jobWorkspace} for details"
fi

echo "Disagg server and benchmark completed successfully"
echo "Total runtime: $SECONDS seconds"
```

**éªŒè¯ç‚¹ï¼š**
- [ ] æ£€æŸ¥ benchmark æ˜¯å¦å‰å°è¿è¡Œï¼ˆæ²¡æœ‰ `&`ï¼‰
- [ ] æ£€æŸ¥å¤±è´¥æ—¶æ˜¯å¦è°ƒç”¨ `cleanup_on_failure`

---

### 6. test_perf_sanity.py - æµ‹è¯•æ‰§è¡Œå™¨

**æ–‡ä»¶ï¼š** `tests/integration/defs/perf/test_perf_sanity.py`

#### 6.1 test_e2e å‡½æ•°

**ä»£ç ä½ç½®ï¼š** ç¬¬ 1490-1521 è¡Œ

```python
@pytest.mark.parametrize("perf_sanity_test_case", PERF_SANITY_TEST_CASES)
def test_e2e(output_dir, perf_sanity_test_case):
    # Create config and parse test case name
    config = PerfSanityTestConfig(perf_sanity_test_case, output_dir)

    # Parse config file to get server_configs and server_client_configs
    config.parse_config_file()

    # Get commands
    commands = config.get_commands()

    # Run commands and collect outputs
    outputs = config.run_ex(commands)

    # For disagg mode, only BENCHMARK node parses results and uploads
    if config.runtime == "multi_node_disagg_server":
        disagg_config = config.server_configs[0][2]
        if disagg_config.disagg_serving_type != "BENCHMARK":  # â† ç¬¬1507è¡Œï¼šå…³é”®åˆ¤æ–­
            print_info(
                f"Disagg serving type is {disagg_config.disagg_serving_type}, skipping perf result parsing and upload."
            )
            return  # â† GEN/CTX/DISAGG_SERVER èŠ‚ç‚¹ç›´æ¥é€€å‡º

    # Parse performance results
    config.get_perf_result(outputs)

    # Check for test failures
    config.check_test_failure()

    # Upload results to database
    config.upload_test_result()  # â† ç¬¬1519è¡Œï¼šåªæœ‰ BENCHMARK èŠ‚ç‚¹æ‰§è¡Œ
```

**éªŒè¯ç‚¹ï¼š**
- [ ] æ£€æŸ¥ `config.runtime` æ˜¯å¦æ­£ç¡®è¯†åˆ« disagg æ¨¡å¼
- [ ] æ£€æŸ¥ `disagg_config.disagg_serving_type` æ˜¯å¦ä»ç¯å¢ƒå˜é‡è¯»å–
- [ ] æ£€æŸ¥é BENCHMARK èŠ‚ç‚¹æ˜¯å¦æ­£ç¡®è·³è¿‡ä¸Šä¼ 

#### 6.2 DisaggConfig ç±» - è¯»å–ç¯å¢ƒå˜é‡

**ä»£ç ä½ç½®ï¼š** ç¬¬ 331-376 è¡Œï¼ˆDisaggConfig ç±»å®šä¹‰ï¼‰

```python
class DisaggConfig:
    """Disagg configuration."""

    def __init__(
        self,
        name: str,
        hardware: dict,
        benchmark_mode: str = "e2e",
        # ... å…¶ä»–å‚æ•° ...
    ):
        self.name = name
        self.num_ctx_servers = hardware.get("num_ctx_servers", 0)
        self.num_gen_servers = hardware.get("num_gen_servers", 1)
        # ... å…¶ä»–åˆå§‹åŒ– ...
        
        # âš ï¸ å…³é”®ï¼šä»ç¯å¢ƒå˜é‡è¯»å– serving type
        self.disagg_serving_type = os.getenv("DISAGG_SERVING_TYPE", "BENCHMARK")  # â† ç¬¬353è¡Œå·¦å³
```

**éªŒè¯ç‚¹ï¼š**
- [ ] ç¡®è®¤ `DISAGG_SERVING_TYPE` ç¯å¢ƒå˜é‡æ˜¯å¦æ­£ç¡®ä¼ é€’
- [ ] ç¡®è®¤é»˜è®¤å€¼æ˜¯å¦åˆç†

#### 6.3 upload_test_result å‡½æ•°

**ä»£ç ä½ç½®ï¼š** ç¬¬ 1380-1413 è¡Œ

```python
def upload_test_result(self):
    """Upload test result to database."""
    # Get job info
    job_info = get_job_info()

    # Prepare new data
    new_data_dict = {}
    for test_case_index in range(len(self.server_configs)):
        # ... å‡†å¤‡æ•°æ® ...
        new_data_dict[test_case_index] = {
            "model": self.model_name,
            "precision": self.precision,
            # ... å…¶ä»–å­—æ®µ ...
        }

    # ... å‡†å¤‡ baseline æ•°æ® ...

    if self.upload_to_db:
        # Upload the new perf data and baseline data to database
        post_new_perf_data(new_baseline_data_dict, new_data_dict)  # â† ç¬¬1407è¡Œï¼šä¸Šä¼ åˆ° OpenSearch

    check_perf_regression(
        new_data_dict,
        fail_on_regression=is_scenario_mode,
        output_dir=self.perf_sanity_output_dir,
    )
```

**éªŒè¯ç‚¹ï¼š**
- [ ] æ£€æŸ¥ `post_new_perf_data` å‡½æ•°æ˜¯å¦æ­£ç¡®è°ƒç”¨
- [ ] æ£€æŸ¥ `self.upload_to_db` æ ‡å¿—æ˜¯å¦æ­£ç¡®è®¾ç½®
- [ ] æ£€æŸ¥æ•°æ®æ ¼å¼æ˜¯å¦ç¬¦åˆ OpenSearch è¦æ±‚

---

## ğŸ” å…³é”®éªŒè¯ç‚¹æ€»ç»“

### ç¯å¢ƒå˜é‡ä¼ é€’é“¾

```
slurm_launch_draft.sh (è®¾ç½®)
  â†“ export DISAGG_SERVING_TYPE="GEN_0"
  â†“ export pytestCommand="..."
  â†“
srun $runScript (è°ƒç”¨ pytest)
  â†“
test_perf_sanity.py (è¯»å–)
  â†“ os.getenv("DISAGG_SERVING_TYPE")
  â†“
åˆ¤æ–­æ˜¯å¦ä¸Šä¼ 
```

**å…³é”®æ–‡ä»¶å’Œè¡Œå·ï¼š**
1. **è®¾ç½®ç¯å¢ƒå˜é‡ï¼š** `slurm_launch_draft.sh` ç¬¬23ã€38ã€54ã€65è¡Œ
2. **è¯»å–ç¯å¢ƒå˜é‡ï¼š** `test_perf_sanity.py` ç¬¬353è¡Œï¼ˆDisaggConfig.__init__ï¼‰
3. **åˆ¤æ–­é€»è¾‘ï¼š** `test_perf_sanity.py` ç¬¬1507è¡Œï¼ˆtest_e2eå‡½æ•°ï¼‰

---

### æ—¥å¿—æ–‡ä»¶è·¯å¾„

```
slurm_launch_draft.sh ä¸­çš„æ—¥å¿—é‡å®šå‘ï¼š

ç¬¬29è¡Œ: &> $jobWorkspace/gen_server_$i.log
ç¬¬44è¡Œ: &> $jobWorkspace/ctx_server_$i.log
ç¬¬60è¡Œ: &> $jobWorkspace/disagg_server.log
ç¬¬70è¡Œ: (benchmark è¾“å‡ºåˆ° stdoutï¼Œè¢« srun æ•è·)
```

**éªŒè¯ç‚¹ï¼š**
- [ ] æ£€æŸ¥ `$jobWorkspace` å˜é‡æ˜¯å¦æ­£ç¡®è®¾ç½®
- [ ] æ£€æŸ¥æ—¥å¿—ç›®å½•æ˜¯å¦å­˜åœ¨ä¸”å¯å†™
- [ ] æ£€æŸ¥ benchmark æ—¥å¿—æ˜¯å¦è¢«æ­£ç¡®æ•è·

---

### æ•°æ®ä¸Šä¼ è·¯å¾„

```
test_perf_sanity.py::test_e2e (ç¬¬1490è¡Œ)
  â†“
config.upload_test_result() (ç¬¬1519è¡Œ)
  â†“
post_new_perf_data() (ç¬¬1407è¡Œ)
  â†“
OpenSearch (åœ¨ open_search_db_utils.py ä¸­å®ç°)
```

**å¾…å®ç°ï¼šPerf DB ä¸Šä¼ **
- éœ€è¦åœ¨ç¬¬1407è¡Œä¹‹åæ·»åŠ 
- å»ºè®®ä½ç½®ï¼š`upload_test_result()` å‡½æ•°ä¸­ï¼Œ`post_new_perf_data()` è°ƒç”¨ä¹‹å

---

## ğŸ› æ½œåœ¨ Bug æ£€æŸ¥æ¸…å•

### 1. ç¯å¢ƒå˜é‡ä¸¢å¤±

**æ£€æŸ¥ç‚¹ï¼š** `slurm_launch_draft.sh` ç¬¬23-70è¡Œ

```bash
# æ˜¯å¦æ‰€æœ‰ export éƒ½åœ¨ srun ä¹‹å‰ï¼Ÿ
export DISAGG_SERVING_TYPE="GEN_0"
export pytestCommand="$pytestCommandWorker"
srun ... $runScript  # â† srun ä¼šç»§æ‰¿ç¯å¢ƒå˜é‡å—ï¼Ÿ
```

**éªŒè¯æ–¹æ³•ï¼š**
```bash
# åœ¨ pytest ä¸­æ‰“å°ç¯å¢ƒå˜é‡
import os
print(f"DISAGG_SERVING_TYPE = {os.getenv('DISAGG_SERVING_TYPE')}")
```

### 2. æ—¥å¿—æ–‡ä»¶æƒé™

**æ£€æŸ¥ç‚¹ï¼š** `slurm_launch_draft.sh` ç¬¬8è¡Œ

```bash
mkdir -p $jobWorkspace  # æ˜¯å¦éœ€è¦æ£€æŸ¥æƒé™ï¼Ÿ
```

**éªŒè¯æ–¹æ³•ï¼š**
```bash
# æ£€æŸ¥ç›®å½•æ˜¯å¦å¯å†™
if [[ ! -w "$jobWorkspace" ]]; then
    echo "Error: $jobWorkspace is not writable"
    exit 1
fi
```

### 3. åå°è¿›ç¨‹æ¸…ç†

**æ£€æŸ¥ç‚¹ï¼š** `slurm_launch_draft.sh` ç¬¬29ã€44ã€60è¡Œ

æ‰€æœ‰ server éƒ½æ˜¯åå°è¿è¡Œï¼ˆ`&`ï¼‰ï¼Œå¦‚æœ benchmark å¤±è´¥ï¼Œè¿™äº›åå°è¿›ç¨‹æ˜¯å¦ä¼šè¢«æ¸…ç†ï¼Ÿ

**éªŒè¯æ–¹æ³•ï¼š**
æ£€æŸ¥ SLURM çš„ `--kill-on-bad-exit` å‚æ•°æ˜¯å¦ä¼šæ€æ‰æ‰€æœ‰å­è¿›ç¨‹ã€‚

### 4. config.runtime åˆ¤æ–­

**æ£€æŸ¥ç‚¹ï¼š** `test_perf_sanity.py` ç¬¬1505è¡Œ

```python
if config.runtime == "multi_node_disagg_server":
```

**éªŒè¯æ–¹æ³•ï¼š**
```bash
# æœç´¢ runtime åœ¨å“ªé‡Œè®¾ç½®
grep -n "self.runtime.*disagg" tests/integration/defs/perf/test_perf_sanity.py
```

### 5. disagg_config ç´¢å¼•

**æ£€æŸ¥ç‚¹ï¼š** `test_perf_sanity.py` ç¬¬1506è¡Œ

```python
disagg_config = config.server_configs[0][2]  # â† ä¸ºä»€ä¹ˆæ˜¯ [0][2]ï¼Ÿ
```

**éœ€è¦éªŒè¯ï¼š**
- `server_configs` çš„ç»“æ„æ˜¯ä»€ä¹ˆï¼Ÿ
- `[0]` ä»£è¡¨ä»€ä¹ˆï¼Ÿ
- `[2]` ä»£è¡¨ä»€ä¹ˆï¼Ÿ

---

## âš ï¸ å…³é”®çº æ­£ï¼šä¸¤ä¸ªä¸åŒçš„ submit.py

| submit.py | è¡Œæ•° | åŠŸèƒ½ | ä½¿ç”¨åœºæ™¯ |
|-----------|------|------|---------|
| **`jenkins/scripts/perf/disaggregated/submit.py`** | **292è¡Œ** | **ç¯å¢ƒå˜é‡ç”Ÿæˆå™¨** | **Jenkins CI ä½¿ç”¨** âœ… |
| `examples/disaggregated/slurm/benchmark/submit.py` | 594è¡Œ | å®Œæ•´çš„ SLURM job æäº¤å™¨ | æœ¬åœ°æ‰‹åŠ¨æµ‹è¯• |

**æˆ‘ä¹‹å‰çš„é”™è¯¯ï¼š**
- âŒ æˆ‘é”™è¯¯åœ°åˆ†æäº† 594 è¡Œçš„ submit.py
- âŒ æè¿°äº†å¾ˆå¤šä¸å­˜åœ¨çš„ `submit_job()` å‡½æ•°
- âŒ æè¿°äº† `allocations`ã€`srun` å‘½ä»¤ç”Ÿæˆç­‰ï¼ˆè¿™äº›åœ¨ 292 è¡Œç‰ˆæœ¬ä¸­ä¸å­˜åœ¨ï¼‰

**æ­£ç¡®çš„ç†è§£ï¼š**
- âœ… Jenkins ä½¿ç”¨çš„æ˜¯ 292 è¡Œçš„ç®€åŒ–ç‰ˆæœ¬
- âœ… å®ƒåªè´Ÿè´£è¯»å–é…ç½®ã€ç”Ÿæˆç¯å¢ƒå˜é‡ã€ç”Ÿæˆ launch.sh
- âœ… çœŸæ­£å¯åŠ¨ servers çš„æ˜¯ `slurm_launch_draft.sh`

---

## ğŸ“š ç›¸å…³æ–‡ä»¶ç´¢å¼•

### æ ¸å¿ƒæ–‡ä»¶

| æ–‡ä»¶ | è¡Œæ•° | åŠŸèƒ½ |
|------|------|------|
| `jenkins_test/Perf_Test.groovy` | ~489 | Jenkins Pipeline |
| `jenkins_test/scripts/run_perf_tests.sh` | 409 | æµ‹è¯•åˆ†å‘å™¨ |
| `jenkins_test/scripts/run_disagg_test.sh` | 378 | SLURM ä½œä¸šæäº¤ |
| `jenkins/scripts/perf/disaggregated/submit.py` | **292** | ç¯å¢ƒå˜é‡ç”Ÿæˆå™¨ âš ï¸ |
| `jenkins/scripts/perf/disaggregated/slurm_launch_draft.sh` | 77 | Server å¯åŠ¨å™¨ï¼ˆçœŸæ­£çš„å·¥ä½œè€…ï¼‰|
| `tests/integration/defs/perf/test_perf_sanity.py` | 1521 | æµ‹è¯•æ‰§è¡Œå™¨ |

### è¾…åŠ©æ–‡ä»¶

| æ–‡ä»¶ | åŠŸèƒ½ |
|------|------|
| `jenkins_test/scripts/calculate_hardware_nodes.py` | è®¡ç®—ç¡¬ä»¶èŠ‚ç‚¹æ•° |
| `jenkins_test/scripts/parse_unified_testlist.py` | è§£æ testlist |
| `tests/integration/defs/perf/open_search_db_utils.py` | OpenSearch ä¸Šä¼  |

---

## ğŸ¯ ä¸‹ä¸€æ­¥è¡ŒåŠ¨

### å»ºè®®æ£€æŸ¥é¡ºåº

1. **éªŒè¯ç¯å¢ƒå˜é‡ä¼ é€’**
   ```bash
   # åœ¨ test_perf_sanity.py ç¬¬1492è¡Œä¹‹åæ·»åŠ 
   print(f"DEBUG: DISAGG_SERVING_TYPE = {os.getenv('DISAGG_SERVING_TYPE')}")
   ```

2. **éªŒè¯æ—¥å¿—æ–‡ä»¶åˆ›å»º**
   ```bash
   # æ£€æŸ¥ $jobWorkspace æ˜¯å¦å­˜åœ¨
   ls -la $jobWorkspace/*.log
   ```

3. **éªŒè¯æ•°æ®ä¸Šä¼ **
   ```bash
   # æ£€æŸ¥ OpenSearch æ˜¯å¦æ”¶åˆ°æ•°æ®
   # æŸ¥çœ‹ post_new_perf_data çš„å®ç°
   ```

4. **éªŒè¯ config.runtime è®¾ç½®**
   ```python
   # åœ¨ test_perf_sanity.py ç¬¬1505è¡Œä¹‹å‰æ·»åŠ 
   print(f"DEBUG: config.runtime = {config.runtime}")
   ```

---

**æ‰€æœ‰å…³é”®ä»£ç ä½ç½®å·²åˆ—å‡ºï¼Œè¯·æŒ‰æ­¤æ–‡æ¡£è¿½è¸ªä»£ç æµç¨‹å¹¶æ£€æŸ¥æ˜¯å¦æœ‰bugï¼**
