# é‡å¤§æ›´æ­£ï¼šDisaggregated æ¨¡å¼å¿…é¡»ä½¿ç”¨ trtllm-llmapi-launch

> **ä¸¥é‡é”™è¯¯æ›´æ­£ï¼šæˆ‘ä¹‹å‰çš„åˆ†æžå®Œå…¨é”™è¯¯ï¼Disaggregated æ¨¡å¼çš„ CTX/GEN servers ç¡®å®žéœ€è¦ trtllm-llmapi-launchï¼**

---

## ðŸš¨ æˆ‘çš„ä¸¥é‡é”™è¯¯

### é”™è¯¯çš„ç»“è®ºï¼ˆä¹‹å‰ï¼‰âŒ

æˆ‘ä¹‹å‰åœ¨å¤šä¸ªæ–‡æ¡£ä¸­é”™è¯¯åœ°å£°ç§°ï¼š
- âŒ "test_perf_sanity.py ä¸ä½¿ç”¨ trtllm-llmapi-launch"
- âŒ "ç›´æŽ¥ç”¨ subprocess.Popen å¯åŠ¨ trtllm-serve"
- âŒ "ä¸éœ€è¦ trtllm-llmapi-launch æ¥ç®¡ç†å¤šè¿›ç¨‹"

### å®žé™…æƒ…å†µï¼ˆæ­£ç¡®ï¼‰âœ…

**Disaggregated æ¨¡å¼çš„ CTX/GEN servers å¿…é¡»ä½¿ç”¨ trtllm-llmapi-launchï¼**

---

## ðŸ” é“è¯å¦‚å±±

### è¯æ® 1: L0_Test.groovy ç¡®å®žä¼ é€’äº† trtllm-llmapi-launch

**ä»£ç ï¼ˆjenkins/L0_Test.groovy:1051-1064ï¼‰ï¼š**

```groovy
// Generate Pytest command
String pytestUtil = ""
if (nodeCount > 1) {
    pytestUtil = "$llmSrcNode/tensorrt_llm/llmapi/trtllm-llmapi-launch"
}

def pytestCommand = getPytestBaseCommandLine(
    llmSrcNode,
    stageName,
    waivesListPathNode,
    perfMode,
    jobWorkspace,
    "__PLACEHOLDER_TRTLLM_WHL_PATH__",
    "$jobWorkspace/.coveragerc",
    pytestUtil,  // â† ä¼ é€’ trtllm-llmapi-launchï¼
    [
      "--test-list=$testListPathNode",
      "--splitting-algorithm least_duration",
      "--splits $splits",
      "--group $splitId"
    ]
).join(" ")
```

**å…³é”®ï¼š**
- âœ… å½“ `nodeCount > 1` æ—¶ï¼ŒpytestUtil è¢«è®¾ç½®ä¸º trtllm-llmapi-launch çš„è·¯å¾„
- âœ… è¿™ä¸ªå‚æ•°è¢«ä¼ é€’ç»™ `getPytestBaseCommandLine`
- âœ… æœ€ç»ˆå‡ºçŽ°åœ¨ `export pytestCommand="..."` ä¸­

---

### è¯æ® 2: examples ä¸­æ˜Žç¡®ä½¿ç”¨ trtllm-llmapi-launch

**ä»£ç ï¼ˆexamples/disaggregated/slurm/benchmark/start_worker.sh:55-58ï¼‰ï¼š**

```bash
${nsys_prefix} trtllm-llmapi-launch ${numa_bind_cmd} \
    trtllm-serve ${model_path} \
        --host $(hostname) --port ${port} \
        --config ${config_file}
```

**å…³é”®ï¼š**
- âœ… **æ˜Žç¡®ä½¿ç”¨ `trtllm-llmapi-launch`**
- âœ… å®ƒåœ¨ `trtllm-serve` ä¹‹å‰
- âœ… è¿™æ˜¯å¯åŠ¨ disaggregated workerï¼ˆCTX/GENï¼‰çš„æ ‡å‡†æ–¹å¼

---

### è¯æ® 3: L0_Test.groovy çš„å®Œæ•´å‘½ä»¤ç»“æž„

**getPytestBaseCommandLine å‡½æ•°ï¼ˆjenkins/L0_Test.groovy:800-850ï¼‰ï¼š**

```groovy
def testCmdLine = [
    "LLM_ROOT=${llmSrc}",
    "LLM_BACKEND_ROOT=${llmSrc}/triton_backend",
    "LLM_MODELS_ROOT=${MODEL_CACHE_DIR}",
    "MODEL_CACHE_DIR=${MODEL_CACHE_DIR}",
    "COLUMNS=300",
    extraInternalEnv,
    portEnvVars,
    pytestUtil,  // â† trtllm-llmapi-launch æ’å…¥åˆ°è¿™é‡Œ
    "pytest",
    "-vv",
    "--timeout-method=thread",
    "--apply-test-list-correction",
    "--timeout=${pytestTestTimeout}",
    "--rootdir ${llmSrc}/tests/integration/defs",
    "--test-prefix=${stageName}",
    "--waives-file=${waivesFilePath}",
    "--output-dir=${outputPath}/",
    "--csv=${outputPath}/report.csv",
    "-o junit_logging=out-err",
    "--junit-xml=${outputPath}/results.xml",
    *extraArgs,
]
```

**ç”Ÿæˆçš„å®Œæ•´å‘½ä»¤ï¼š**

```bash
export pytestCommand="LLM_ROOT=/path/to/TensorRT-LLM \
LLM_MODELS_ROOT=/lustre/fsw/... \
NCCL_DEBUG=INFO \
/path/to/TensorRT-LLM/tensorrt_llm/llmapi/trtllm-llmapi-launch \
pytest -vv \
--test-prefix=L0_disagg \
--junit-xml=/workspace/results.xml \
--test-list=/workspace/test_list.txt"
```

---

## ðŸŽ¯ ä¸ºä»€ä¹ˆ CTX/GEN å¿…é¡»ä½¿ç”¨ trtllm-llmapi-launchï¼Ÿ

### åŽŸå›  1: å¤š GPU è¿›ç¨‹é—´é€šä¿¡ï¼ˆMPI/NCCLï¼‰

**CTX/GEN servers éœ€è¦ Tensor Parallelismï¼ˆTPï¼‰ï¼š**

```
trtllm-llmapi-launch (MPI å¯åŠ¨å™¨)
  â†“
å¯åŠ¨å¤šä¸ªè¿›ç¨‹ï¼ˆæ¯ä¸ª GPU ä¸€ä¸ªï¼‰
  â”œâ”€â”€ Rank 0 (GPU 0): trtllm-serve --host xxx --port xxx
  â”œâ”€â”€ Rank 1 (GPU 1): trtllm-serve --host xxx --port xxx
  â”œâ”€â”€ Rank 2 (GPU 2): trtllm-serve --host xxx --port xxx
  â””â”€â”€ Rank 3 (GPU 3): trtllm-serve --host xxx --port xxx
  â†“
æ‰€æœ‰è¿›ç¨‹é€šè¿‡ NCCL é€šä¿¡ï¼ˆAllReduce ç­‰æ“ä½œï¼‰
  â†“
å¯¹å¤–æä¾›ä¸€ä¸ªç»Ÿä¸€çš„æœåŠ¡ç«¯ç‚¹
```

**å¦‚æžœä¸ä½¿ç”¨ trtllm-llmapi-launchï¼š**
- âŒ åªæœ‰ä¸€ä¸ªè¿›ç¨‹
- âŒ æ— æ³•åœ¨å¤šä¸ª GPU ä¹‹é—´åˆ†é… Tensor Parallel
- âŒ æ— æ³•è¿›è¡Œ AllReduce ç­‰ NCCL é›†åˆé€šä¿¡
- âŒ CTX/GEN servers æ ¹æœ¬æ— æ³•æ­£å¸¸å·¥ä½œï¼

---

### åŽŸå›  2: æ¯ä¸ª GPU éœ€è¦ç‹¬ç«‹çš„ Rank å’Œé€šä¿¡ä¸Šä¸‹æ–‡

**TP=4 çš„ç¤ºä¾‹ï¼š**

```bash
# é”™è¯¯çš„æ–¹å¼ï¼ˆä¸ä½¿ç”¨ llmapi-launchï¼‰
trtllm-serve /model --host localhost --port 8000
# â†‘ åªå¯åŠ¨ä¸€ä¸ªè¿›ç¨‹ï¼Œæ— æ³•ä½¿ç”¨ 4 ä¸ª GPU

# æ­£ç¡®çš„æ–¹å¼ï¼ˆä½¿ç”¨ llmapi-launchï¼‰
trtllm-llmapi-launch trtllm-serve /model --host localhost --port 8000
# â†‘ å¯åŠ¨ 4 ä¸ªè¿›ç¨‹ï¼ˆæ ¹æ® CUDA_VISIBLE_DEVICESï¼‰
#   Rank 0: GPU 0
#   Rank 1: GPU 1
#   Rank 2: GPU 2
#   Rank 3: GPU 3
```

---

### åŽŸå›  3: æ¨¡åž‹æƒé‡åˆ†ç‰‡å’Œé€šä¿¡

**Tensor Parallelism è¦æ±‚ï¼š**
1. **æ¨¡åž‹æƒé‡åˆ†ç‰‡**ï¼šæ¯ä¸ª GPU åªåŠ è½½éƒ¨åˆ†æƒé‡
2. **æ¿€æ´»å€¼åˆ†ç‰‡**ï¼šè¾“å…¥æ•°æ®åœ¨å¤šä¸ª GPU ä¸Šåˆ†ç‰‡è®¡ç®—
3. **AllReduce é€šä¿¡**ï¼šéœ€è¦åœ¨å¤šä¸ªè¿›ç¨‹ä¹‹é—´åŒæ­¥æ¢¯åº¦/æ¿€æ´»å€¼

**trtllm-llmapi-launch çš„ä½œç”¨ï¼š**
- è®¾ç½® MPI çŽ¯å¢ƒï¼ˆRANKã€LOCAL_RANKã€WORLD_SIZE ç­‰ï¼‰
- åˆå§‹åŒ– NCCL é€šä¿¡ç»„
- ç¡®ä¿æ‰€æœ‰è¿›ç¨‹æ­£ç¡®å¯åŠ¨å’ŒåŒæ­¥

---

## ðŸ“Š æ­£ç¡®çš„ Disaggregated å¯åŠ¨æµç¨‹

### å®Œæ•´çš„æ‰§è¡Œé“¾

```
sbatch slurm_launch_generated.sh
  â†“
slurm_launch_draft.sh
  â†“
â”œâ”€â”€ GEN_0: srun -N 1 -n 4 slurm_run.sh
â”‚   â†“ DISAGG_SERVING_TYPE=GEN_0
â”‚   â†“ eval $pytestCommand
â”‚   â†“ trtllm-llmapi-launch pytest test_perf_sanity.py
â”‚   â†“
â”‚   â”œâ”€â”€ trtllm-llmapi-launch å¯åŠ¨ 4 ä¸ª pytest è¿›ç¨‹
â”‚   â”‚   â”œâ”€â”€ Rank 0: pytest â†’ test_perf_sanity.py â†’ subprocess.Popen(["trtllm-serve", ...])
â”‚   â”‚   â”œâ”€â”€ Rank 1: pytest â†’ test_perf_sanity.py â†’ subprocess.Popen(["trtllm-serve", ...])
â”‚   â”‚   â”œâ”€â”€ Rank 2: pytest â†’ test_perf_sanity.py â†’ subprocess.Popen(["trtllm-serve", ...])
â”‚   â”‚   â””â”€â”€ Rank 3: pytest â†’ test_perf_sanity.py â†’ subprocess.Popen(["trtllm-serve", ...])
â”‚   â†“
â”‚   æ‰€æœ‰ 4 ä¸ª trtllm-serve è¿›ç¨‹é€šè¿‡ NCCL ç»„æˆä¸€ä¸ª TP=4 çš„ GEN server
â”‚
â”œâ”€â”€ CTX_0: srun -N 1 -n 4 slurm_run.sh
â”‚   â†“ DISAGG_SERVING_TYPE=CTX_0
â”‚   â†“ trtllm-llmapi-launch pytest test_perf_sanity.py
â”‚   â†“ ï¼ˆåŒæ ·çš„å¤šè¿›ç¨‹å¯åŠ¨ï¼‰
â”‚
â”œâ”€â”€ DISAGG_SERVER: srun -N 1 slurm_run.sh
â”‚   â†“ DISAGG_SERVING_TYPE=DISAGG_SERVER
â”‚   â†“ pytest test_perf_sanity.py ï¼ˆå•è¿›ç¨‹ï¼Œä¸éœ€è¦ llmapi-launchï¼‰
â”‚   â†“ subprocess.Popen(["trtllm-serve-coordinator", ...])
â”‚
â””â”€â”€ BENCHMARK: srun -N 1 slurm_run.sh
    â†“ DISAGG_SERVING_TYPE=BENCHMARK
    â†“ pytest test_perf_sanity.py ï¼ˆå•è¿›ç¨‹ï¼Œä¸éœ€è¦ llmapi-launchï¼‰
    â†“ subprocess.check_output(["benchmark_serving", ...])
```

---

## ðŸ”§ run_disagg_test.sh å¿…é¡»æ·»åŠ  trtllm-llmapi-launch

### å½“å‰ä»£ç ï¼ˆé”™è¯¯ï¼‰âŒ

```bash
export pytestCommand="pytest perf/test_perf_sanity.py::test_e2e[disagg_upload-${CONFIG_NAME}] -vv --junit-xml=$WORKSPACE/results.xml"
```

**é—®é¢˜ï¼š**
- âŒ ç¼ºå°‘ trtllm-llmapi-launch
- âŒ CTX/GEN servers æ— æ³•æ­£ç¡®å¯åŠ¨å¤šè¿›ç¨‹
- âŒ æ— æ³•è¿›è¡Œ NCCL é€šä¿¡
- âŒ æµ‹è¯•ä¼šå¤±è´¥ï¼

---

### æ­£ç¡®çš„å®žçŽ°ï¼ˆå¿…é¡»ä¿®æ”¹ï¼‰âœ…

```bash
# æ­¥éª¤ 0: åˆ¤æ–­æ˜¯å¦éœ€è¦ llmapi-launch
if [ "$TOTAL_NODES" -gt 1 ] || [ "$GPUS_PER_NODE" -gt 1 ]; then
    PYTEST_UTIL="$TRTLLM_DIR/tensorrt_llm/llmapi/trtllm-llmapi-launch"
else
    PYTEST_UTIL=""
fi

# æ­¥éª¤ 4.2: ç”Ÿæˆ slurm_launch_prefix.shï¼ˆå®Œæ•´ç‰ˆï¼‰
cat > "$SCRIPT_PREFIX_FILE" << EOFPREFIX
#!/bin/bash
# ... SBATCH directives ...

export jobWorkspace=$WORKSPACE/disagg_workspace
export llmSrcNode=$TRTLLM_DIR
export stageName="disagg_perf_test_${CONFIG_NAME}"
export perfMode=true
export resourcePathNode=$TRTLLM_DIR

# âœ… å…³é”®ï¼šæ·»åŠ çŽ¯å¢ƒå˜é‡å’Œ llmapi-launch
export pytestCommand="LLM_ROOT=$TRTLLM_DIR \\
LLM_MODELS_ROOT=$CLUSTER_LLM_DATA \\
MODEL_CACHE_DIR=$CLUSTER_LLM_DATA \\
NCCL_DEBUG=INFO \\
$PYTEST_UTIL \\
pytest ${PERF_TEST_MODULE}::${PERF_TEST_FUNCTION}[${PERF_TEST_PREFIX}-${CONFIG_NAME}] \\
-vv \\
--junit-xml=$WORKSPACE/results.xml"

export coverageConfigFile=$WORKSPACE/coverage_config.json
export NVIDIA_IMEX_CHANNELS=\\\${NVIDIA_IMEX_CHANNELS:-0}
export NVIDIA_VISIBLE_DEVICES=\\\${NVIDIA_VISIBLE_DEVICES:-\\\$(seq -s, 0 \\\$((\\\$(nvidia-smi --query-gpu=count -i 0 --format=csv,noheader)-1)))}
EOFPREFIX
```

---

## ðŸ“Š submit.py çš„æ™ºèƒ½å¤„ç†

**submit.py ä¼šè‡ªåŠ¨å¤„ç† trtllm-llmapi-launchï¼š**

```python
# submit.py è¯»å– slurm_launch_prefix.sh
pytest_command_line = "export pytestCommand=\"... trtllm-llmapi-launch pytest ...\""

# ç”Ÿæˆä¸¤ä¸ªç‰ˆæœ¬
pytestCommand = "... trtllm-llmapi-launch pytest ..."  # å¸¦ llmapi-launch
pytestCommandNoLLMAPILaunch = "... pytest ..."  # ä¸å¸¦ llmapi-launch

# æ´¾ç”Ÿå‘½ä»¤
pytestCommandWorker = "unset UCX_TLS && ... $pytestCommand"  # â† GEN/CTX ä½¿ç”¨ï¼Œå¸¦ llmapi-launch
pytestCommandDisaggServer = "... $pytestCommandNoLLMAPILaunch"  # â† DISAGG_SERVER ä½¿ç”¨ï¼Œä¸å¸¦
pytestCommandBenchmark = "$pytestCommandNoLLMAPILaunch"  # â† BENCHMARK ä½¿ç”¨ï¼Œä¸å¸¦
```

**æœ€ç»ˆæ‰§è¡Œï¼š**

| ç»„ä»¶ | ä½¿ç”¨çš„å‘½ä»¤ | æ˜¯å¦æœ‰ llmapi-launch | åŽŸå›  |
|------|-----------|---------------------|------|
| **GEN servers** | `pytestCommandWorker` | âœ… æœ‰ | éœ€è¦å¤š GPU TP é€šä¿¡ |
| **CTX servers** | `pytestCommandWorker` | âœ… æœ‰ | éœ€è¦å¤š GPU TP é€šä¿¡ |
| **DISAGG_SERVER** | `pytestCommandDisaggServer` | âŒ æ—  | å•è¿›ç¨‹åè°ƒå™¨ |
| **BENCHMARK** | `pytestCommandBenchmark` | âŒ æ—  | å•è¿›ç¨‹å®¢æˆ·ç«¯ |

---

## ðŸŽ¯ test_perf_sanity.py çš„å®žé™…æ‰§è¡Œæµç¨‹

### GEN/CTX ç»„ä»¶ï¼ˆå¤šè¿›ç¨‹ï¼‰

```
slurm_run.sh æ‰§è¡Œ:
  trtllm-llmapi-launch pytest test_perf_sanity.py
  â†“
trtllm-llmapi-launch å¯åŠ¨ 4 ä¸ª pytest è¿›ç¨‹ï¼ˆTP=4ï¼‰
  â†“
â”œâ”€â”€ Rank 0 (GPU 0):
â”‚   pytest test_perf_sanity.py
â”‚   â†“ test_e2e() å‡½æ•°
â”‚   â†“ è¯»å– DISAGG_SERVING_TYPE=GEN_0
â”‚   â†“ run_cmd() ä¸­åˆ¤æ–­æ˜¯ GEN
â”‚   â†“ subprocess.Popen(["trtllm-serve", model, "--host", "xxx", "--port", "8000"])
â”‚   â†“ trtllm-serve å¯åŠ¨ï¼ˆRank 0ï¼ŒMASTERï¼‰
â”‚
â”œâ”€â”€ Rank 1 (GPU 1):
â”‚   pytest test_perf_sanity.py
â”‚   â†“ subprocess.Popen(["trtllm-serve", ...])
â”‚   â†“ trtllm-serve å¯åŠ¨ï¼ˆRank 1ï¼ŒWORKERï¼‰
â”‚
â”œâ”€â”€ Rank 2 (GPU 2):
â”‚   pytest test_perf_sanity.py
â”‚   â†“ subprocess.Popen(["trtllm-serve", ...])
â”‚   â†“ trtllm-serve å¯åŠ¨ï¼ˆRank 2ï¼ŒWORKERï¼‰
â”‚
â””â”€â”€ Rank 3 (GPU 3):
    pytest test_perf_sanity.py
    â†“ subprocess.Popen(["trtllm-serve", ...])
    â†“ trtllm-serve å¯åŠ¨ï¼ˆRank 3ï¼ŒWORKERï¼‰
    â†“
æ‰€æœ‰ 4 ä¸ª trtllm-serve è¿›ç¨‹é€šè¿‡ NCCL ç»„æˆä¸€ä¸ª TP=4 çš„æœåŠ¡
```

**å…³é”®ç‚¹ï¼š**
- âœ… `trtllm-llmapi-launch` å¯åŠ¨å¤šä¸ª pytest è¿›ç¨‹
- âœ… æ¯ä¸ª pytest è¿›ç¨‹è°ƒç”¨ `subprocess.Popen(["trtllm-serve", ...])`
- âœ… æ¯ä¸ª `trtllm-serve` è¿›ç¨‹æœ‰è‡ªå·±çš„ RANK å’Œ GPU
- âœ… æ‰€æœ‰è¿›ç¨‹é€šè¿‡ NCCL é€šä¿¡

---

### DISAGG_SERVER å’Œ BENCHMARKï¼ˆå•è¿›ç¨‹ï¼‰

```
slurm_run.sh æ‰§è¡Œ:
  pytest test_perf_sanity.py ï¼ˆä¸å¸¦ llmapi-launchï¼‰
  â†“
å•ä¸ª pytest è¿›ç¨‹
  â†“ test_e2e() å‡½æ•°
  â†“ è¯»å– DISAGG_SERVING_TYPE=DISAGG_SERVER æˆ– BENCHMARK
  â†“ run_cmd() ä¸­åˆ¤æ–­ç±»åž‹
  â†“ subprocess.Popen(["trtllm-serve-coordinator", ...]) æˆ–
  â†“ subprocess.check_output(["benchmark_serving", ...])
```

**å…³é”®ç‚¹ï¼š**
- âŒ ä¸éœ€è¦ `trtllm-llmapi-launch`
- âœ… å•è¿›ç¨‹æ‰§è¡Œ
- âœ… ä¸éœ€è¦ NCCL é€šä¿¡

---

## âœ… æœ€ç»ˆç»“è®º

### æˆ‘ä¹‹å‰çš„é”™è¯¯

1. âŒ é”™è¯¯åœ°è®¤ä¸º test_perf_sanity.py ä¸ä½¿ç”¨ trtllm-llmapi-launch
2. âŒ é”™è¯¯åœ°è®¤ä¸º trtllm-serve å¯ä»¥è‡ªå·±ç®¡ç†å¤š GPUï¼ˆåªå¯¹å•èŠ‚ç‚¹æœ‰é™é€‚ç”¨ï¼‰
3. âŒ é”™è¯¯åœ°è®¤ä¸º run_disagg_test.sh ä¸éœ€è¦æ·»åŠ  trtllm-llmapi-launch

### æ­£ç¡®çš„ç†è§£

1. âœ… **L0_Test.groovy ç¡®å®žä¼ é€’äº† trtllm-llmapi-launch**
2. âœ… **examples/disaggregated æ˜Žç¡®ä½¿ç”¨ trtllm-llmapi-launch**
3. âœ… **CTX/GEN servers å¿…é¡»ä½¿ç”¨ trtllm-llmapi-launch æ‰èƒ½æ­£å¸¸å·¥ä½œ**
4. âœ… **run_disagg_test.sh å¿…é¡»æ·»åŠ  trtllm-llmapi-launch**

---

## ðŸ”§ å¿…é¡»çš„ä¿®æ”¹æ¸…å•

### run_disagg_test.sh éœ€è¦å®Œå…¨é‡å†™ pytestCommand ç”Ÿæˆéƒ¨åˆ†

**å¿…é¡»åŒ…å«ï¼š**
1. âœ… åˆ¤æ–­ `nodeCount` å’Œ `gpusPerNode` æ¥å†³å®šæ˜¯å¦éœ€è¦ llmapi-launch
2. âœ… æ·»åŠ çŽ¯å¢ƒå˜é‡ï¼ˆ`LLM_ROOT`ã€`MODEL_CACHE_DIR`ã€`NCCL_DEBUG` ç­‰ï¼‰
3. âœ… æ’å…¥ `trtllm-llmapi-launch` åˆ° pytest ä¹‹å‰
4. âœ… å®Œæ•´çš„ pytest å‚æ•°ï¼ˆtimeoutã€rootdir ç­‰ï¼‰

---

## ðŸ“š éœ€è¦æ›´æ­£çš„æ–‡æ¡£

ä»¥ä¸‹æ–‡æ¡£éœ€è¦å…¨é¢æ›´æ­£ï¼š
1. âŒ `jenkins_test/docs/CLARIFICATION_NO_LLMAPI_LAUNCH.md` - å®Œå…¨é”™è¯¯
2. âŒ `jenkins_test/docs/L0_VS_DISAGG_PYTEST_COMMAND.md` - éƒ¨åˆ†é”™è¯¯
3. âš ï¸ `jenkins_test/docs/CUSTOM_PERF_TEST_GUIDE.md` - éœ€è¦æ›´æ–°å®žçŽ°ç»†èŠ‚

---

## ðŸ™ æ·±åˆ»çš„é“æ­‰

**æˆ‘ä¸ºä¹‹å‰çš„é”™è¯¯åˆ†æžæ·±è¡¨æ­‰æ„ï¼**

ä½ çš„è§‚å¯Ÿå®Œå…¨æ­£ç¡®ï¼š
- âœ… L0_Test.groovy ç¡®å®žä¼ é€’äº† trtllm-llmapi-launch
- âœ… Disaggregated æ¨¡å¼çš„ CTX/GEN å¿…é¡»ä½¿ç”¨ trtllm-llmapi-launch
- âœ… æ²¡æœ‰ trtllm-llmapi-launchï¼ŒCTX/GEN æ ¹æœ¬æ— æ³•è¿›è¡Œå¤š GPU é€šä¿¡

**æ„Ÿè°¢ä½ çš„çº æ­£ï¼è¿™æ˜¯ä¸€ä¸ªå…³é”®çš„å‘çŽ°ï¼** ðŸ™
