# ä½¿ç”¨ trt_perf_parser.py å‘ perf_db ä¸Šä¼  Disagg æ€§èƒ½æ•°æ®

> å®Œæ•´æŒ‡å—ï¼šåœ¨é›†ç¾¤å†…ä½¿ç”¨ trt_perf_parser.py ä¸Šä¼  disagg æµ‹è¯•æ€§èƒ½æ•°æ®åˆ° TRT_perf æ•°æ®åº“

---

## ğŸ“‹ æ¦‚è¿°

### å½“å‰çŠ¶æ€ vs ç›®æ ‡çŠ¶æ€

| ç»´åº¦ | å½“å‰ Disagg æµ‹è¯• | ä½¿ç”¨ trt_perf_parser.py |
|------|------------------|------------------------|
| **æ•°æ®å­˜å‚¨** | âœ… OpenSearchï¼ˆé€šè¿‡ test_perf_sanity.pyï¼‰ | âœ… MySQL TRT_perf æ•°æ®åº“ |
| **æ•°æ®æ ¼å¼** | JSON (ç›´æ¥ POST) | CSV â†’ è§£æ â†’ æ’å…¥ |
| **æŸ¥çœ‹æ–¹å¼** | OpenSearch æŸ¥è¯¢ | TRTPerf ç½‘é¡µ |
| **é€‚ç”¨åœºæ™¯** | è‡ªåŠ¨åŒ–æµ‹è¯•ã€å›å½’æ£€æµ‹ | å†å²è¿½è¸ªã€æ€§èƒ½å¯¹æ¯” |

**ç»“è®ºï¼šä¸¤ä¸ªç³»ç»Ÿå¯ä»¥å¹¶å­˜ï¼**
- âœ… **OpenSearch**: å·²ç»é›†æˆåœ¨ `test_perf_sanity.py` ä¸­ï¼ˆæ— éœ€ä¿®æ”¹ï¼‰
- âœ… **TRT_perf DB**: éœ€è¦é¢å¤–è°ƒç”¨ `trt_perf_parser.py`ï¼ˆæœ¬æ–‡æ¡£è¯´æ˜å¦‚ä½•é›†æˆï¼‰

---

## ğŸ¯ trt_perf_parser.py å·¥ä½œåŸç†

### è¾“å…¥è¦æ±‚

```python
# å¿…éœ€è¾“å…¥
--source-metric-csv          # CSV æ–‡ä»¶è·¯å¾„ï¼ŒåŒ…å«æ€§èƒ½æŒ‡æ ‡
                            # ä¾‹å¦‚ï¼šperf_script_test_results.csv

# å¯é€‰ä½†æ¨èè¾“å…¥
--source-properties         # Session å±æ€§ CSVï¼ˆç³»ç»Ÿä¿¡æ¯ï¼‰
--source-gpu-monitoring     # GPU ç›‘æ§æ•°æ® CSV
--junit-xml                 # JUnit XML æ–‡ä»¶ï¼ˆç”¨äºæå–æ—¥å¿—ï¼‰

# ç³»ç»Ÿä¿¡æ¯ï¼ˆå¿…éœ€ï¼‰
--tensorrt      # TensorRT ç‰ˆæœ¬
--trtllm        # TensorRT-LLM ç‰ˆæœ¬
--driver        # GPU é©±åŠ¨ç‰ˆæœ¬
--gpu           # GPU å‹å·
--cuda          # CUDA ç‰ˆæœ¬
--os            # æ“ä½œç³»ç»Ÿ

# æµ‹è¯•å…ƒæ•°æ®ï¼ˆæ¨èï¼‰
--start-time    # å¼€å§‹æ—¶é—´ "YYYY-MM-DD HH:MM:SS"
--end-time      # ç»“æŸæ—¶é—´ "YYYY-MM-DD HH:MM:SS"
--commit        # Git commit hash
--link          # Jenkins ä½œä¸šé“¾æ¥
--notes         # å¤‡æ³¨ä¿¡æ¯

# æ•°æ®åº“é…ç½®ï¼ˆå¯é€‰ï¼Œæœ‰é»˜è®¤å€¼ï¼‰
--DB-host       # é»˜è®¤ï¼šdlswqa-nas.nvidia.com
--DB-port       # é»˜è®¤ï¼š13306
--DB-user       # é»˜è®¤ï¼šswqa
--DB-password   # é»˜è®¤ï¼šlabuser
--DB-schema     # é»˜è®¤ï¼šTRT_perf

# æ§åˆ¶å‚æ•°
--write-db      # æ˜¯å¦å†™å…¥æ•°æ®åº“ï¼ˆyes/noï¼Œé»˜è®¤ yesï¼‰
--verbose       # è¯¦ç»†è¾“å‡º
```

### è¾“å‡º

1. **æ•°æ®åº“è¡¨ï¼š`TRT_perf.runs`**
   - è®°å½•æµ‹è¯•è¿è¡Œçš„ç³»ç»Ÿä¿¡æ¯
   - è¿”å› `run_id`

2. **æ•°æ®åº“è¡¨ï¼š`TRT_perf.cases`**
   - è®°å½•æµ‹è¯•ç”¨ä¾‹ï¼ˆnetwork, batch_size, precision ç­‰ï¼‰
   - è¿”å› `case_id`

3. **æ•°æ®åº“è¡¨ï¼š`TRT_perf.perf_result`**
   - è®°å½•æ€§èƒ½ç»“æœï¼ˆthroughput, latency, ç­‰ï¼‰
   - å…³è” `run_id` å’Œ `case_id`

4. **TRTPerf ç½‘é¡µé“¾æ¥**
   ```
   http://dlswqa.nvidia.com/trtperf?req=get_html&run_ids=<run_id>&baseline=--&target=--&drop_limit=5&time_limit=0.0&gap_limit=-999.9&only_show_drop=true
   ```

---

## âŒ é—®é¢˜ï¼šDisagg æµ‹è¯•ä¸ç”Ÿæˆ CSV æ–‡ä»¶

### å½“å‰ Disagg æµ‹è¯•æµç¨‹

```python
# test_perf_sanity.py (1491-1520 è¡Œ)
def test_e2e(output_dir, perf_sanity_test_case):
    config = PerfSanityTestConfig(perf_sanity_test_case, output_dir)
    config.parse_config_file()
    commands = config.get_commands()
    outputs = config.run_ex(commands)
    
    # åªæœ‰ BENCHMARK èŠ‚ç‚¹å¤„ç†ç»“æœ
    if config.runtime == "multi_node_disagg_server":
        disagg_config = config.server_configs[0][2]
        if disagg_config.disagg_serving_type != "BENCHMARK":
            return  # GEN/CTX/DISAGG_SERVER ç›´æ¥è¿”å›
    
    # è§£ææ€§èƒ½ç»“æœï¼ˆå­˜å‚¨åœ¨å†…å­˜ä¸­ï¼‰
    config.get_perf_result(outputs)
    
    # æ£€æŸ¥æµ‹è¯•å¤±è´¥
    config.check_test_failure()
    
    # âŒ ç›´æ¥ä¸Šä¼ åˆ° OpenSearchï¼Œæ²¡æœ‰ç”Ÿæˆ CSV
    config.upload_test_results_to_database()
```

**é—®é¢˜ï¼š**
- âœ… æ€§èƒ½æ•°æ®åœ¨å†…å­˜ä¸­ï¼ˆ`config._perf_results`ï¼‰
- âŒ æ²¡æœ‰å¯¼å‡ºä¸º CSV æ–‡ä»¶
- âŒ `trt_perf_parser.py` éœ€è¦ CSV è¾“å…¥

---

## âœ… è§£å†³æ–¹æ¡ˆï¼šä¸‰ç§é›†æˆæ–¹å¼

### æ–¹æ¡ˆ 1: ä¿®æ”¹ test_perf_sanity.py å¯¼å‡º CSVï¼ˆæ¨èï¼‰â­

**ä¼˜ç‚¹ï¼š**
- âœ… ä¸€æ¬¡è¿è¡Œï¼Œä¸¤ä¸ªæ•°æ®åº“éƒ½æ›´æ–°
- âœ… æ•°æ®ä¸€è‡´æ€§æœ€å¥½
- âœ… è‡ªåŠ¨åŒ–ç¨‹åº¦é«˜

**ç¼ºç‚¹ï¼š**
- âŒ éœ€è¦ä¿®æ”¹ test_perf_sanity.py
- âŒ éœ€è¦ç†è§£ä»£ç ç»“æ„

#### å®æ–½æ­¥éª¤

**æ­¥éª¤ 1: åœ¨ test_perf_sanity.py æ·»åŠ  CSV å¯¼å‡ºåŠŸèƒ½**

åœ¨ `PerfSanityTestConfig` ç±»ä¸­æ·»åŠ æ–¹æ³•ï¼ˆå»ºè®®åœ¨ 1520 è¡Œä¹‹åï¼‰ï¼š

```python
# tests/integration/defs/perf/test_perf_sanity.py

def export_results_to_csv(self, csv_path: str):
    """Export performance results to CSV for trt_perf_parser.py"""
    import csv
    
    if not self._perf_results:
        print_info("No performance results to export")
        return
    
    csv_rows = []
    
    if self.runtime == "multi_node_disagg_server":
        # Only BENCHMARK node exports
        if self.server_configs[0][2].disagg_serving_type != "BENCHMARK":
            return
        
        for server_idx, (ctx_config, gen_config, disagg_config) in enumerate(self.server_configs):
            client_configs = self.server_client_configs[server_idx]
            server_perf_results = self._perf_results.get(server_idx, [])
            
            for client_idx, client_config in enumerate(client_configs):
                if client_idx >= len(server_perf_results) or server_perf_results[client_idx] is None:
                    continue
                
                perf_data = server_perf_results[client_idx]
                
                # Build CSV row
                row = {
                    'network': disagg_config.name,
                    'batchsize': client_config.concurrency,
                    'precision': gen_config.dtype,
                    'framework': 'TensorRT-LLM',
                    'command': f"disagg_{ctx_config.name}_{gen_config.name}",
                }
                
                # Add performance metrics
                for metric_name, metric_value in perf_data.items():
                    # Convert metric names to trt_perf_parser format
                    # e.g., "mean_ttft" -> "mean_ttft__ms"
                    if metric_name in ['mean_ttft', 'median_ttft', 'p99_ttft']:
                        row[f'{metric_name}__ms'] = metric_value
                    elif metric_name in ['mean_e2el', 'median_e2el', 'p99_e2el']:
                        row[f'{metric_name}__ms'] = metric_value
                    elif metric_name == 'token_throughput':
                        row['throughput__qps'] = metric_value
                    elif metric_name == 'seq_throughput':
                        row['tokens_per__sec'] = metric_value
                    else:
                        row[metric_name] = metric_value
                
                csv_rows.append(row)
    
    elif self.runtime == "aggr_server":
        # Aggregated server export logic
        for server_idx, client_configs in self.server_client_configs.items():
            server_config = self.server_configs[server_idx]
            server_perf_results = self._perf_results.get(server_idx, [])
            
            for client_idx, client_config in enumerate(client_configs):
                if client_idx >= len(server_perf_results) or server_perf_results[client_idx] is None:
                    continue
                
                perf_data = server_perf_results[client_idx]
                row = {
                    'network': server_config.name,
                    'batchsize': client_config.concurrency,
                    'precision': server_config.dtype,
                    'framework': 'TensorRT-LLM',
                    'command': f"aggr_{server_config.name}_{client_config.name}",
                }
                
                for metric_name, metric_value in perf_data.items():
                    if metric_name in ['mean_ttft', 'median_ttft', 'p99_ttft']:
                        row[f'{metric_name}__ms'] = metric_value
                    elif metric_name in ['mean_e2el', 'median_e2el', 'p99_e2el']:
                        row[f'{metric_name}__ms'] = metric_value
                    elif metric_name == 'token_throughput':
                        row['throughput__qps'] = metric_value
                    elif metric_name == 'seq_throughput':
                        row['tokens_per__sec'] = metric_value
                    else:
                        row[metric_name] = metric_value
                
                csv_rows.append(row)
    
    # Write to CSV
    if csv_rows:
        fieldnames = list(csv_rows[0].keys())
        with open(csv_path, 'w', newline='') as csvfile:
            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
            writer.writeheader()
            writer.writerows(csv_rows)
        print_info(f"Exported {len(csv_rows)} results to {csv_path}")
    else:
        print_info("No results to export")
```

**æ­¥éª¤ 2: åœ¨ test_e2e() ä¸­è°ƒç”¨å¯¼å‡º**

ä¿®æ”¹ `test_e2e()` å‡½æ•°ï¼ˆ1491-1520 è¡Œï¼‰ï¼š

```python
def test_e2e(output_dir, perf_sanity_test_case):
    # ... ç°æœ‰ä»£ç  ...
    
    # Parse performance results
    config.get_perf_result(outputs)
    
    # Check for test failures
    config.check_test_failure()
    
    # âœ… æ–°å¢ï¼šå¯¼å‡º CSV ä¾› trt_perf_parser.py ä½¿ç”¨
    csv_output_path = os.path.join(
        config.perf_sanity_output_dir,
        "perf_script_test_results.csv"
    )
    config.export_results_to_csv(csv_output_path)
    
    # Upload results to database (OpenSearch)
    config.upload_test_results_to_database()
```

**æ­¥éª¤ 3: åœ¨ slurm_run.sh ä¸­è°ƒç”¨ trt_perf_parser.py**

åœ¨ `slurm_run.sh` çš„æ€§èƒ½æŠ¥å‘Šéƒ¨åˆ†ä¹‹åæ·»åŠ ï¼ˆçº¦ 154 è¡Œä¹‹åï¼‰ï¼š

```bash
# åœ¨ slurm_run.sh ä¸­æ·»åŠ ï¼ˆ154 è¡Œä¹‹åï¼‰
if [ $SLURM_PROCID -eq 0 ] && [ "$perfMode" = "true" ] && [ "$USE_TRT_PERF_DB" = "true" ]; then
    echo "Uploading to TRT_perf database..."
    
    # æ£€æŸ¥ CSV æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    CSV_FILE="$stageName/perf_script_test_results.csv"
    if [ ! -f "$CSV_FILE" ]; then
        echo "Warning: CSV file not found: $CSV_FILE"
    else
        # è·å–ç³»ç»Ÿä¿¡æ¯
        DRIVER_VERSION=$(nvidia-smi --query-gpu=driver_version --format=csv,noheader | head -1)
        GPU_NAME=$(nvidia-smi --query-gpu=name --format=csv,noheader | head -1)
        CUDA_VERSION=$(nvcc --version | grep "release" | awk '{print $5}' | sed 's/,//')
        
        # è°ƒç”¨ trt_perf_parser.py
        python3 "$llmSrcNode/../jenkins_test/trt_perf_parser.py" \
            --source-metric-csv "$CSV_FILE" \
            --tensorrt "${TRT_VERSION:-unknown}" \
            --trtllm "${TRTLLM_VERSION:-unknown}" \
            --driver "$DRIVER_VERSION" \
            --gpu "$GPU_NAME" \
            --cuda "$CUDA_VERSION" \
            --os "$(cat /etc/os-release | grep PRETTY_NAME | cut -d '=' -f2 | tr -d '\"')" \
            --start-time "${TEST_START_TIME:-$(date '+%Y-%m-%d %H:%M:%S')}" \
            --end-time "$(date '+%Y-%m-%d %H:%M:%S')" \
            --commit "${GIT_COMMIT:-unknown}" \
            --link "${BUILD_URL:-}" \
            --notes "Disagg test: $stageName" \
            --write-db yes \
            --verbose
    fi
fi
```

---

### æ–¹æ¡ˆ 2: åå¤„ç†è„šæœ¬ï¼ˆæ— éœ€ä¿®æ”¹ test_perf_sanity.pyï¼‰

**ä¼˜ç‚¹ï¼š**
- âœ… ä¸ä¿®æ”¹ç°æœ‰ä»£ç 
- âœ… çµæ´»æ§åˆ¶

**ç¼ºç‚¹ï¼š**
- âŒ éœ€è¦ä» results.xml æˆ–æ—¥å¿—ä¸­æå–æ€§èƒ½æ•°æ®
- âŒ æ•°æ®è§£æå¤æ‚

#### å®æ–½æ­¥éª¤

**æ­¥éª¤ 1: åˆ›å»ºæ€§èƒ½æ•°æ®æå–è„šæœ¬**

`jenkins_test/scripts/extract_perf_from_junit.py`:

```python
#!/usr/bin/env python3
"""Extract performance data from JUnit XML and generate CSV for trt_perf_parser.py"""

import xml.etree.ElementTree as ET
import csv
import re
import argparse
import sys

# Performance metric patterns (from test_perf_sanity.py)
PERF_METRIC_PATTERNS = {
    "seq_throughput": re.compile(r"Request throughput \(req\/s\):\s+(-?[\d\.]+)"),
    "token_throughput": re.compile(r"Output token throughput \(tok\/s\):\s+(-?[\d\.]+)"),
    "total_token_throughput": re.compile(r"Total Token throughput \(tok\/s\):\s+(-?[\d\.]+)"),
    "mean_ttft": re.compile(r"Mean TTFT \(ms\):\s+(-?[\d\.]+)"),
    "median_ttft": re.compile(r"Median TTFT \(ms\):\s+(-?[\d\.]+)"),
    "p99_ttft": re.compile(r"P99 TTFT \(ms\):\s+(-?[\d\.]+)"),
    "mean_e2el": re.compile(r"Mean E2EL \(ms\):\s+(-?[\d\.]+)"),
    "median_e2el": re.compile(r"Median E2EL \(ms\):\s+(-?[\d\.]+)"),
    "p99_e2el": re.compile(r"P99 E2EL \(ms\):\s+(-?[\d\.]+)"),
}

def extract_perf_from_junit(junit_xml_path):
    """Extract performance metrics from JUnit XML file"""
    tree = ET.parse(junit_xml_path)
    root = tree.getroot()
    
    results = []
    
    for testcase in root.findall('.//testcase'):
        test_name = testcase.get('name', '')
        
        # Find system-out or system-err with performance data
        output = ""
        for elem in testcase.findall('.//system-out'):
            output += elem.text or ""
        for elem in testcase.findall('.//system-err'):
            output += elem.text or ""
        
        if not output:
            continue
        
        # Extract test case info from name
        # Format: test_e2e[disagg_upload-deepseek-r1-fp4_...]
        match = re.search(r'\[disagg_upload-(.+)\]', test_name)
        if not match:
            continue
        
        config_name = match.group(1)
        
        # Extract metrics from output
        metrics = {'network': config_name, 'framework': 'TensorRT-LLM'}
        
        for metric_name, pattern in PERF_METRIC_PATTERNS.items():
            match = pattern.search(output)
            if match:
                value = match.group(1)
                # Convert metric names to CSV format
                if metric_name in ['mean_ttft', 'median_ttft', 'p99_ttft']:
                    metrics[f'{metric_name}__ms'] = value
                elif metric_name in ['mean_e2el', 'median_e2el', 'p99_e2el']:
                    metrics[f'{metric_name}__ms'] = value
                elif metric_name == 'token_throughput':
                    metrics['throughput__qps'] = value
                elif metric_name == 'seq_throughput':
                    metrics['tokens_per__sec'] = value
                else:
                    metrics[metric_name] = value
        
        if len(metrics) > 2:  # Has more than just network and framework
            results.append(metrics)
    
    return results

def write_csv(results, output_csv):
    """Write results to CSV file"""
    if not results:
        print("No results to write")
        return
    
    fieldnames = list(results[0].keys())
    with open(output_csv, 'w', newline='') as csvfile:
        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
        writer.writeheader()
        writer.writerows(results)
    
    print(f"Wrote {len(results)} results to {output_csv}")

def main():
    parser = argparse.ArgumentParser(description="Extract perf data from JUnit XML to CSV")
    parser.add_argument("--junit-xml", required=True, help="JUnit XML file path")
    parser.add_argument("--output-csv", required=True, help="Output CSV file path")
    
    args = parser.parse_args()
    
    results = extract_perf_from_junit(args.junit_xml)
    write_csv(results, args.output_csv)

if __name__ == "__main__":
    main()
```

**æ­¥éª¤ 2: åœ¨ slurm_run.sh æˆ– Jenkins ä¸­è°ƒç”¨**

```bash
# åœ¨æµ‹è¯•å®Œæˆå
python3 $llmSrcNode/../jenkins_test/scripts/extract_perf_from_junit.py \
    --junit-xml "$jobWorkspace/results.xml" \
    --output-csv "$jobWorkspace/perf_script_test_results.csv"

# ç„¶åè°ƒç”¨ trt_perf_parser.py
python3 $llmSrcNode/../jenkins_test/trt_perf_parser.py \
    --source-metric-csv "$jobWorkspace/perf_script_test_results.csv" \
    --tensorrt "..." \
    --trtllm "..." \
    # ... å…¶ä»–å‚æ•°
```

---

### æ–¹æ¡ˆ 3: Jenkins Pipeline åå¤„ç†ï¼ˆæœ€çµæ´»ï¼‰

**ä¼˜ç‚¹ï¼š**
- âœ… å®Œå…¨ä¸ä¿®æ”¹æµ‹è¯•ä»£ç 
- âœ… å¯ä»¥æ‰¹é‡å¤„ç†å¤šä¸ªæµ‹è¯•
- âœ… æ˜“äºè°ƒè¯•å’Œç»´æŠ¤

**ç¼ºç‚¹ï¼š**
- âŒ éœ€è¦åœ¨ Jenkins ä¸­é…ç½®
- âŒ ä¸æµ‹è¯•æ‰§è¡Œåˆ†ç¦»

#### å®æ–½æ­¥éª¤

åœ¨ `Perf_Test.groovy` ä¸­æ·»åŠ ï¼š

```groovy
stage('Upload to TRT_perf DB') {
    when {
        expression { params.UPLOAD_TO_TRTPERF == true }
    }
    steps {
        script {
            // æå–æ€§èƒ½æ•°æ®
            sh """
                python3 jenkins_test/scripts/extract_perf_from_junit.py \\
                    --junit-xml ${WORKSPACE}/disagg_workspace/results.xml \\
                    --output-csv ${WORKSPACE}/perf_results.csv
            """
            
            // è·å–ç³»ç»Ÿä¿¡æ¯
            def driverVersion = sh(returnStdout: true, script: 'nvidia-smi --query-gpu=driver_version --format=csv,noheader | head -1').trim()
            def gpuName = sh(returnStdout: true, script: 'nvidia-smi --query-gpu=name --format=csv,noheader | head -1').trim()
            def cudaVersion = sh(returnStdout: true, script: 'nvcc --version | grep "release" | awk \'{print \$5}\' | sed \'s/,//\'').trim()
            def trtllmVersion = sh(returnStdout: true, script: 'cd TensorRT-LLM && git describe --tags').trim()
            
            // ä¸Šä¼ åˆ° TRT_perf æ•°æ®åº“
            sh """
                python3 jenkins_test/trt_perf_parser.py \\
                    --source-metric-csv ${WORKSPACE}/perf_results.csv \\
                    --tensorrt "${TRT_VERSION}" \\
                    --trtllm "${trtllmVersion}" \\
                    --driver "${driverVersion}" \\
                    --gpu "${gpuName}" \\
                    --cuda "${cudaVersion}" \\
                    --os "${OS_VERSION}" \\
                    --start-time "${TEST_START_TIME}" \\
                    --end-time "\$(date '+%Y-%m-%d %H:%M:%S')" \\
                    --commit "${GIT_COMMIT}" \\
                    --link "${BUILD_URL}" \\
                    --notes "Disagg perf test - ${CONFIG_NAME}" \\
                    --write-db yes \\
                    --verbose
            """
        }
    }
}
```

---

## ğŸ“Š æ–¹æ¡ˆå¯¹æ¯”æ€»ç»“

| æ–¹æ¡ˆ | ä»£ç ä¿®æ”¹ | æ•°æ®è´¨é‡ | è‡ªåŠ¨åŒ– | çµæ´»æ€§ | æ¨èåº¦ |
|------|----------|---------|--------|--------|--------|
| **æ–¹æ¡ˆ 1: ä¿®æ”¹ test_perf_sanity.py** | ä¸­ç­‰ï¼ˆä¸€æ¬¡æ€§ï¼‰ | â­â­â­ æœ€å¥½ | â­â­â­ è‡ªåŠ¨ | â­â­ ä¸­ç­‰ | â­â­â­ æ¨è |
| **æ–¹æ¡ˆ 2: åå¤„ç†è„šæœ¬** | å°ï¼ˆæ–°å¢è„šæœ¬ï¼‰ | â­â­ å¥½ | â­â­ åŠè‡ªåŠ¨ | â­â­â­ é«˜ | â­â­ å¯ç”¨ |
| **æ–¹æ¡ˆ 3: Jenkins Pipeline** | æ— ï¼ˆä»… Groovyï¼‰ | â­â­ å¥½ | â­ æ‰‹åŠ¨è§¦å‘ | â­â­â­ æœ€é«˜ | â­â­ çµæ´» |

---

## ğŸ”§ å®Œæ•´é›†æˆç¤ºä¾‹ï¼ˆæ¨èæ–¹æ¡ˆ 1ï¼‰

### æ­¥éª¤ 1: ä¿®æ”¹ test_perf_sanity.py

æ·»åŠ  `export_results_to_csv()` æ–¹æ³•ï¼ˆè§ä¸Šæ–‡"æ–¹æ¡ˆ 1"ï¼‰

### æ­¥éª¤ 2: ä¿®æ”¹ slurm_run.sh

åœ¨ 154 è¡Œä¹‹åæ·»åŠ ï¼š

```bash
# ä¸Šä¼ åˆ° TRT_perf æ•°æ®åº“ï¼ˆå¯é€‰ï¼‰
if [ $SLURM_PROCID -eq 0 ] && [ "$perfMode" = "true" ] && [ "${USE_TRT_PERF_DB:-false}" = "true" ]; then
    echo "Uploading to TRT_perf database..."
    
    CSV_FILE="$stageName/perf_script_test_results.csv"
    if [ -f "$CSV_FILE" ]; then
        # è·å–ç³»ç»Ÿä¿¡æ¯
        DRIVER_VERSION=$(nvidia-smi --query-gpu=driver_version --format=csv,noheader | head -1)
        GPU_NAME=$(nvidia-smi --query-gpu=name --format=csv,noheader | head -1)
        CUDA_VERSION=$(nvcc --version | grep "release" | awk '{print $5}' | sed 's/,//')
        OS_INFO=$(cat /etc/os-release | grep PRETTY_NAME | cut -d '=' -f2 | tr -d '"')
        TRTLLM_VERSION=$(cd $llmSrcNode && git describe --tags 2>/dev/null || echo "unknown")
        
        # è°ƒç”¨ trt_perf_parser.py
        python3 "$llmSrcNode/../jenkins_test/trt_perf_parser.py" \
            --source-metric-csv "$CSV_FILE" \
            --tensorrt "${TRT_VERSION:-unknown}" \
            --trtllm "$TRTLLM_VERSION" \
            --driver "$DRIVER_VERSION" \
            --gpu "$GPU_NAME" \
            --cuda "$CUDA_VERSION" \
            --os "$OS_INFO" \
            --start-time "${TEST_START_TIME:-$(date '+%Y-%m-%d %H:%M:%S')}" \
            --end-time "$(date '+%Y-%m-%d %H:%M:%S')" \
            --commit "${GIT_COMMIT:-unknown}" \
            --link "${BUILD_URL:-}" \
            --hostname "$(hostname)" \
            --notes "Disagg test: $stageName, Config: ${CONFIG_NAME:-unknown}" \
            --write-db yes \
            --verbose || echo "Warning: Failed to upload to TRT_perf DB"
    else
        echo "Warning: CSV file not found: $CSV_FILE, skipping TRT_perf upload"
    fi
fi
```

### æ­¥éª¤ 3: ä¿®æ”¹ run_disagg_test.sh

åœ¨æ­¥éª¤ 4.2 çš„ `slurm_launch_prefix.sh` ä¸­æ·»åŠ ç¯å¢ƒå˜é‡ï¼š

```bash
# åœ¨ slurm_launch_prefix.sh ä¸­æ·»åŠ 
export USE_TRT_PERF_DB=${USE_TRT_PERF_DB:-false}  # æ§åˆ¶æ˜¯å¦ä¸Šä¼ åˆ° TRT_perf
export TEST_START_TIME="$(date '+%Y-%m-%d %H:%M:%S')"
export GIT_COMMIT=$(cd $TRTLLM_DIR && git rev-parse HEAD)
export CONFIG_NAME="${CONFIG_NAME}"
```

### æ­¥éª¤ 4: ä½¿ç”¨æ–¹å¼

```bash
# ä¸ä¸Šä¼ åˆ° TRT_perfï¼ˆé»˜è®¤ï¼Œåªä¸Šä¼ åˆ° OpenSearchï¼‰
bash jenkins_test/scripts/run_disagg_test.sh deepseek-r1-fp4_...

# åŒæ—¶ä¸Šä¼ åˆ° TRT_perf å’Œ OpenSearch
export USE_TRT_PERF_DB=true
bash jenkins_test/scripts/run_disagg_test.sh deepseek-r1-fp4_...
```

---

## ğŸ“ é›†ç¾¤å†…æ‰€éœ€å‰ç½®æ¡ä»¶

### 1. Python ä¾èµ–

```bash
pip install pymysql pandas
```

### 2. æ•°æ®åº“è®¿é—®æƒé™

```bash
# æµ‹è¯•æ•°æ®åº“è¿æ¥
python3 -c "
import pymysql
db = pymysql.connect(
    host='dlswqa-nas.nvidia.com',
    port=13306,
    user='swqa',
    password='labuser',
    database='TRT_perf'
)
print('Database connection successful!')
db.close()
"
```

å¦‚æœè¿æ¥å¤±è´¥ï¼š
- æ£€æŸ¥é˜²ç«å¢™è§„åˆ™
- æ£€æŸ¥ç½‘ç»œè¿é€šæ€§ï¼š`ping dlswqa-nas.nvidia.com`
- æ£€æŸ¥ç«¯å£å¼€æ”¾ï¼š`telnet dlswqa-nas.nvidia.com 13306`
- è”ç³» DLS QA å›¢é˜Ÿè·å–è®¿é—®æƒé™

### 3. ç¯å¢ƒå˜é‡ï¼ˆåœ¨ Jenkins æˆ– slurm_launch_prefix.sh ä¸­è®¾ç½®ï¼‰

```bash
# å¿…éœ€
export TRT_VERSION="10.0.0"          # TensorRT ç‰ˆæœ¬
export TRTLLM_VERSION="0.14.0"       # TensorRT-LLM ç‰ˆæœ¬ï¼ˆæˆ–ä» git describe è·å–ï¼‰
export GIT_COMMIT="abc123..."        # Git commit hash
export BUILD_URL="http://jenkins..." # Jenkins ä½œä¸šé“¾æ¥

# å¯é€‰ï¼ˆä¼šè‡ªåŠ¨æ£€æµ‹ï¼‰
export DRIVER_VERSION="550.54.15"
export GPU_NAME="NVIDIA H200"
export CUDA_VERSION="12.4"
export OS_VERSION="Ubuntu 22.04"
```

---

## ğŸ¯ éªŒè¯å’Œæµ‹è¯•

### æµ‹è¯• trt_perf_parser.py

```bash
# åˆ›å»ºæµ‹è¯• CSV
cat > /tmp/test_perf.csv << 'EOF'
network,batchsize,precision,framework,throughput__qps,mean_ttft__ms,mean_e2el__ms
deepseek-r1-fp4,768,fp4,TensorRT-LLM,1234.56,15.2,123.4
EOF

# è¿è¡Œ trt_perf_parser.pyï¼ˆdry-runï¼‰
python3 jenkins_test/trt_perf_parser.py \
    --source-metric-csv /tmp/test_perf.csv \
    --tensorrt "10.0.0" \
    --trtllm "0.14.0" \
    --driver "550.54.15" \
    --gpu "H200" \
    --cuda "12.4" \
    --os "Ubuntu 22.04" \
    --start-time "2025-02-02 10:00:00" \
    --end-time "2025-02-02 11:00:00" \
    --commit "abc123" \
    --notes "Test run" \
    --write-db no \
    --verbose

# æ£€æŸ¥è¾“å‡º
# åº”è¯¥çœ‹åˆ°è§£æçš„æ•°æ®å’Œ SQL è¯­å¥
```

### å®Œæ•´é›†æˆæµ‹è¯•

```bash
# 1. è¿è¡Œ disagg æµ‹è¯•ï¼ˆå¸¦ CSV å¯¼å‡ºï¼‰
export USE_TRT_PERF_DB=true
bash jenkins_test/scripts/run_disagg_test.sh deepseek-r1-fp4_1k1k_ctx1_gen1_dep8_bs768_eplb0_mtp0_ccb-UCX

# 2. æ£€æŸ¥ CSV æ˜¯å¦ç”Ÿæˆ
ls -lh $WORKSPACE/disagg_logs/deepseek-r1-fp4_*/perf_script_test_results.csv

# 3. æ£€æŸ¥ TRTPerf ç½‘é¡µ
# åœ¨ slurm_run.sh çš„è¾“å‡ºä¸­ä¼šæ‰“å°ç±»ä¼¼é“¾æ¥ï¼š
# http://dlswqa.nvidia.com/trtperf?req=get_html&run_ids=12345&...

# 4. éªŒè¯æ•°æ®åº“ä¸­çš„æ•°æ®
python3 -c "
import pymysql
db = pymysql.connect(host='dlswqa-nas.nvidia.com', port=13306, user='swqa', password='labuser', database='TRT_perf')
cursor = db.cursor()
cursor.execute('SELECT id, trtllm, notes FROM runs ORDER BY id DESC LIMIT 5')
for row in cursor.fetchall():
    print(row)
db.close()
"
```

---

## ğŸ“š ç›¸å…³æ–‡æ¡£

1. **trt_perf_parser.py æºç **: `jenkins_test/trt_perf_parser.py`
2. **test_perf_sanity.py æºç **: `tests/integration/defs/perf/test_perf_sanity.py`
3. **TRTPerf ç½‘é¡µ**: http://dlswqa.nvidia.com/trtperf
4. **æ•°æ®åº“ schema**: è§ `trt_perf_parser.py` å¼€å¤´çš„æ³¨é‡Šï¼ˆ20-74 è¡Œï¼‰

---

## ğŸ” å¸¸è§é—®é¢˜

### Q1: ä¸ºä»€ä¹ˆéœ€è¦ä¸¤ä¸ªæ•°æ®åº“ï¼ˆOpenSearch å’Œ TRT_perfï¼‰ï¼Ÿ

**A:** 
- **OpenSearch**: æ–°ç³»ç»Ÿï¼ŒåŠŸèƒ½ä¸°å¯Œï¼Œè‡ªåŠ¨å›å½’æ£€æµ‹
- **TRT_perf**: å†å²ç³»ç»Ÿï¼Œå·²æœ‰å¤§é‡å†å²æ•°æ®ï¼Œç”¨äºé•¿æœŸè¿½è¸ª

ä¸¤è€…å¯ä»¥å¹¶å­˜ï¼Œä¸å†²çªã€‚

### Q2: CSV æ–‡ä»¶æ ¼å¼è¦æ±‚ï¼Ÿ

**A:** å¿…é¡»åŒ…å«ä»¥ä¸‹å­—æ®µï¼š
- `network`: æµ‹è¯•æ¨¡å‹åç§°
- `framework`: æ¡†æ¶åç§°ï¼ˆé€šå¸¸æ˜¯ "TensorRT-LLM"ï¼‰
- è‡³å°‘ä¸€ä¸ªæ€§èƒ½æŒ‡æ ‡ï¼Œä¾‹å¦‚ï¼š
  - `throughput__qps`: ååé‡ï¼ˆQPSï¼‰
  - `mean_ttft__ms`: å¹³å‡é¦– token æ—¶é—´
  - `mean_e2el__ms`: å¹³å‡ç«¯åˆ°ç«¯å»¶è¿Ÿ

### Q3: å¦‚ä½•æŸ¥çœ‹ä¸Šä¼ çš„æ•°æ®ï¼Ÿ

**A:** é€šè¿‡ TRTPerf ç½‘é¡µï¼š
```
http://dlswqa.nvidia.com/trtperf?req=get_html&run_ids=<ä½ çš„run_id>
```

`run_id` ä¼šåœ¨ `trt_perf_parser.py` çš„è¾“å‡ºä¸­æ‰“å°ã€‚

### Q4: æ•°æ®åº“è¿æ¥å¤±è´¥æ€ä¹ˆåŠï¼Ÿ

**A:** 
1. æ£€æŸ¥æ˜¯å¦åœ¨ NVIDIA å†…ç½‘
2. æµ‹è¯•è¿æ¥ï¼š`telnet dlswqa-nas.nvidia.com 13306`
3. è”ç³» DLS QA å›¢é˜Ÿç”³è¯·è®¿é—®æƒé™

### Q5: å¦‚ä½•æ‰¹é‡ä¸Šä¼ å¤šä¸ªæµ‹è¯•çš„ç»“æœï¼Ÿ

**A:** æœ‰ä¸¤ç§æ–¹å¼ï¼š
1. æ¯ä¸ªæµ‹è¯•ç”Ÿæˆç‹¬ç«‹çš„ CSVï¼Œåˆ†åˆ«è°ƒç”¨ `trt_perf_parser.py`
2. åˆå¹¶å¤šä¸ª CSV æ–‡ä»¶ï¼Œä¸€æ¬¡æ€§ä¸Šä¼ ï¼ˆéœ€è¦ç¡®ä¿å­—æ®µä¸€è‡´ï¼‰

---

## âœ… å®æ–½å»ºè®®

### æœ€å°åŒ–å®æ–½ï¼ˆå¿«é€ŸéªŒè¯ï¼‰

1. âœ… ä½¿ç”¨**æ–¹æ¡ˆ 2**ï¼ˆåå¤„ç†è„šæœ¬ï¼‰
2. âœ… åªåœ¨ Jenkins Pipeline æœ€åæ·»åŠ ä¸€ä¸ª stage
3. âœ… å…ˆæ‰‹åŠ¨è¿è¡ŒéªŒè¯ï¼Œå†è‡ªåŠ¨åŒ–

### å®Œæ•´å®æ–½ï¼ˆç”Ÿäº§ç¯å¢ƒï¼‰

1. âœ… ä½¿ç”¨**æ–¹æ¡ˆ 1**ï¼ˆä¿®æ”¹ test_perf_sanity.pyï¼‰
2. âœ… åœ¨ `slurm_run.sh` ä¸­é›†æˆ
3. âœ… æ·»åŠ  `USE_TRT_PERF_DB` ç¯å¢ƒå˜é‡æ§åˆ¶
4. âœ… æ·»åŠ é”™è¯¯å¤„ç†å’Œæ—¥å¿—

---

**ç°åœ¨ä½ å¯ä»¥æ ¹æ®éœ€æ±‚é€‰æ‹©åˆé€‚çš„æ–¹æ¡ˆå¼€å§‹å®æ–½ï¼éœ€è¦æˆ‘å¸®ä½ å®é™…ä¿®æ”¹ä»£ç å—ï¼Ÿ** ğŸš€
