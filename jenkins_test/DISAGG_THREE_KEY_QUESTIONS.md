# Disagg æµ‹è¯•ä¸‰ä¸ªå…³é”®é—®é¢˜è§£ç­”

> è¯¦ç»†è§£ç­” pytestCommand å·®å¼‚ã€æ€§èƒ½æ£€æŸ¥è·³è¿‡ã€æ—¥å¿—æ”¶é›†æ–¹æ¡ˆ

---

## ğŸ“Œ é—®é¢˜ 1: pytestCommand çš„å·®å¼‚å’Œåˆ†æµæœºåˆ¶

### 1.1 ä¸‰ç§ pytestCommand çš„å·®å¼‚

åœ¨ `submit.py` (248-250 è¡Œ) ä¸­ç”Ÿæˆäº†ä¸‰ä¸ªä¸åŒçš„ pytestCommandï¼š

```bash
# åœ¨ submit.py ä¸­ç”Ÿæˆ
export pytestCommandWorker="unset UCX_TLS && ${worker_env_vars} $pytestCommand"
export pytestCommandDisaggServer="${server_env_vars} $pytestCommandNoLLMAPILaunch"
export pytestCommandBenchmark="${env_config["benchmark_env_var"]} $pytestCommandNoLLMAPILaunch"
```

#### å·®å¼‚å¯¹æ¯”è¡¨

| pytestCommand | ä½¿ç”¨åœºæ™¯ | ç¯å¢ƒå˜é‡å‰ç¼€ | æ˜¯å¦ä½¿ç”¨ llmapi-launch | DISAGG_SERVING_TYPE |
|---------------|----------|--------------|----------------------|---------------------|
| **pytestCommandWorker** | GEN/CTX Server | `unset UCX_TLS && worker_env_var` | âœ… æ˜¯ (`$pytestCommand`) | `GEN_0`, `GEN_1`, `CTX_0`, `CTX_1` |
| **pytestCommandDisaggServer** | DISAGG Server | `server_env_var` | âŒ å¦ (`$pytestCommandNoLLMAPILaunch`) | `DISAGG_SERVER` |
| **pytestCommandBenchmark** | Benchmark Client | `benchmark_env_var` | âŒ å¦ (`$pytestCommandNoLLMAPILaunch`) | `BENCHMARK` |

#### å…·ä½“å±•å¼€ç¤ºä¾‹

**åŸºç¡€å‘½ä»¤ (pytestCommand):**
```bash
pytestCommand="pytest perf/test_perf_sanity.py::test_e2e[disagg_upload-deepseek-r1-fp4_...] -vv --junit-xml=/workspace/results.xml"
```

**pytestCommandNoLLMAPILaunch:**
```bash
# submit.py é€šè¿‡ get_pytest_command_no_llmapilaunch() ç”Ÿæˆ
pytestCommandNoLLMAPILaunch="TRTLLM_SERVER_DISABLE_GC=1 pytest perf/test_perf_sanity.py..."
```

**å±•å¼€åçš„ä¸‰ä¸ªå‘½ä»¤:**

1. **pytestCommandWorker** (GEN/CTX ä½¿ç”¨):
   ```bash
   unset UCX_TLS && \
   TLLM_LOG_LEVEL=INFO \
   TRTLLM_WORKER_DISABLE_GC=1 \
   trtllm-llmapi-launch pytest perf/test_perf_sanity.py::test_e2e[...]
   ```
   - `unset UCX_TLS`: æ¸…é™¤ UCX ä¼ è¾“å±‚é…ç½®ï¼Œé¿å…å†²çª
   - `worker_env_var`: æ¥è‡ª YAML çš„ `environment.worker_env_var`
   - **å…³é”®**: ä½¿ç”¨ `trtllm-llmapi-launch` wrapper å¯åŠ¨

2. **pytestCommandDisaggServer** (DISAGG_SERVER ä½¿ç”¨):
   ```bash
   TRTLLM_SERVER_DISABLE_GC=1 \
   pytest perf/test_perf_sanity.py::test_e2e[...]
   ```
   - `server_env_var`: æ¥è‡ª YAML çš„ `environment.server_env_var`
   - **å…³é”®**: ç›´æ¥è¿è¡Œ pytestï¼Œä¸ä½¿ç”¨ llmapi-launch

3. **pytestCommandBenchmark** (BENCHMARK ä½¿ç”¨):
   ```bash
   pytest perf/test_perf_sanity.py::test_e2e[...]
   ```
   - `benchmark_env_var`: æ¥è‡ª YAML çš„ `environment.benchmark_env_var`ï¼ˆé€šå¸¸ä¸ºç©ºï¼‰
   - **å…³é”®**: æœ€ç®€å•çš„ pytest è°ƒç”¨

---

### 1.2 YAML é…ç½®ä¸­çš„ç¯å¢ƒå˜é‡æ¥æº

**ç¤ºä¾‹ YAML é…ç½®:**

```yaml
environment:
  worker_env_var: "TLLM_LOG_LEVEL=INFO TRTLLM_WORKER_DISABLE_GC=1"
  server_env_var: "TRTLLM_SERVER_DISABLE_GC=1"
  benchmark_env_var: ""
```

**è¿™äº›ç¯å¢ƒå˜é‡ä¼šè¢« submit.py è¯»å–å¹¶æ·»åŠ åˆ°å¯¹åº”çš„ pytestCommand ä¸­ã€‚**

---

### 1.3 test_perf_sanity.py ä¸­çš„åˆ†æµé€»è¾‘

#### å…¥å£å‡½æ•°: `test_e2e()` (1491-1520 è¡Œ)

```python
def test_e2e(output_dir, perf_sanity_test_case):
    # 1. åˆ›å»ºé…ç½®å¹¶è§£ææµ‹è¯•ç”¨ä¾‹å
    config = PerfSanityTestConfig(perf_sanity_test_case, output_dir)
    
    # 2. è§£æé…ç½®æ–‡ä»¶ (ä¼šè¯»å– DISAGG_SERVING_TYPE ç¯å¢ƒå˜é‡)
    config.parse_config_file()
    
    # 3. è·å–å‘½ä»¤
    commands = config.get_commands()
    
    # 4. è¿è¡Œå‘½ä»¤å¹¶æ”¶é›†è¾“å‡º
    outputs = config.run_ex(commands)
    
    # 5. åˆ†æµï¼šåªæœ‰ BENCHMARK èŠ‚ç‚¹å¤„ç†ç»“æœ
    if config.runtime == "multi_node_disagg_server":
        disagg_config = config.server_configs[0][2]
        if disagg_config.disagg_serving_type != "BENCHMARK":
            print_info(
                f"Disagg serving type is {disagg_config.disagg_serving_type}, "
                f"skipping perf result parsing and upload."
            )
            return  # â† GEN/CTX/DISAGG_SERVER åœ¨è¿™é‡Œç›´æ¥è¿”å›
    
    # 6. åªæœ‰ BENCHMARK ç»§ç»­æ‰§è¡Œä»¥ä¸‹æ­¥éª¤
    config.get_perf_result(outputs)
    config.check_test_failure()
    config.upload_test_results_to_database()
```

#### å…³é”®åˆ†æµç‚¹ 1: è§£æé…ç½®æ–‡ä»¶ (936 è¡Œ)

```python
def _parse_disagg_config_file(self, config_file_path: str, config_file: str):
    """Parse YAML config file for disaggregated server."""
    # ä»ç¯å¢ƒå˜é‡è·å–å½“å‰è§’è‰²
    disagg_serving_type = os.environ.get("DISAGG_SERVING_TYPE", "BENCHMARK")
    
    # è¯»å– YAML é…ç½®
    with open(config_file_path, "r") as f:
        config = yaml.safe_load(f)
    
    # æ ¹æ® disagg_serving_type å†³å®šè¡Œä¸º
    # ...
```

#### å…³é”®åˆ†æµç‚¹ 2: è·å–å‘½ä»¤ (1035-1043 è¡Œ)

```python
def get_commands(self):
    """Get commands based on runtime."""
    if self.runtime == "aggr_server":
        return self._get_aggr_commands(self.perf_sanity_output_dir)
    elif self.runtime == "multi_node_disagg_server":
        return self._get_disagg_commands(self.perf_sanity_output_dir)
        # â†“ è¿”å› DisaggTestCmds å¯¹è±¡
```

#### å…³é”®åˆ†æµç‚¹ 3: è¿è¡Œå‘½ä»¤ (682-783 è¡Œ)

**DisaggTestCmds.run_cmd() æ–¹æ³•æ ¹æ® DISAGG_SERVING_TYPE æ‰§è¡Œä¸åŒé€»è¾‘:**

```python
def run_cmd(self, server_idx: int) -> List[str]:
    """Run commands for a server and return outputs."""
    outputs = []
    benchmark_status_file = os.path.join(self.output_dir, f"benchmark_status.{server_idx}.txt")
    port = get_free_port()
    
    ctx_cmd, gen_cmd, disagg_cmd = self.server_cmds[server_idx]
    
    # åˆ†æ”¯ 1: CTX/GEN Server
    if "CTX" in self.disagg_serving_type or "GEN" in self.disagg_serving_type:
        # 1. ç”Ÿæˆ hostname æ–‡ä»¶ (è®© DISAGG_SERVER çŸ¥é“åœ°å€)
        self._generate_hostname_file(server_idx, port)
        
        # 2. å†³å®šå¯åŠ¨å“ªä¸ª server
        is_ctx = "CTX" in self.disagg_serving_type
        server_cmd = ctx_cmd if is_ctx else gen_cmd
        server_cmd = add_host_port_to_cmd(server_cmd, self.hostname, port)
        
        # 3. å¯åŠ¨ server è¿›ç¨‹
        print_info(f"Starting server. disagg_serving_type: {self.disagg_serving_type}")
        server_proc = subprocess.Popen(server_cmd, ...)
        
        # 4. ç­‰å¾… benchmark_status æ–‡ä»¶ (é˜»å¡ï¼Œç›´åˆ° BENCHMARK å®Œæˆ)
        self.wait_for_benchmark_ready(benchmark_status_file)
        
        # 5. æ”¶åˆ°ä¿¡å·åç»ˆæ­¢ server
        server_proc.terminate()
        server_proc.wait()
    
    # åˆ†æ”¯ 2: DISAGG_SERVER
    elif self.disagg_serving_type == "DISAGG_SERVER":
        # 1. ç”Ÿæˆ server_config.yaml (ä» hostname æ–‡ä»¶è¯»å– GEN/CTX åœ°å€)
        self._generate_disagg_server_config(server_idx, port)
        
        # 2. å¯åŠ¨åè°ƒæœåŠ¡å™¨
        print_info(f"Starting disagg server. cmd is {disagg_cmd}")
        disagg_server_proc = subprocess.Popen(disagg_cmd, ...)
        
        # 3. ç­‰å¾… benchmark_status æ–‡ä»¶
        self.wait_for_benchmark_ready(benchmark_status_file)
        
        # 4. ç»ˆæ­¢ server
        disagg_server_proc.terminate()
    
    # åˆ†æ”¯ 3: BENCHMARK
    elif self.disagg_serving_type == "BENCHMARK":
        # 1. è¯»å– server_config.yaml (è·å– DISAGG_SERVER åœ°å€)
        disagg_server_hostname, disagg_server_port = \
            self._get_disagg_server_hostname_and_port(server_idx)
        
        # 2. ç­‰å¾… /health ç«¯ç‚¹å°±ç»ª
        wait_for_endpoint_ready(
            f"http://{disagg_server_hostname}:{disagg_server_port}/health",
            timeout=self.timeout,
            check_files=server_files,
        )
        
        # 3. è¿è¡Œæ‰€æœ‰ benchmark clients
        for client_idx, client_cmd in enumerate(self.client_cmds[server_idx]):
            client_cmd_with_port = add_host_port_to_cmd(
                client_cmd, disagg_server_hostname, disagg_server_port
            )
            
            # è¿è¡Œ benchmark å¹¶æ”¶é›†è¾“å‡º
            output = subprocess.check_output(
                client_cmd_with_port,
                env=copy.deepcopy(os.environ),
                stderr=subprocess.STDOUT,
            ).decode()
            
            # ä¿å­˜åˆ°æ–‡ä»¶
            with open(benchmark_file_path, "w") as benchmark_ctx:
                benchmark_ctx.write(output)
            
            outputs.append(output)  # â† åªæœ‰ BENCHMARK æœ‰è¾“å‡º
        
        # 4. åˆ›å»º benchmark_status æ–‡ä»¶ (é€šçŸ¥å…¶ä»–ç»„ä»¶é€€å‡º)
        with open(benchmark_status_file, "w") as status_file:
            status_file.write("completed")
    
    return outputs  # GEN/CTX/DISAGG_SERVER è¿”å›ç©ºåˆ—è¡¨ï¼ŒBENCHMARK è¿”å›æ€§èƒ½æ•°æ®
```

---

### 1.4 å®Œæ•´æ‰§è¡Œæµç¨‹å¯¹æ¯”

| æ­¥éª¤ | GEN/CTX Server | DISAGG_SERVER | BENCHMARK |
|------|----------------|---------------|-----------|
| 1. è¯»å– DISAGG_SERVING_TYPE | âœ… `GEN_0` / `CTX_0` | âœ… `DISAGG_SERVER` | âœ… `BENCHMARK` |
| 2. è§£æ YAML é…ç½® | âœ… è¯»å– worker é…ç½® | âœ… è¯»å– server é…ç½® | âœ… è¯»å– benchmark é…ç½® |
| 3. ç”Ÿæˆå‘½ä»¤ | âœ… ctx_cmd / gen_cmd | âœ… disagg_cmd | âœ… client_cmd |
| 4. æ‰§è¡Œæ“ä½œ | ğŸ”¹ ç”Ÿæˆ hostname æ–‡ä»¶<br>ğŸ”¹ å¯åŠ¨ server<br>ğŸ”¹ ç­‰å¾… benchmark_status | ğŸ”¹ ç­‰å¾… hostname æ–‡ä»¶<br>ğŸ”¹ ç”Ÿæˆ server_config<br>ğŸ”¹ å¯åŠ¨åè°ƒæœåŠ¡å™¨<br>ğŸ”¹ ç­‰å¾… benchmark_status | ğŸ”¹ ç­‰å¾… server_config<br>ğŸ”¹ ç­‰å¾… /health<br>ğŸ”¹ è¿è¡Œ benchmark<br>ğŸ”¹ åˆ›å»º benchmark_status |
| 5. è¿”å›è¾“å‡º | âŒ ç©ºåˆ—è¡¨ | âŒ ç©ºåˆ—è¡¨ | âœ… æ€§èƒ½æ•°æ® |
| 6. è§£æç»“æœ | âŒ è·³è¿‡ (æå‰ return) | âŒ è·³è¿‡ (æå‰ return) | âœ… è§£æå¹¶ä¸Šä¼  |

---

### 1.5 ä¸ºä»€ä¹ˆéœ€è¦ä¸‰ç§ä¸åŒçš„ pytestCommandï¼Ÿ

**åŸå› æ€»ç»“:**

1. **Worker éœ€è¦ llmapi-launch**
   - GEN/CTX æ˜¯çœŸæ­£çš„æ¨ç†æœåŠ¡å™¨ï¼Œéœ€è¦ TensorRT-LLM çš„å®Œæ•´åˆå§‹åŒ–
   - `trtllm-llmapi-launch` ä¼šè®¾ç½® GPUã€MPIã€ç¯å¢ƒç­‰

2. **DISAGG_SERVER æ˜¯è½»é‡åè°ƒå™¨**
   - åªè´Ÿè´£è¯·æ±‚è·¯ç”±ï¼Œä¸éœ€è¦åŠ è½½æ¨¡å‹
   - ç›´æ¥è¿è¡Œ `trtllm-serve disaggregated`

3. **BENCHMARK æ˜¯çº¯å®¢æˆ·ç«¯**
   - åªå‘é€è¯·æ±‚å’Œæ”¶é›†æŒ‡æ ‡
   - ä¸éœ€è¦ä»»ä½•æœåŠ¡å™¨åˆå§‹åŒ–

---

## ğŸ“Œ é—®é¢˜ 2: è·³è¿‡æ€§èƒ½æ£€æŸ¥ (perf check)

### 2.1 å½“å‰é€»è¾‘åˆ†æ

**slurm_run.sh (129-154 è¡Œ):**

```bash
if [ $SLURM_PROCID -eq 0 ] && [ "$perfMode" = "true" ]; then
    if [[ "$stageName" == *PyTorch* ]]; then
        basePerfFilename="base_perf_pytorch.csv"
    else
        basePerfFilename="base_perf.csv"
    fi
    basePerfPath="$llmSrcNode/tests/integration/defs/perf/$basePerfFilename"
    
    # æ€§èƒ½æ£€æŸ¥
    echo "Check Perf Result"
    python3 $llmSrcNode/tests/integration/defs/perf/sanity_perf_check.py \
        $stageName/perf_script_test_results.csv \
        $basePerfPath
    perf_check_exit_code=$?
    
    # ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š
    echo "Create Perf Report"
    python3 $llmSrcNode/tests/integration/defs/perf/create_perf_comparison_report.py \
        --output_path $stageName/report.pdf \
        --files $stageName/perf_script_test_results.csv \
        $basePerfPath
    perf_report_exit_code=$?
    
    # åˆå¹¶é€€å‡ºç 
    if [ "$perf_check_exit_code" -eq 0 ] && [ "$perf_report_exit_code" -ne 0 ]; then
        perf_check_exit_code=$perf_report_exit_code
    fi
fi
```

**æ‰§è¡Œæ¡ä»¶:**
1. `SLURM_PROCID -eq 0`: åªæœ‰ç¬¬ä¸€ä¸ªè¿›ç¨‹æ‰§è¡Œ
2. `perfMode = "true"`: æ€§èƒ½æ¨¡å¼å¼€å¯

**é—®é¢˜:**
- L0 æ€§èƒ½æµ‹è¯•éœ€è¦è¿™ä¸ªæ£€æŸ¥ï¼ˆç¡®ä¿æ€§èƒ½ä¸å›é€€ï¼‰
- åŠŸèƒ½æµ‹è¯•ä¸éœ€è¦ï¼ˆåªå…³å¿ƒåŠŸèƒ½æ­£ç¡®æ€§ï¼Œä¸å…³å¿ƒæ€§èƒ½ï¼‰

---

### 2.2 è§£å†³æ–¹æ¡ˆï¼ˆä¸‰ç§æ–¹æ¡ˆï¼‰

#### æ–¹æ¡ˆ 1: é€šè¿‡ç¯å¢ƒå˜é‡æ§åˆ¶ï¼ˆæ¨èï¼‰â­

**ä¼˜ç‚¹:**
- âœ… ä¸ä¿®æ”¹è„šæœ¬ä»£ç 
- âœ… çµæ´»æ§åˆ¶
- âœ… ä¿æŒå‘åå…¼å®¹

**å®ç°:**

**åœ¨ run_disagg_test.sh çš„ slurm_launch_prefix.sh ä¸­æ·»åŠ :**

```bash
# åœ¨æ­¥éª¤ 4.2 ä¸­ä¿®æ”¹ (jenkins_test/scripts/run_disagg_test.sh)
SCRIPT_PREFIX_FILE="$WORKSPACE/slurm_launch_prefix.sh"
cat > "$SCRIPT_PREFIX_FILE" << EOFPREFIX
#!/bin/bash
#SBATCH --output=$WORKSPACE/slurm_%j.log
#SBATCH --nodes=$TOTAL_NODES
#SBATCH --ntasks=$TOTAL_GPUS
#SBATCH --ntasks-per-node=$GPUS_PER_NODE
#SBATCH --gpus-per-node=$GPUS_PER_NODE
#SBATCH --partition=$CLUSTER_PARTITION
#SBATCH --account=$CLUSTER_ACCOUNT
#SBATCH --job-name=disagg_perf_test
#SBATCH --time=04:00:00

set -xEeuo pipefail
trap 'rc=\$? ; echo "Error in file \${BASH_SOURCE[0]} on line \$LINENO: \$BASH_COMMAND (exit \$rc)"; exit \$rc' ERR

echo "Starting Slurm job \$SLURM_JOB_ID on \$SLURM_NODELIST"
export jobWorkspace=$WORKSPACE/disagg_workspace
export llmSrcNode=$TRTLLM_DIR
export stageName="disagg_perf_test_${CONFIG_NAME}"
export perfMode=true

# âœ… æ–°å¢ï¼šæ§åˆ¶æ€§èƒ½æ£€æŸ¥çš„å¼€å…³
export SKIP_PERF_CHECK=${SKIP_PERF_CHECK:-false}  # â† æ·»åŠ è¿™ä¸€è¡Œ

export resourcePathNode=$TRTLLM_DIR
export pytestCommand="pytest perf/test_perf_sanity.py::test_e2e[disagg_upload-${CONFIG_NAME}] -vv --junit-xml=$WORKSPACE/results.xml"
export coverageConfigFile=$WORKSPACE/coverage_config.json
export NVIDIA_IMEX_CHANNELS=\${NVIDIA_IMEX_CHANNELS:-0}
export NVIDIA_VISIBLE_DEVICES=\${NVIDIA_VISIBLE_DEVICES:-\$(seq -s, 0 \$((\$(nvidia-smi --query-gpu=count -i 0 --format=csv,noheader)-1)))}
EOFPREFIX
```

**åœ¨ slurm_run.sh ä¸­ä¿®æ”¹ (129 è¡Œ):**

```bash
# ä¿®æ”¹å‰
if [ $SLURM_PROCID -eq 0 ] && [ "$perfMode" = "true" ]; then

# ä¿®æ”¹å
if [ $SLURM_PROCID -eq 0 ] && [ "$perfMode" = "true" ] && [ "$SKIP_PERF_CHECK" != "true" ]; then
```

**ä½¿ç”¨æ–¹å¼:**

```bash
# L0 æ€§èƒ½æµ‹è¯•ï¼ˆé»˜è®¤ï¼Œæ‰§è¡Œæ€§èƒ½æ£€æŸ¥ï¼‰
export SKIP_PERF_CHECK=false
bash run_disagg_test.sh

# åŠŸèƒ½æµ‹è¯•ï¼ˆè·³è¿‡æ€§èƒ½æ£€æŸ¥ï¼‰
export SKIP_PERF_CHECK=true
bash run_disagg_test.sh
```

---

#### æ–¹æ¡ˆ 2: é€šè¿‡ stageName åˆ¤æ–­ï¼ˆé€‚åˆåŒºåˆ†æµ‹è¯•ç±»å‹ï¼‰

**ä¼˜ç‚¹:**
- âœ… è‡ªåŠ¨åˆ¤æ–­
- âœ… æ ¹æ®æµ‹è¯•åç§°è‡ªåŠ¨å†³ç­–

**å®ç°:**

**åœ¨ slurm_run.sh ä¸­ä¿®æ”¹ (129 è¡Œ):**

```bash
# ä¿®æ”¹å‰
if [ $SLURM_PROCID -eq 0 ] && [ "$perfMode" = "true" ]; then

# ä¿®æ”¹å
# åªæœ‰ stageName åŒ…å« "Perf" æˆ– "Performance" æ‰æ‰§è¡Œæ€§èƒ½æ£€æŸ¥
if [ $SLURM_PROCID -eq 0 ] && [ "$perfMode" = "true" ] && [[ "$stageName" == *Perf* ]]; then
```

**æ•ˆæœ:**

```bash
# æ‰§è¡Œæ€§èƒ½æ£€æŸ¥
stageName="disagg_perf_test_deepseek"     â†’ æ‰§è¡Œ
stageName="L0_Performance_Test"           â†’ æ‰§è¡Œ

# è·³è¿‡æ€§èƒ½æ£€æŸ¥
stageName="disagg_functional_test"        â†’ è·³è¿‡
stageName="disagg_sanity_test"            â†’ è·³è¿‡
```

---

#### æ–¹æ¡ˆ 3: ç‹¬ç«‹çš„æ€§èƒ½æ£€æŸ¥è„šæœ¬ï¼ˆæœ€å½»åº•çš„åˆ†ç¦»ï¼‰

**ä¼˜ç‚¹:**
- âœ… å®Œå…¨è§£è€¦
- âœ… å¯ä»¥åœ¨æµ‹è¯•åå•ç‹¬è¿è¡Œ

**å®ç°:**

**åˆ›å»ºç‹¬ç«‹è„šæœ¬: `jenkins/scripts/perf/run_perf_check.sh`**

```bash
#!/bin/bash
# ç‹¬ç«‹çš„æ€§èƒ½æ£€æŸ¥è„šæœ¬

set -xEeuo pipefail

STAGE_NAME="$1"
LLM_SRC_NODE="$2"
OUTPUT_DIR="${3:-$(pwd)}"

if [[ "$STAGE_NAME" == *PyTorch* ]]; then
    basePerfFilename="base_perf_pytorch.csv"
else
    basePerfFilename="base_perf.csv"
fi
basePerfPath="$LLM_SRC_NODE/tests/integration/defs/perf/$basePerfFilename"

echo "Check Perf Result"
python3 $LLM_SRC_NODE/tests/integration/defs/perf/sanity_perf_check.py \
    $OUTPUT_DIR/$STAGE_NAME/perf_script_test_results.csv \
    $basePerfPath

echo "Create Perf Report"
python3 $LLM_SRC_NODE/tests/integration/defs/perf/create_perf_comparison_report.py \
    --output_path $OUTPUT_DIR/$STAGE_NAME/report.pdf \
    --files $OUTPUT_DIR/$STAGE_NAME/perf_script_test_results.csv \
    $basePerfPath
```

**åœ¨ slurm_run.sh ä¸­ç§»é™¤æ€§èƒ½æ£€æŸ¥éƒ¨åˆ† (129-154 è¡Œ)**

**åœ¨ Jenkins ä¸­æŒ‰éœ€è°ƒç”¨:**

```groovy
// Perf_Test.groovy

// è¿è¡Œæµ‹è¯•
sh "bash jenkins_test/scripts/run_disagg_test.sh"

// L0 éœ€è¦æ€§èƒ½æ£€æŸ¥
if (env.JOB_NAME.contains("L0")) {
    sh """
        bash jenkins/scripts/perf/run_perf_check.sh \
            "disagg_perf_test_${CONFIG_NAME}" \
            "${WORKSPACE}/TensorRT-LLM" \
            "${WORKSPACE}"
    """
}
```

---

### 2.3 æ–¹æ¡ˆå¯¹æ¯”

| æ–¹æ¡ˆ | ä¼˜ç‚¹ | ç¼ºç‚¹ | é€‚ç”¨åœºæ™¯ |
|------|------|------|----------|
| **æ–¹æ¡ˆ 1: ç¯å¢ƒå˜é‡** | çµæ´»ã€ä¸æ”¹ä»£ç ã€å‘åå…¼å®¹ | éœ€è¦æ‰‹åŠ¨è®¾ç½®ç¯å¢ƒå˜é‡ | â­ **æ¨èï¼Œé€šç”¨** |
| **æ–¹æ¡ˆ 2: stageName** | è‡ªåŠ¨åˆ¤æ–­ã€ç®€å• | ä¾èµ–å‘½åçº¦å®š | æµ‹è¯•åç§°è§„èŒƒçš„åœºæ™¯ |
| **æ–¹æ¡ˆ 3: ç‹¬ç«‹è„šæœ¬** | å®Œå…¨è§£è€¦ã€å¯å¤ç”¨ | éœ€è¦åœ¨ Jenkins ä¸­é¢å¤–è°ƒç”¨ | å¤æ‚çš„ CI/CD æµç¨‹ |

---

### 2.4 æ¨èå®æ–½æ­¥éª¤ï¼ˆæ–¹æ¡ˆ 1ï¼‰

**æ­¥éª¤ 1: ä¿®æ”¹ run_disagg_test.sh**

```bash
# åœ¨æ­¥éª¤ 4.2 çš„ slurm_launch_prefix.sh ä¸­æ·»åŠ 
export SKIP_PERF_CHECK=${SKIP_PERF_CHECK:-false}
```

**æ­¥éª¤ 2: ä¿®æ”¹ slurm_run.sh**

```bash
# ç¬¬ 129 è¡Œæ”¹ä¸º
if [ $SLURM_PROCID -eq 0 ] && [ "$perfMode" = "true" ] && [ "$SKIP_PERF_CHECK" != "true" ]; then
```

**æ­¥éª¤ 3: åœ¨ Jenkins ä¸­è®¾ç½®**

```groovy
// Perf_Test.groovy

stage('Disagg Functional Test') {
    environment {
        SKIP_PERF_CHECK = 'true'  // â† åŠŸèƒ½æµ‹è¯•è·³è¿‡
    }
    steps {
        sh "bash jenkins_test/scripts/run_disagg_test.sh"
    }
}

stage('Disagg Performance Test') {
    environment {
        SKIP_PERF_CHECK = 'false'  // â† L0 æ€§èƒ½æµ‹è¯•æ‰§è¡Œ
    }
    steps {
        sh "bash jenkins_test/scripts/run_disagg_test.sh"
    }
}
```

---

## ğŸ“Œ é—®é¢˜ 3: æ—¥å¿—æ”¶é›†æ–¹æ¡ˆ

### 3.1 å½“å‰æ—¥å¿—æ”¶é›†æ–¹å¼

**åœ¨ slurm_launch_draft.sh ä¸­:**

```bash
# å®‰è£…æ—¥å¿—
srun "${srunArgs[@]}" $installScript &> $jobWorkspace/install.log

# GEN server æ—¥å¿—
for i in $(seq 0 $((numGenServers - 1))); do
    srun ... $runScript &> $jobWorkspace/gen_server_$i.log &
done

# CTX server æ—¥å¿—
for i in $(seq 0 $((numCtxServers - 1))); do
    srun ... $runScript &> $jobWorkspace/ctx_server_$i.log &
done

# DISAGG server æ—¥å¿—
srun ... $runScript &> $jobWorkspace/disagg_server.log &

# Benchmark æ—¥å¿—ï¼ˆæ²¡æœ‰å•ç‹¬çš„æ–‡ä»¶ï¼Œè¾“å‡ºåˆ° stdoutï¼‰
srun ... $runScript  # æ²¡æœ‰ &> é‡å®šå‘
```

**å½“å‰é—®é¢˜:**
1. âŒ æ‰€æœ‰æµ‹è¯•çš„æ—¥å¿—éƒ½æ··åœ¨ `$jobWorkspace` ä¸‹
2. âŒ å¤šä¸ªæµ‹è¯•ä¼šäº’ç›¸è¦†ç›–
3. âŒ ä¸æ–¹ä¾¿å½’æ¡£å’ŒæŸ¥æ‰¾
4. âŒ benchmark æ—¥å¿—æ²¡æœ‰å•ç‹¬ä¿å­˜

---

### 3.2 ç†æƒ³çš„æ—¥å¿—ç»“æ„

```
$WORKSPACE/
â””â”€â”€ disagg_logs/
    â”œâ”€â”€ deepseek-r1-fp4_1k1k_ctx1_gen1_dep8_bs768_eplb0_mtp0_ccb-UCX/
    â”‚   â”œâ”€â”€ slurm_12345.log                  â† Slurm ä½œä¸šæ—¥å¿—
    â”‚   â”œâ”€â”€ install.log                      â† å®‰è£…æ—¥å¿—
    â”‚   â”œâ”€â”€ gen_server_0.log                 â† GEN server 0 æ—¥å¿—
    â”‚   â”œâ”€â”€ gen_server_1.log                 â† GEN server 1 æ—¥å¿—ï¼ˆå¦‚æœæœ‰ï¼‰
    â”‚   â”œâ”€â”€ ctx_server_0.log                 â† CTX server 0 æ—¥å¿—
    â”‚   â”œâ”€â”€ ctx_server_1.log                 â† CTX server 1 æ—¥å¿—ï¼ˆå¦‚æœæœ‰ï¼‰
    â”‚   â”œâ”€â”€ disagg_server.log                â† DISAGG server æ—¥å¿—
    â”‚   â”œâ”€â”€ benchmark.log                    â† Benchmark å®¢æˆ·ç«¯æ—¥å¿—
    â”‚   â”œâ”€â”€ results.xml                      â† pytest JUnit æŠ¥å‘Š
    â”‚   â”œâ”€â”€ perf_script_test_results.csv     â† æ€§èƒ½ç»“æœ
    â”‚   â””â”€â”€ report.pdf                       â† æ€§èƒ½æŠ¥å‘Šï¼ˆå¦‚æœç”Ÿæˆï¼‰
    â”‚
    â””â”€â”€ llama3_8b_tp4_pp2/
        â”œâ”€â”€ slurm_12346.log
        â”œâ”€â”€ install.log
        â””â”€â”€ ...
```

---

### 3.3 è§£å†³æ–¹æ¡ˆï¼ˆä¸‰ç§æ–¹æ¡ˆï¼‰

#### æ–¹æ¡ˆ 1: ä¿®æ”¹ jobWorkspace è·¯å¾„ï¼ˆæ¨èï¼‰â­

**ä¼˜ç‚¹:**
- âœ… æ”¹åŠ¨æœ€å°
- âœ… ä¿æŒç°æœ‰ç»“æ„
- âœ… è‡ªåŠ¨æŒ‰ case åˆ†ç±»

**å®ç°:**

**ä¿®æ”¹ run_disagg_test.sh çš„æ­¥éª¤ 4.2:**

```bash
# å½“å‰
export jobWorkspace=$WORKSPACE/disagg_workspace

# ä¿®æ”¹ä¸º
export jobWorkspace=$WORKSPACE/disagg_logs/${CONFIG_NAME}
```

**å®Œæ•´ç¤ºä¾‹:**

```bash
# åœ¨ slurm_launch_prefix.sh ä¸­ï¼ˆrun_disagg_test.sh æ­¥éª¤ 4.2ï¼‰
SCRIPT_PREFIX_FILE="$WORKSPACE/slurm_launch_prefix.sh"
cat > "$SCRIPT_PREFIX_FILE" << EOFPREFIX
#!/bin/bash
#SBATCH --output=$WORKSPACE/disagg_logs/${CONFIG_NAME}/slurm_%j.log  # â† ä¿®æ”¹
#SBATCH --nodes=$TOTAL_NODES
#SBATCH --ntasks=$TOTAL_GPUS
#SBATCH --ntasks-per-node=$GPUS_PER_NODE
#SBATCH --gpus-per-node=$GPUS_PER_NODE
#SBATCH --partition=$CLUSTER_PARTITION
#SBATCH --account=$CLUSTER_ACCOUNT
#SBATCH --job-name=disagg_${CONFIG_NAME}  # â† ä¿®æ”¹
#SBATCH --time=04:00:00

set -xEeuo pipefail
trap 'rc=\$? ; echo "Error in file \${BASH_SOURCE[0]} on line \$LINENO: \$BASH_COMMAND (exit \$rc)"; exit \$rc' ERR

echo "Starting Slurm job \$SLURM_JOB_ID on \$SLURM_NODELIST"

# âœ… ä¿®æ”¹ï¼šæŒ‰ case åç§°åˆ›å»ºæ—¥å¿—ç›®å½•
export jobWorkspace=$WORKSPACE/disagg_logs/${CONFIG_NAME}  # â† å…³é”®ä¿®æ”¹
mkdir -p \$jobWorkspace  # â† ç¡®ä¿ç›®å½•å­˜åœ¨

export llmSrcNode=$TRTLLM_DIR
export stageName="disagg_perf_test_${CONFIG_NAME}"
export perfMode=true
export resourcePathNode=$TRTLLM_DIR
export pytestCommand="pytest perf/test_perf_sanity.py::test_e2e[disagg_upload-${CONFIG_NAME}] -vv --junit-xml=\$jobWorkspace/results.xml"  # â† ä¿®æ”¹è¾“å‡ºè·¯å¾„
export coverageConfigFile=\$jobWorkspace/coverage_config.json  # â† ä¿®æ”¹
export NVIDIA_IMEX_CHANNELS=\${NVIDIA_IMEX_CHANNELS:-0}
export NVIDIA_VISIBLE_DEVICES=\${NVIDIA_VISIBLE_DEVICES:-\$(seq -s, 0 \$((\$(nvidia-smi --query-gpu=count -i 0 --format=csv,noheader)-1)))}
EOFPREFIX
```

**æ•ˆæœ:**

```
è¿è¡Œ: run_disagg_test.sh deepseek-r1-fp4_...
æ—¥å¿—ä½ç½®: /workspace/disagg_logs/deepseek-r1-fp4_1k1k_ctx1_gen1_dep8_bs768_eplb0_mtp0_ccb-UCX/

è¿è¡Œ: run_disagg_test.sh llama3_8b_tp4_pp2
æ—¥å¿—ä½ç½®: /workspace/disagg_logs/llama3_8b_tp4_pp2/
```

---

#### æ–¹æ¡ˆ 2: ä¿®æ”¹ slurm_launch_draft.sh é‡å®šå‘ï¼ˆå®Œæ•´æ§åˆ¶ï¼‰

**ä¼˜ç‚¹:**
- âœ… å®Œæ•´æ§åˆ¶æ‰€æœ‰æ—¥å¿—
- âœ… åŒ…æ‹¬ benchmark æ—¥å¿—

**å®ç°:**

**ä¿®æ”¹ slurm_launch_draft.sh:**

```bash
# åœ¨æ–‡ä»¶å¼€å¤´æ·»åŠ 
LOG_DIR="${jobWorkspace}/logs"
mkdir -p "$LOG_DIR"

# ä¿®æ”¹å„ä¸ªæ—¥å¿—é‡å®šå‘
srun "${srunArgs[@]}" $installScript &> "$LOG_DIR/install.log"

for i in $(seq 0 $((numGenServers - 1))); do
    srun ... $runScript &> "$LOG_DIR/gen_server_$i.log" &
done

for i in $(seq 0 $((numCtxServers - 1))); do
    srun ... $runScript &> "$LOG_DIR/ctx_server_$i.log" &
done

srun ... $runScript &> "$LOG_DIR/disagg_server.log" &

# âœ… æ–°å¢ï¼šbenchmark æ—¥å¿—ä¹Ÿä¿å­˜
srun ... $runScript &> "$LOG_DIR/benchmark.log"
```

**æ³¨æ„:** è¿™ç§æ–¹å¼éœ€è¦ä¿®æ”¹ slurm_launch_draft.shï¼Œä½† submit.py ä¼šè¦†ç›–è¿™ä¸ªæ–‡ä»¶çš„å†…å®¹ï¼Œéœ€è¦åœ¨ submit.py ä¸­ç”Ÿæˆæ—¶å°±åŒ…å«è¿™äº›ä¿®æ”¹ã€‚

---

#### æ–¹æ¡ˆ 3: åå¤„ç†è„šæœ¬ï¼ˆäº‹åæ”¶é›†ï¼‰

**ä¼˜ç‚¹:**
- âœ… ä¸ä¿®æ”¹ç°æœ‰æµç¨‹
- âœ… çµæ´»å½’æ¡£

**å®ç°:**

**åˆ›å»ºæ”¶é›†è„šæœ¬: `jenkins_test/scripts/collect_disagg_logs.sh`**

```bash
#!/bin/bash
# æ”¶é›†å’Œå½’æ¡£ disagg æµ‹è¯•æ—¥å¿—

set -xEeuo pipefail

WORKSPACE="$1"
CONFIG_NAME="$2"
JOB_WORKSPACE="${3:-$WORKSPACE/disagg_workspace}"

# ç›®æ ‡ç›®å½•
TARGET_DIR="$WORKSPACE/disagg_logs/$CONFIG_NAME"
mkdir -p "$TARGET_DIR"

echo "Collecting logs for $CONFIG_NAME..."

# å¤åˆ¶æ‰€æœ‰æ—¥å¿—æ–‡ä»¶
if [ -d "$JOB_WORKSPACE" ]; then
    cp -v "$JOB_WORKSPACE"/*.log "$TARGET_DIR/" 2>/dev/null || true
    cp -v "$JOB_WORKSPACE"/*.xml "$TARGET_DIR/" 2>/dev/null || true
    cp -v "$JOB_WORKSPACE"/*.csv "$TARGET_DIR/" 2>/dev/null || true
    cp -v "$JOB_WORKSPACE"/*.pdf "$TARGET_DIR/" 2>/dev/null || true
fi

# å¤åˆ¶ Slurm ä½œä¸šæ—¥å¿—ï¼ˆå¦‚æœæœ‰ï¼‰
if [ -n "${SLURM_JOB_ID:-}" ]; then
    cp -v "$WORKSPACE/slurm_${SLURM_JOB_ID}.log" "$TARGET_DIR/" 2>/dev/null || true
fi

# åˆ›å»ºå½’æ¡£
tar -czf "$TARGET_DIR.tar.gz" -C "$WORKSPACE/disagg_logs" "$CONFIG_NAME"

echo "Logs collected and archived to: $TARGET_DIR.tar.gz"
ls -lh "$TARGET_DIR"
```

**åœ¨ run_disagg_test.sh æœ«å°¾æ·»åŠ :**

```bash
# æ­¥éª¤ 7: æ”¶é›†æ—¥å¿—
echo ""
echo "[æ­¥éª¤ 7] æ”¶é›†æ—¥å¿—..."
bash "$TRTLLM_DIR/jenkins_test/scripts/collect_disagg_logs.sh" \
    "$WORKSPACE" \
    "$CONFIG_NAME" \
    "$WORKSPACE/disagg_workspace"
```

---

### 3.4 æ–¹æ¡ˆå¯¹æ¯”

| æ–¹æ¡ˆ | ä¼˜ç‚¹ | ç¼ºç‚¹ | æ”¹åŠ¨èŒƒå›´ |
|------|------|------|----------|
| **æ–¹æ¡ˆ 1: ä¿®æ”¹ jobWorkspace** | ç®€å•ã€æ”¹åŠ¨å°ã€è‡ªåŠ¨åˆ†ç±» | éœ€è¦ç¡®ä¿ç›®å½•æå‰åˆ›å»º | â­ åªä¿®æ”¹ run_disagg_test.sh |
| **æ–¹æ¡ˆ 2: ä¿®æ”¹é‡å®šå‘** | å®Œæ•´æ§åˆ¶ã€åŒ…æ‹¬ benchmark | éœ€è¦ä¿®æ”¹ç”Ÿæˆé€»è¾‘ | submit.py å’Œ slurm_launch_draft.sh |
| **æ–¹æ¡ˆ 3: åå¤„ç†è„šæœ¬** | ä¸ä¿®æ”¹ç°æœ‰æµç¨‹ã€çµæ´» | äº‹åå¤„ç†ã€å¯èƒ½é—æ¼æ—¥å¿— | æ–°å¢è„šæœ¬ + è°ƒç”¨ç‚¹ |

---

### 3.5 æ¨èå®æ–½æ­¥éª¤ï¼ˆæ–¹æ¡ˆ 1 + å¢å¼ºï¼‰

**æ­¥éª¤ 1: ä¿®æ”¹ run_disagg_test.sh (æ­¥éª¤ 4.2)**

```bash
# ä¿®æ”¹ jobWorkspace è·¯å¾„
export jobWorkspace=$WORKSPACE/disagg_logs/${CONFIG_NAME}

# ä¿®æ”¹ pytest è¾“å‡ºè·¯å¾„
export pytestCommand="pytest perf/test_perf_sanity.py::test_e2e[disagg_upload-${CONFIG_NAME}] -vv --junit-xml=\$jobWorkspace/results.xml"

# ä¿®æ”¹ coverage é…ç½®è·¯å¾„
export coverageConfigFile=\$jobWorkspace/coverage_config.json
```

**æ­¥éª¤ 2: ä¿®æ”¹ SBATCH è¾“å‡ºè·¯å¾„**

```bash
#SBATCH --output=$WORKSPACE/disagg_logs/${CONFIG_NAME}/slurm_%j.log
```

**æ­¥éª¤ 3: åœ¨ slurm_launch_draft.sh å¼€å¤´æ·»åŠ ï¼ˆå¯é€‰ï¼‰**

å¦‚æœè¦ä¿®æ”¹ slurm_launch_draft.shï¼Œéœ€è¦åœ¨ submit.py ç”Ÿæˆæ—¶æ³¨å…¥ï¼š

**åœ¨ submit.py çš„æ¨¡æ¿ä¸­æ·»åŠ  (å¯é€‰ï¼Œéœ€è¦ä¿®æ”¹ submit.py):**

```python
# åœ¨ç”Ÿæˆ launch.sh æ—¶ï¼Œåœ¨ draft_launch_content å‰é¢æ’å…¥
benchmark_log_redirect = f"&> $jobWorkspace/benchmark.log"
```

**æ­¥éª¤ 4: æ·»åŠ æ—¥å¿—æ”¶é›†æ‘˜è¦ï¼ˆå¯é€‰ï¼‰**

**åœ¨ run_disagg_test.sh æœ«å°¾æ·»åŠ :**

```bash
# æ­¥éª¤ 7: æ—¥å¿—æ”¶é›†æ‘˜è¦
echo ""
echo "[æ­¥éª¤ 7] æ—¥å¿—æ”¶é›†æ‘˜è¦"
echo "æ‰€æœ‰æ—¥å¿—å·²ä¿å­˜åˆ°: $WORKSPACE/disagg_logs/${CONFIG_NAME}/"
echo "æ–‡ä»¶åˆ—è¡¨:"
ls -lh "$WORKSPACE/disagg_logs/${CONFIG_NAME}/" || true
```

---

### 3.6 æ—¥å¿—æ–‡ä»¶è¯´æ˜

| æ–‡ä»¶å | æ¥æº | å†…å®¹ |
|--------|------|------|
| `slurm_<job_id>.log` | SBATCH stdout | æ•´ä¸ªä½œä¸šçš„æ ‡å‡†è¾“å‡º |
| `install.log` | slurm_install.sh | å®‰è£… TensorRT-LLM çš„æ—¥å¿— |
| `gen_server_<i>.log` | slurm_run.sh (GEN) | GEN server å¯åŠ¨å’Œè¿è¡Œæ—¥å¿— |
| `ctx_server_<i>.log` | slurm_run.sh (CTX) | CTX server å¯åŠ¨å’Œè¿è¡Œæ—¥å¿— |
| `disagg_server.log` | slurm_run.sh (DISAGG_SERVER) | åè°ƒæœåŠ¡å™¨æ—¥å¿— |
| `benchmark.log` | slurm_run.sh (BENCHMARK) | Benchmark å®¢æˆ·ç«¯æ—¥å¿—ï¼ˆéœ€è¦æ·»åŠ é‡å®šå‘ï¼‰ |
| `results.xml` | pytest | JUnit æµ‹è¯•æŠ¥å‘Š |
| `perf_script_test_results.csv` | test_perf_sanity.py | æ€§èƒ½æŒ‡æ ‡æ•°æ® |
| `report.pdf` | create_perf_comparison_report.py | æ€§èƒ½å¯¹æ¯”æŠ¥å‘Šï¼ˆå¦‚æœç”Ÿæˆï¼‰ |

---

## ğŸ¯ æ€»ç»“

### é—®é¢˜ 1: pytestCommand å·®å¼‚

**æ ¸å¿ƒå·®å¼‚:**
- `pytestCommandWorker`: ä½¿ç”¨ `trtllm-llmapi-launch`ï¼ŒåŒ…å« worker_env_var
- `pytestCommandDisaggServer`: ä¸ä½¿ç”¨ llmapi-launchï¼ŒåŒ…å« server_env_var
- `pytestCommandBenchmark`: æœ€ç®€å•çš„ pytest è°ƒç”¨ï¼ŒåŒ…å« benchmark_env_var

**åˆ†æµæœºåˆ¶:**
- é€šè¿‡ `DISAGG_SERVING_TYPE` ç¯å¢ƒå˜é‡åŒºåˆ†è§’è‰²
- åœ¨ `test_perf_sanity.py` çš„ `DisaggTestCmds.run_cmd()` ä¸­åˆ†æ”¯æ‰§è¡Œ
- åªæœ‰ BENCHMARK è¿”å›æ€§èƒ½æ•°æ®å¹¶è§£æç»“æœ

---

### é—®é¢˜ 2: è·³è¿‡æ€§èƒ½æ£€æŸ¥

**æ¨èæ–¹æ¡ˆ:** ç¯å¢ƒå˜é‡æ§åˆ¶ï¼ˆæ–¹æ¡ˆ 1ï¼‰

**å®æ–½:**
```bash
# run_disagg_test.sh
export SKIP_PERF_CHECK=${SKIP_PERF_CHECK:-false}

# slurm_run.sh (129 è¡Œ)
if [ $SLURM_PROCID -eq 0 ] && [ "$perfMode" = "true" ] && [ "$SKIP_PERF_CHECK" != "true" ]; then
```

**ä½¿ç”¨:**
- L0 æ€§èƒ½æµ‹è¯•: `export SKIP_PERF_CHECK=false`
- åŠŸèƒ½æµ‹è¯•: `export SKIP_PERF_CHECK=true`

---

### é—®é¢˜ 3: æ—¥å¿—æ”¶é›†

**æ¨èæ–¹æ¡ˆ:** ä¿®æ”¹ jobWorkspace è·¯å¾„ï¼ˆæ–¹æ¡ˆ 1ï¼‰

**å®æ–½:**
```bash
# run_disagg_test.sh (æ­¥éª¤ 4.2)
export jobWorkspace=$WORKSPACE/disagg_logs/${CONFIG_NAME}

# SBATCH è¾“å‡º
#SBATCH --output=$WORKSPACE/disagg_logs/${CONFIG_NAME}/slurm_%j.log
```

**æ•ˆæœ:**
- æ¯ä¸ª case ç‹¬ç«‹ç›®å½•
- è‡ªåŠ¨åˆ†ç±»å’Œå½’æ¡£
- ä¸ä¼šäº’ç›¸è¦†ç›–

---

**ä¸‰ä¸ªé—®é¢˜éƒ½æœ‰æ¸…æ™°çš„è§£å†³æ–¹æ¡ˆï¼Œå¯ä»¥æŒ‰éœ€å®æ–½ï¼** ğŸš€
