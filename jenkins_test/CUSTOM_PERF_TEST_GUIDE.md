# ä½¿ç”¨è‡ªå®šä¹‰ test_perf_enhanced.py æ›¿ä»£ test_perf_sanity.py

> å®Œæ•´æŒ‡å—ï¼šå¦‚ä½•è®© CI ä½¿ç”¨è‡ªå®šä¹‰çš„æ€§èƒ½æµ‹è¯•æ–‡ä»¶ï¼Œæ”¯æŒ single-aggã€multi-aggã€multi-disagg æ‰€æœ‰æ¨¡å¼

---

## ğŸ“‹ æ¦‚è¿°

### å½“å‰æ¶æ„

```
Jenkins Pipeline (Perf_Test.groovy)
    â†“
run_*_test.sh (run_disagg_test.sh / run_single_agg_test.sh / run_multi_agg_test.sh)
    â†“
submit.py (ä»… disagg æ¨¡å¼) æˆ–ç›´æ¥ pytest (agg æ¨¡å¼)
    â†“
pytest tests/integration/defs/perf/test_perf_sanity.py  â† å›ºå®šè·¯å¾„
```

### ç›®æ ‡æ¶æ„

```
Jenkins Pipeline (Perf_Test.groovy)
    â†“
run_*_test.sh (æ”¯æŒè‡ªå®šä¹‰æµ‹è¯•æ–‡ä»¶è·¯å¾„)
    â†“
submit.py (æ”¯æŒè‡ªå®šä¹‰æµ‹è¯•æ–‡ä»¶) æˆ–ç›´æ¥ pytest
    â†“
pytest tests/integration/defs/perf/test_perf_enhanced.py  â† å¯é…ç½®è·¯å¾„
```

---

## ğŸ¯ è®¾è®¡æ–¹æ¡ˆ

### æ–¹æ¡ˆ 1: ç¯å¢ƒå˜é‡æ§åˆ¶ï¼ˆæ¨èï¼‰â­

**ä¼˜ç‚¹ï¼š**
- âœ… ä¸ä¿®æ”¹ç°æœ‰è„šæœ¬çš„ä¸»é€»è¾‘
- âœ… ä¿æŒå‘åå…¼å®¹
- âœ… çµæ´»åˆ‡æ¢
- âœ… æ˜“äºè°ƒè¯•

**å®ç°ï¼š**

é€šè¿‡ç¯å¢ƒå˜é‡ `PERF_TEST_MODULE` æŒ‡å®šæµ‹è¯•æ–‡ä»¶è·¯å¾„ã€‚

---

## ğŸ“ è¯¦ç»†å®æ–½æ–¹æ¡ˆ

### æ­¥éª¤ 1: åˆ›å»ºè‡ªå®šä¹‰æµ‹è¯•æ–‡ä»¶

**æ–‡ä»¶è·¯å¾„ï¼š**
```
tests/integration/defs/perf/test_perf_enhanced.py
```

**åŸºç¡€ç»“æ„ï¼ˆåŸºäº test_perf_sanity.pyï¼‰ï¼š**

```python
#!/usr/bin/env python3
"""
TensorRT-LLM Enhanced Performance Tests
åŸºäº test_perf_sanity.pyï¼Œæ·»åŠ è‡ªå®šä¹‰åŠŸèƒ½
"""

# å¯¼å…¥åŸå§‹ test_perf_sanity çš„æ‰€æœ‰åŠŸèƒ½
from test_perf_sanity import (
    PerfSanityTestConfig,
    MODEL_PATH_DICT,
    PERF_METRIC_LOG_QUERIES,
    get_model_dir,
    get_dataset_path,
    # ... å…¶ä»–éœ€è¦çš„å¯¼å…¥
)

# å¯é€‰ï¼šæ·»åŠ è‡ªå·±çš„æ¨¡å‹è·¯å¾„æ˜ å°„
ENHANCED_MODEL_PATH_DICT = {
    **MODEL_PATH_DICT,  # ç»§æ‰¿åŸå§‹æ˜ å°„
    "my_custom_model": "path/to/my/model",  # æ·»åŠ è‡ªå®šä¹‰æ¨¡å‹
}

# å¯é€‰ï¼šæ‰©å±•é…ç½®ç±»
class EnhancedPerfTestConfig(PerfSanityTestConfig):
    """å¢å¼ºç‰ˆæ€§èƒ½æµ‹è¯•é…ç½®"""
    
    def __init__(self, test_case_name: str, output_dir: str):
        super().__init__(test_case_name, output_dir)
        # æ·»åŠ è‡ªå®šä¹‰åˆå§‹åŒ–
        self._load_custom_settings()
    
    def _load_custom_settings(self):
        """åŠ è½½è‡ªå®šä¹‰è®¾ç½®"""
        # ä¾‹å¦‚ï¼šè¯»å–é¢å¤–çš„é…ç½®æ–‡ä»¶
        # ä¾‹å¦‚ï¼šè®¾ç½®è‡ªå®šä¹‰çš„é»˜è®¤å€¼
        pass
    
    def export_results_to_csv(self, csv_path: str):
        """å¯¼å‡ºç»“æœåˆ° CSVï¼ˆæ”¯æŒ trt_perf_parser.pyï¼‰"""
        # è‡ªå®šä¹‰ CSV å¯¼å‡ºé€»è¾‘
        pass
    
    def upload_to_custom_db(self):
        """ä¸Šä¼ åˆ°è‡ªå®šä¹‰æ•°æ®åº“"""
        # è‡ªå®šä¹‰æ•°æ®åº“ä¸Šä¼ é€»è¾‘
        pass

# ä¸»æµ‹è¯•å‡½æ•°ï¼ˆpytest å…¥å£ï¼‰
@pytest.fixture
def perf_enhanced_test_case(request):
    """Enhanced test case fixture"""
    return request.param

def test_e2e(output_dir, perf_enhanced_test_case):
    """ç«¯åˆ°ç«¯æ€§èƒ½æµ‹è¯•ï¼ˆå¢å¼ºç‰ˆï¼‰"""
    # åˆ›å»ºé…ç½®
    config = EnhancedPerfTestConfig(perf_enhanced_test_case, output_dir)
    
    # è§£æé…ç½®æ–‡ä»¶
    config.parse_config_file()
    
    # è·å–å‘½ä»¤
    commands = config.get_commands()
    
    # è¿è¡Œå‘½ä»¤å¹¶æ”¶é›†è¾“å‡º
    outputs = config.run_ex(commands)
    
    # åˆ†æµï¼šåªæœ‰ BENCHMARK èŠ‚ç‚¹å¤„ç†ç»“æœ
    if config.runtime == "multi_node_disagg_server":
        disagg_config = config.server_configs[0][2]
        if disagg_config.disagg_serving_type != "BENCHMARK":
            print_info(
                f"Disagg serving type is {disagg_config.disagg_serving_type}, "
                f"skipping perf result parsing and upload."
            )
            return
    
    # è§£ææ€§èƒ½ç»“æœ
    config.get_perf_result(outputs)
    
    # æ£€æŸ¥æµ‹è¯•å¤±è´¥
    config.check_test_failure()
    
    # âœ… è‡ªå®šä¹‰åŠŸèƒ½ 1: å¯¼å‡º CSV
    csv_output_path = os.path.join(
        config.perf_sanity_output_dir,
        "perf_script_test_results.csv"
    )
    config.export_results_to_csv(csv_output_path)
    
    # âœ… è‡ªå®šä¹‰åŠŸèƒ½ 2: ä¸Šä¼ åˆ° OpenSearchï¼ˆåŸå§‹åŠŸèƒ½ï¼‰
    config.upload_test_results_to_database()
    
    # âœ… è‡ªå®šä¹‰åŠŸèƒ½ 3: ä¸Šä¼ åˆ°è‡ªå®šä¹‰æ•°æ®åº“
    config.upload_to_custom_db()
    
    # âœ… è‡ªå®šä¹‰åŠŸèƒ½ 4: å…¶ä»–å®šåˆ¶é€»è¾‘
    # ...

if __name__ == "__main__":
    pytest.main([__file__])
```

---

### æ­¥éª¤ 2: ä¿®æ”¹è„šæœ¬æ”¯æŒè‡ªå®šä¹‰æµ‹è¯•è·¯å¾„

#### 2.1 ä¿®æ”¹ run_disagg_test.sh

**å½“å‰ä»£ç ï¼ˆ257 è¡Œå’Œ 284 è¡Œï¼‰ï¼š**

```bash
# æ­¥éª¤ 2.1: åˆ›å»º test list æ–‡ä»¶
TEST_LIST_FILE="$WORKSPACE/test_list_disagg.txt"
cat > "$TEST_LIST_FILE" << EOF
perf/test_perf_sanity.py::test_e2e[disagg_upload-${CONFIG_NAME}]
EOF

# æ­¥éª¤ 4.2: åˆ›å»º script prefix æ–‡ä»¶
export pytestCommand="pytest perf/test_perf_sanity.py::test_e2e[disagg_upload-${CONFIG_NAME}] -vv --junit-xml=$WORKSPACE/results.xml"
```

**ä¿®æ”¹ä¸ºï¼ˆæ”¯æŒè‡ªå®šä¹‰ï¼‰ï¼š**

```bash
# ============================================
# æ­¥éª¤ 0: ç¡®å®šæµ‹è¯•æ¨¡å—è·¯å¾„
# ============================================

# ä»ç¯å¢ƒå˜é‡è¯»å–è‡ªå®šä¹‰æµ‹è¯•æ¨¡å—ï¼ˆé»˜è®¤ä½¿ç”¨ test_perf_sanity.pyï¼‰
PERF_TEST_MODULE="${PERF_TEST_MODULE:-perf/test_perf_sanity.py}"
PERF_TEST_FUNCTION="${PERF_TEST_FUNCTION:-test_e2e}"
PERF_TEST_PREFIX="${PERF_TEST_PREFIX:-disagg_upload}"

echo "[æ­¥éª¤ 0] æµ‹è¯•æ¨¡å—é…ç½®:"
echo "  æµ‹è¯•æ¨¡å—: $PERF_TEST_MODULE"
echo "  æµ‹è¯•å‡½æ•°: $PERF_TEST_FUNCTION"
echo "  æµ‹è¯•å‰ç¼€: $PERF_TEST_PREFIX"

# ============================================
# æ­¥éª¤ 2.1: åˆ›å»º test list æ–‡ä»¶
# ============================================
TEST_LIST_FILE="$WORKSPACE/test_list_disagg.txt"
cat > "$TEST_LIST_FILE" << EOF
${PERF_TEST_MODULE}::${PERF_TEST_FUNCTION}[${PERF_TEST_PREFIX}-${CONFIG_NAME}]
EOF
echo "âœ“ ç”Ÿæˆ test list: $TEST_LIST_FILE"

# ============================================
# æ­¥éª¤ 4.2: åˆ›å»º script prefix æ–‡ä»¶
# ============================================
SCRIPT_PREFIX_FILE="$WORKSPACE/slurm_launch_prefix.sh"
cat > "$SCRIPT_PREFIX_FILE" << EOFPREFIX
#!/bin/bash
#SBATCH --output=$WORKSPACE/slurm_%j.log
#SBATCH --nodes=$TOTAL_NODES
#SBATCH --ntasks=$TOTAL_GPUS
#SBATCH --ntasks-per-node=$GPUS_PER_NODE
#SBATCH --gpus-per-node=$GPUS_PER_NODE
#SBATCH --partition=$CLUSTER_PARTITION
#SBATCH --account=$CLUSTER_ACCOUNT
#SBATCH --job-name=disagg_perf_test
#SBATCH --time=04:00:00

set -xEeuo pipefail

export pytestCommand="pytest ${PERF_TEST_MODULE}::${PERF_TEST_FUNCTION}[${PERF_TEST_PREFIX}-${CONFIG_NAME}] -vv --junit-xml=$WORKSPACE/results.xml"
export jobWorkspace=$WORKSPACE/disagg_workspace
export llmSrcNode=$TRTLLM_DIR
export stageName="disagg_perf_test_${CONFIG_NAME}"
export perfMode=true
export resourcePathNode=$TRTLLM_DIR
export coverageConfigFile=$WORKSPACE/coverage_config.json
EOFPREFIX
```

**å…³é”®ä¿®æ”¹ï¼š**

1. âœ… æ·»åŠ ç¯å¢ƒå˜é‡ `PERF_TEST_MODULE`ï¼ˆé»˜è®¤ `perf/test_perf_sanity.py`ï¼‰
2. âœ… æ·»åŠ ç¯å¢ƒå˜é‡ `PERF_TEST_FUNCTION`ï¼ˆé»˜è®¤ `test_e2e`ï¼‰
3. âœ… æ·»åŠ ç¯å¢ƒå˜é‡ `PERF_TEST_PREFIX`ï¼ˆé»˜è®¤ `disagg_upload`ï¼‰
4. âœ… ä½¿ç”¨å˜é‡æ„é€ æµ‹è¯•è·¯å¾„

---

#### 2.2 ä¿®æ”¹ run_single_agg_test.sh

**å½“å‰ä»£ç ï¼ˆ131 è¡Œï¼‰ï¼š**

```bash
PYTEST_CMD+=" tests/integration/defs/perf/test_perf_sanity.py::test_e2e"
```

**ä¿®æ”¹ä¸ºï¼š**

```bash
# ç¡®å®šæµ‹è¯•æ¨¡å—è·¯å¾„
PERF_TEST_MODULE="${PERF_TEST_MODULE:-tests/integration/defs/perf/test_perf_sanity.py}"
PERF_TEST_FUNCTION="${PERF_TEST_FUNCTION:-test_e2e}"

echo "æµ‹è¯•æ¨¡å—: $PERF_TEST_MODULE"
echo "æµ‹è¯•å‡½æ•°: $PERF_TEST_FUNCTION"

PYTEST_CMD+=" ${PERF_TEST_MODULE}::${PERF_TEST_FUNCTION}"
```

---

#### 2.3 ä¿®æ”¹ run_multi_agg_test.sh

**å½“å‰ä»£ç ï¼ˆ201 è¡Œï¼‰ï¼š**

```bash
PYTEST_CMD+=" tests/integration/defs/perf/test_perf_sanity.py::test_e2e"
```

**ä¿®æ”¹ä¸ºï¼š**

```bash
# ç¡®å®šæµ‹è¯•æ¨¡å—è·¯å¾„
PERF_TEST_MODULE="${PERF_TEST_MODULE:-tests/integration/defs/perf/test_perf_sanity.py}"
PERF_TEST_FUNCTION="${PERF_TEST_FUNCTION:-test_e2e}"

echo "æµ‹è¯•æ¨¡å—: $PERF_TEST_MODULE"
echo "æµ‹è¯•å‡½æ•°: $PERF_TEST_FUNCTION"

PYTEST_CMD+=" ${PERF_TEST_MODULE}::${PERF_TEST_FUNCTION}"
```

---

### æ­¥éª¤ 3: ä¿®æ”¹ Jenkins Pipelineï¼ˆPerf_Test.groovyï¼‰

**æ·»åŠ æ–°çš„å‚æ•°ï¼ˆåœ¨ 15-111 è¡Œçš„ parameters éƒ¨åˆ†ï¼‰ï¼š**

```groovy
properties([
    parameters([
        // ... ç°æœ‰å‚æ•° ...
        
        // âœ… æ–°å¢ï¼šè‡ªå®šä¹‰æµ‹è¯•æ¨¡å—å‚æ•°
        string(
            name: 'PERF_TEST_MODULE',
            defaultValue: 'perf/test_perf_sanity.py',
            description: '''æ€§èƒ½æµ‹è¯•æ¨¡å—è·¯å¾„ï¼ˆç›¸å¯¹äº tests/integration/defs/ï¼‰
é»˜è®¤: perf/test_perf_sanity.py
è‡ªå®šä¹‰: perf/test_perf_enhanced.py
å®Œæ•´è·¯å¾„ç¤ºä¾‹: tests/integration/defs/perf/test_perf_enhanced.py'''
        ),
        string(
            name: 'PERF_TEST_FUNCTION',
            defaultValue: 'test_e2e',
            description: '''æ€§èƒ½æµ‹è¯•å‡½æ•°å
é»˜è®¤: test_e2e
è‡ªå®šä¹‰: test_e2e_enhanced'''
        ),
        string(
            name: 'PERF_TEST_PREFIX',
            defaultValue: '',
            description: '''æµ‹è¯•åç§°å‰ç¼€ï¼ˆä»… disagg æ¨¡å¼ï¼‰
é»˜è®¤: disagg_upload (ä¸å¡«åˆ™ä½¿ç”¨é»˜è®¤å€¼)
è‡ªå®šä¹‰: disagg_custom'''
        ),
        
        // ... å…¶ä»–å‚æ•° ...
    ])
])
```

**åœ¨ environment éƒ¨åˆ†æ·»åŠ ç¯å¢ƒå˜é‡ï¼ˆ124-148 è¡Œï¼‰ï¼š**

```groovy
environment {
    // ... ç°æœ‰ç¯å¢ƒå˜é‡ ...
    
    // âœ… æ–°å¢ï¼šè‡ªå®šä¹‰æµ‹è¯•æ¨¡å—ç¯å¢ƒå˜é‡
    PERF_TEST_MODULE = "${params.PERF_TEST_MODULE ?: 'perf/test_perf_sanity.py'}"
    PERF_TEST_FUNCTION = "${params.PERF_TEST_FUNCTION ?: 'test_e2e'}"
    PERF_TEST_PREFIX = "${params.PERF_TEST_PREFIX ?: 'disagg_upload'}"
}
```

**åœ¨æ‰§è¡Œæµ‹è¯•æ—¶å¯¼å‡ºç¯å¢ƒå˜é‡ï¼ˆ382-404 è¡Œï¼‰ï¼š**

```groovy
// æ‰§è¡Œ sync_and_run.sh
def result = sh(
    script: """
        # å¯¼å‡ºé›†ç¾¤é…ç½®ç¯å¢ƒå˜é‡
        export CLUSTER_ACCOUNT='${env.CLUSTER_ACCOUNT}'
        export CLUSTER_PARTITION='${env.CLUSTER_PARTITION}'
        export CLUSTER_LLM_DATA='${env.CLUSTER_LLM_DATA}'
        export DOCKER_IMAGE='${env.DOCKER_IMAGE}'
        export MPI_TYPE='${env.MPI_TYPE}'
        export CLUSTER_HOST='${env.CLUSTER_HOST}'
        export CLUSTER_USER='${env.CLUSTER_USER}'
        export CLUSTER_TYPE='${env.CLUSTER_TYPE}'
        export CLUSTER_NAME='${env.CLUSTER_NAME}'
        export CLUSTER_WORKDIR='${env.CLUSTER_WORKDIR}'
        
        # âœ… æ–°å¢ï¼šå¯¼å‡ºè‡ªå®šä¹‰æµ‹è¯•æ¨¡å—ç¯å¢ƒå˜é‡
        export PERF_TEST_MODULE='${env.PERF_TEST_MODULE}'
        export PERF_TEST_FUNCTION='${env.PERF_TEST_FUNCTION}'
        export PERF_TEST_PREFIX='${env.PERF_TEST_PREFIX}'
        
        # è°ƒç”¨ sync_and_run.sh
        ${SCRIPTS_DIR}/sync_and_run.sh \\
            --trtllm-dir ${TRTLLM_DIR} \\
            --workspace ${OUTPUT_DIR} \\
            --remote-script ${remoteScript} \\
            ${remoteScriptArgs.join(' ')}
    """,
    returnStatus: true
)
```

---

### æ­¥éª¤ 4: ä¿®æ”¹ sync_and_run.shï¼ˆä¼ é€’ç¯å¢ƒå˜é‡ï¼‰

**åœ¨ SSH æ‰§è¡Œéƒ¨åˆ†æ·»åŠ ç¯å¢ƒå˜é‡ï¼š**

```bash
# åœ¨ SSH å‘½ä»¤ä¸­æ·»åŠ ç¯å¢ƒå˜é‡
ssh ${CLUSTER_USER}@${CLUSTER_HOST} "
    export CLUSTER_ACCOUNT='${CLUSTER_ACCOUNT}'
    export CLUSTER_PARTITION='${CLUSTER_PARTITION}'
    export CLUSTER_LLM_DATA='${CLUSTER_LLM_DATA}'
    export DOCKER_IMAGE='${DOCKER_IMAGE}'
    export MPI_TYPE='${MPI_TYPE}'
    
    # âœ… æ–°å¢ï¼šä¼ é€’è‡ªå®šä¹‰æµ‹è¯•æ¨¡å—ç¯å¢ƒå˜é‡
    export PERF_TEST_MODULE='${PERF_TEST_MODULE}'
    export PERF_TEST_FUNCTION='${PERF_TEST_FUNCTION}'
    export PERF_TEST_PREFIX='${PERF_TEST_PREFIX}'
    
    cd ${REMOTE_WORKSPACE} && bash ${REMOTE_SCRIPT_PATH} ${SCRIPT_ARGS}
"
```

---

## ğŸ“Š ä½¿ç”¨ç¤ºä¾‹

### ç¤ºä¾‹ 1: ä½¿ç”¨é»˜è®¤ test_perf_sanity.pyï¼ˆä¿æŒç°çŠ¶ï¼‰

**Jenkins å‚æ•°ï¼š**
```
PERF_TEST_MODULE: perf/test_perf_sanity.py  (é»˜è®¤)
PERF_TEST_FUNCTION: test_e2e                (é»˜è®¤)
PERF_TEST_PREFIX: disagg_upload             (é»˜è®¤)
```

**å®é™…æ‰§è¡Œï¼š**
```bash
pytest perf/test_perf_sanity.py::test_e2e[disagg_upload-deepseek-r1-fp4_...]
```

**æ•ˆæœï¼š** âœ… å®Œå…¨å…¼å®¹ç°æœ‰æµç¨‹

---

### ç¤ºä¾‹ 2: ä½¿ç”¨è‡ªå®šä¹‰ test_perf_enhanced.py

**Jenkins å‚æ•°ï¼š**
```
PERF_TEST_MODULE: perf/test_perf_enhanced.py
PERF_TEST_FUNCTION: test_e2e
PERF_TEST_PREFIX: disagg_custom
```

**å®é™…æ‰§è¡Œï¼š**
```bash
pytest perf/test_perf_enhanced.py::test_e2e[disagg_custom-deepseek-r1-fp4_...]
```

**æ•ˆæœï¼š** âœ… ä½¿ç”¨è‡ªå®šä¹‰æµ‹è¯•æ–‡ä»¶

---

### ç¤ºä¾‹ 3: ä½¿ç”¨å®Œå…¨è‡ªå®šä¹‰çš„å‡½æ•°

**Jenkins å‚æ•°ï¼š**
```
PERF_TEST_MODULE: perf/my_custom_tests.py
PERF_TEST_FUNCTION: test_custom_benchmark
PERF_TEST_PREFIX: custom_test
```

**å®é™…æ‰§è¡Œï¼š**
```bash
pytest perf/my_custom_tests.py::test_custom_benchmark[custom_test-deepseek-r1-fp4_...]
```

**æ•ˆæœï¼š** âœ… å®Œå…¨è‡ªå®šä¹‰æµ‹è¯•

---

## ğŸ” æ”¯æŒçš„ä¸‰ç§æ¨¡å¼

### 1. Single-Agg æ¨¡å¼

**è°ƒç”¨é“¾ï¼š**
```
Perf_Test.groovy
  â†’ run_single_agg_test.sh
    â†’ pytest ${PERF_TEST_MODULE}::${PERF_TEST_FUNCTION}[config-name]
```

**ä¿®æ”¹ç‚¹ï¼š**
- âœ… `run_single_agg_test.sh` ä½¿ç”¨ `PERF_TEST_MODULE` ç¯å¢ƒå˜é‡

---

### 2. Multi-Agg æ¨¡å¼

**è°ƒç”¨é“¾ï¼š**
```
Perf_Test.groovy
  â†’ run_multi_agg_test.sh
    â†’ pytest ${PERF_TEST_MODULE}::${PERF_TEST_FUNCTION}[config-name]
```

**ä¿®æ”¹ç‚¹ï¼š**
- âœ… `run_multi_agg_test.sh` ä½¿ç”¨ `PERF_TEST_MODULE` ç¯å¢ƒå˜é‡

---

### 3. Disagg æ¨¡å¼

**è°ƒç”¨é“¾ï¼š**
```
Perf_Test.groovy
  â†’ run_disagg_test.sh
    â†’ submit.py
      â†’ slurm_launch_draft.sh
        â†’ slurm_run.sh
          â†’ pytest ${PERF_TEST_MODULE}::${PERF_TEST_FUNCTION}[${PERF_TEST_PREFIX}-config-name]
```

**ä¿®æ”¹ç‚¹ï¼š**
- âœ… `run_disagg_test.sh` ä½¿ç”¨ `PERF_TEST_MODULE`ã€`PERF_TEST_FUNCTION`ã€`PERF_TEST_PREFIX` ç¯å¢ƒå˜é‡
- âœ… é€šè¿‡ `slurm_launch_prefix.sh` ä¼ é€’ç»™ pytest

---

## ğŸ“ è‡ªå®šä¹‰åŠŸèƒ½ç¤ºä¾‹

### åŠŸèƒ½ 1: å¯¼å‡º CSV ä¾› trt_perf_parser.py ä½¿ç”¨

```python
# test_perf_enhanced.py

def export_results_to_csv(self, csv_path: str):
    """å¯¼å‡ºç»“æœåˆ° CSV ä¾› trt_perf_parser.py ä½¿ç”¨"""
    import csv
    
    if not self._perf_results:
        return
    
    csv_rows = []
    
    for server_idx, (ctx_config, gen_config, disagg_config) in enumerate(self.server_configs):
        client_configs = self.server_client_configs[server_idx]
        server_perf_results = self._perf_results.get(server_idx, [])
        
        for client_idx, client_config in enumerate(client_configs):
            if client_idx >= len(server_perf_results) or server_perf_results[client_idx] is None:
                continue
            
            perf_data = server_perf_results[client_idx]
            
            row = {
                'network': disagg_config.name,
                'batchsize': client_config.concurrency,
                'precision': gen_config.dtype,
                'framework': 'TensorRT-LLM',
                'command': f"disagg_{ctx_config.name}_{gen_config.name}",
            }
            
            # æ·»åŠ æ€§èƒ½æŒ‡æ ‡
            for metric_name, metric_value in perf_data.items():
                if metric_name in ['mean_ttft', 'median_ttft', 'p99_ttft']:
                    row[f'{metric_name}__ms'] = metric_value
                elif metric_name in ['mean_e2el', 'median_e2el', 'p99_e2el']:
                    row[f'{metric_name}__ms'] = metric_value
                elif metric_name == 'token_throughput':
                    row['throughput__qps'] = metric_value
                else:
                    row[metric_name] = metric_value
            
            csv_rows.append(row)
    
    # å†™å…¥ CSV
    if csv_rows:
        fieldnames = list(csv_rows[0].keys())
        with open(csv_path, 'w', newline='') as csvfile:
            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
            writer.writeheader()
            writer.writerows(csv_rows)
        print_info(f"Exported {len(csv_rows)} results to {csv_path}")
```

---

### åŠŸèƒ½ 2: è‡ªå®šä¹‰æ—¥å¿—æ”¶é›†

```python
# test_perf_enhanced.py

def collect_detailed_logs(self, log_dir: str):
    """æ”¶é›†è¯¦ç»†çš„æ—¥å¿—æ–‡ä»¶"""
    import shutil
    
    os.makedirs(log_dir, exist_ok=True)
    
    # æ”¶é›†æ‰€æœ‰æ—¥å¿—
    log_patterns = [
        (f"{self.output_dir}/*.log", "server_logs"),
        (f"{self.output_dir}/*_server_*.log", "component_logs"),
        (f"{self.output_dir}/benchmark*.log", "benchmark_logs"),
    ]
    
    for pattern, subdir in log_patterns:
        dest = os.path.join(log_dir, subdir)
        os.makedirs(dest, exist_ok=True)
        
        for log_file in glob.glob(pattern):
            shutil.copy(log_file, dest)
            print_info(f"Collected log: {log_file} â†’ {dest}")
```

---

### åŠŸèƒ½ 3: è‡ªå®šä¹‰æ€§èƒ½æŒ‡æ ‡

```python
# test_perf_enhanced.py

CUSTOM_PERF_METRICS = {
    **PERF_METRIC_LOG_QUERIES,  # ç»§æ‰¿åŸå§‹æŒ‡æ ‡
    
    # æ·»åŠ è‡ªå®šä¹‰æŒ‡æ ‡
    "custom_metric_1": re.compile(r"My Metric 1 \(units\):\s+(-?[\d\.]+)"),
    "custom_metric_2": re.compile(r"My Metric 2 \(units\):\s+(-?[\d\.]+)"),
}

def get_perf_result(self, outputs: Dict[int, List[str]]):
    """è§£ææ€§èƒ½ç»“æœï¼ˆæ”¯æŒè‡ªå®šä¹‰æŒ‡æ ‡ï¼‰"""
    # ä½¿ç”¨è‡ªå®šä¹‰æŒ‡æ ‡è§£æ
    for metric_name, pattern in CUSTOM_PERF_METRICS.items():
        # è§£æé€»è¾‘
        pass
```

---

## ğŸ¯ å®Œæ•´ä¿®æ”¹æ¸…å•

### å¿…é¡»ä¿®æ”¹çš„æ–‡ä»¶

| æ–‡ä»¶ | ä¿®æ”¹å†…å®¹ | è¡Œå·å‚è€ƒ |
|------|---------|---------|
| **run_disagg_test.sh** | æ·»åŠ  `PERF_TEST_MODULE`ã€`PERF_TEST_FUNCTION`ã€`PERF_TEST_PREFIX` æ”¯æŒ | 257, 284 |
| **run_single_agg_test.sh** | æ·»åŠ  `PERF_TEST_MODULE`ã€`PERF_TEST_FUNCTION` æ”¯æŒ | 131 |
| **run_multi_agg_test.sh** | æ·»åŠ  `PERF_TEST_MODULE`ã€`PERF_TEST_FUNCTION` æ”¯æŒ | 201 |
| **Perf_Test.groovy** | æ·»åŠ å‚æ•°å’Œç¯å¢ƒå˜é‡ | 15-111 (å‚æ•°), 124-148 (ç¯å¢ƒå˜é‡), 382-404 (å¯¼å‡º) |
| **sync_and_run.sh** | ä¼ é€’ç¯å¢ƒå˜é‡åˆ°è¿œç¨‹æ‰§è¡Œ | SSH å‘½ä»¤éƒ¨åˆ† |

### å¯é€‰ä¿®æ”¹çš„æ–‡ä»¶

| æ–‡ä»¶ | ä¿®æ”¹å†…å®¹ |
|------|---------|
| **parse_unified_testlist.py** | æ”¯æŒè‡ªå®šä¹‰æµ‹è¯•å‰ç¼€è§£æ (å¦‚æœä½¿ç”¨ TestList æ¨¡å¼) |

---

## ğŸ“š æµ‹è¯•éªŒè¯

### éªŒè¯æ­¥éª¤ 1: æœ¬åœ°æµ‹è¯•

```bash
# è®¾ç½®ç¯å¢ƒå˜é‡
export PERF_TEST_MODULE="perf/test_perf_enhanced.py"
export PERF_TEST_FUNCTION="test_e2e"
export PERF_TEST_PREFIX="custom_test"

# è¿è¡Œå•ä¸ªæµ‹è¯•
bash jenkins_test/scripts/run_disagg_test.sh deepseek-r1-fp4_1k1k_ctx1_gen1_dep8_bs768_eplb0_mtp0_ccb-UCX
```

### éªŒè¯æ­¥éª¤ 2: Jenkins æµ‹è¯•

**åœ¨ Jenkins ä¸­è®¾ç½®å‚æ•°ï¼š**
- PERF_TEST_MODULE: `perf/test_perf_enhanced.py`
- PERF_TEST_FUNCTION: `test_e2e`
- PERF_TEST_PREFIX: `custom_test`
- TESTLIST: `manual`
- CONFIG_FILE: `deepseek-r1-fp4_1k1k_ctx1_gen1_dep8_bs768_eplb0_mtp0_ccb-UCX`
- MANUAL_TEST_MODE: `disagg`

**æ£€æŸ¥æ—¥å¿—è¾“å‡ºï¼š**
```
[æ­¥éª¤ 0] æµ‹è¯•æ¨¡å—é…ç½®:
  æµ‹è¯•æ¨¡å—: perf/test_perf_enhanced.py
  æµ‹è¯•å‡½æ•°: test_e2e
  æµ‹è¯•å‰ç¼€: custom_test
```

### éªŒè¯æ­¥éª¤ 3: æ£€æŸ¥ç”Ÿæˆçš„å‘½ä»¤

**æŸ¥çœ‹ slurm_launch_prefix.shï¼š**
```bash
cat $WORKSPACE/slurm_launch_prefix.sh | grep pytestCommand
```

**åº”è¯¥çœ‹åˆ°ï¼š**
```bash
export pytestCommand="pytest perf/test_perf_enhanced.py::test_e2e[custom_test-deepseek-r1-fp4_...] -vv --junit-xml=$WORKSPACE/results.xml"
```

---

## ğŸ”§ å¸¸è§é—®é¢˜

### Q1: å¦‚ä½•å¿«é€Ÿåˆ‡æ¢å›åŸå§‹ test_perf_sanity.pyï¼Ÿ

**A:** åªéœ€å°† Jenkins å‚æ•°è®¾ç½®ä¸ºé»˜è®¤å€¼æˆ–ç•™ç©ºå³å¯ï¼š
```
PERF_TEST_MODULE: perf/test_perf_sanity.py (æˆ–ç•™ç©º)
PERF_TEST_FUNCTION: test_e2e (æˆ–ç•™ç©º)
PERF_TEST_PREFIX: disagg_upload (æˆ–ç•™ç©º)
```

---

### Q2: test_perf_enhanced.py éœ€è¦æ”¾åœ¨å“ªé‡Œï¼Ÿ

**A:** å»ºè®®æ”¾åœ¨ä¸ test_perf_sanity.py ç›¸åŒçš„ç›®å½•ï¼š
```
tests/integration/defs/perf/test_perf_enhanced.py
```

è¿™æ ·å¯ä»¥ç›´æ¥ä½¿ç”¨ç›¸å¯¹è·¯å¾„ `perf/test_perf_enhanced.py`ã€‚

---

### Q3: å¦‚ä½•ç¡®ä¿ test_perf_enhanced.py ä¸ç°æœ‰ç³»ç»Ÿå…¼å®¹ï¼Ÿ

**A:** éµå¾ªä»¥ä¸‹åŸåˆ™ï¼š

1. âœ… **ç»§æ‰¿åŸå§‹ç±»**ï¼š
   ```python
   from test_perf_sanity import PerfSanityTestConfig
   
   class EnhancedPerfTestConfig(PerfSanityTestConfig):
       pass
   ```

2. âœ… **ä¿æŒç›¸åŒçš„æµ‹è¯•å‡½æ•°ç­¾å**ï¼š
   ```python
   def test_e2e(output_dir, perf_test_case):
       # å‚æ•°åç§°å’Œæ•°é‡å¿…é¡»ç›¸åŒ
       pass
   ```

3. âœ… **æ”¯æŒç›¸åŒçš„ YAML é…ç½®æ ¼å¼**

4. âœ… **è¿”å›ç›¸åŒçš„æ€§èƒ½æŒ‡æ ‡æ ¼å¼**

---

### Q4: æ˜¯å¦ä¼šå½±å“ç°æœ‰çš„æµ‹è¯•ï¼Ÿ

**A:** ä¸ä¼šï¼
- âœ… é»˜è®¤å€¼ä½¿ç”¨åŸå§‹ `test_perf_sanity.py`
- âœ… æ‰€æœ‰ä¿®æ”¹éƒ½æ˜¯**å‘åå…¼å®¹**çš„
- âœ… åªæœ‰æ˜ç¡®æŒ‡å®šè‡ªå®šä¹‰æ¨¡å—æ—¶æ‰ä¼šä½¿ç”¨

---

### Q5: å¦‚ä½•åœ¨è‡ªå®šä¹‰æµ‹è¯•ä¸­å¤ç”¨åŸå§‹åŠŸèƒ½ï¼Ÿ

**A:** é€šè¿‡å¯¼å…¥å’Œç»§æ‰¿ï¼š

```python
# å¯¼å…¥æ‰€æœ‰åŸå§‹åŠŸèƒ½
from test_perf_sanity import *

# æ‰©å±•é…ç½®ç±»
class EnhancedPerfTestConfig(PerfSanityTestConfig):
    def upload_test_results_to_database(self):
        # è°ƒç”¨åŸå§‹åŠŸèƒ½
        super().upload_test_results_to_database()
        
        # æ·»åŠ è‡ªå®šä¹‰åŠŸèƒ½
        self._upload_to_custom_db()
```

---

## âœ… æ€»ç»“

### å…³é”®ä¼˜åŠ¿

1. âœ… **å®Œå…¨å…¼å®¹**ï¼šä¸ç ´åç°æœ‰æµç¨‹
2. âœ… **çµæ´»åˆ‡æ¢**ï¼šé€šè¿‡ç¯å¢ƒå˜é‡æ§åˆ¶
3. âœ… **ç»Ÿä¸€æ¶æ„**ï¼šsingle-aggã€multi-aggã€disagg éƒ½æ”¯æŒ
4. âœ… **æ˜“äºæ‰©å±•**ï¼šå¯ä»¥æ·»åŠ ä»»æ„è‡ªå®šä¹‰åŠŸèƒ½
5. âœ… **æ˜“äºè°ƒè¯•**ï¼šå¯ä»¥æœ¬åœ°æµ‹è¯•

### å®æ–½æ­¥éª¤æ€»ç»“

1. âœ… åˆ›å»º `test_perf_enhanced.py`
2. âœ… ä¿®æ”¹ `run_disagg_test.sh`ã€`run_single_agg_test.sh`ã€`run_multi_agg_test.sh`
3. âœ… ä¿®æ”¹ `Perf_Test.groovy` æ·»åŠ å‚æ•°
4. âœ… ä¿®æ”¹ `sync_and_run.sh` ä¼ é€’ç¯å¢ƒå˜é‡
5. âœ… æµ‹è¯•éªŒè¯

### ä½¿ç”¨å»ºè®®

- ğŸ”¸ **å¼€å‘é˜¶æ®µ**ï¼šä½¿ç”¨ `test_perf_enhanced.py` æ·»åŠ æ–°åŠŸèƒ½
- ğŸ”¸ **ç¨³å®šå**ï¼šè€ƒè™‘åˆå¹¶åˆ° `test_perf_sanity.py`
- ğŸ”¸ **ç‰¹æ®Šéœ€æ±‚**ï¼šä¿æŒç‹¬ç«‹çš„ `test_perf_enhanced.py`

---

**ç°åœ¨ä½ æœ‰äº†å®Œæ•´çš„å®šåˆ¶æ–¹æ¡ˆï¼éœ€è¦æˆ‘å¸®ä½ å®é™…ä¿®æ”¹è¿™äº›æ–‡ä»¶å—ï¼Ÿ** ğŸš€
